Response: Let's break down the thought process for summarizing the functionality of `maglev-code-generator.cc` part 2.

1. **Understand the Context:** The prompt clearly states this is *part 2* of the file. This immediately tells me that the initial parts of the code generation process (like basic setup, initial code emission) were likely covered in part 1. This part will focus on the later stages.

2. **Identify Key Data Structures and Classes:**  I scan the code for important classes and members. These jump out:
    * `MaglevFrameTranslationBuilder`:  This name strongly suggests handling the conversion of Maglev frames to a format understandable by the deoptimizer.
    * `protected_deopt_literals_`, `deopt_literals_`: These are clearly related to storing constant values needed during deoptimization. The "protected" likely indicates special handling for trusted objects.
    * `EagerDeoptInfo`, `LazyDeoptInfo`:  These represent different types of deoptimization events.
    * `DeoptimizationData`: This is the ultimate output – the data structure containing information needed for deoptimization.
    * `SafepointTableBuilder`, `HandlerTable`: While mentioned in part 1, they are used here for final emission.
    * `CodeDesc`:  Used to construct the final `Code` object.

3. **Follow the Control Flow in Key Methods:** I focus on the primary methods that seem to orchestrate the remaining steps:
    * `EmitDeopts()`: This is clearly the core of this part. It deals with generating code for both eager and lazy deoptimizations. I note the steps involved: building the frame translation, recording deopt reasons, and calling the deoptimization entry points.
    * `EmitExceptionHandlerTrampolines()`: This is a separate, relatively straightforward function related to handling exceptions.
    * `EmitMetadata()`:  This deals with emitting the `SafepointTable` and `HandlerTable`.
    * `BuildCodeObject()`: This is the final step, where the generated code and metadata are combined to create the executable `Code` object. I see the interaction with `DeoptimizationData` here.
    * `GenerateDeoptimizationData()`:  This method is crucial for populating the `DeoptimizationData` object. I look for what data it collects and how it's structured (frame translation, literals, inlining positions, etc.).

4. **Infer Functionality from Names and Actions:**  For instance:
    * `BuildDeoptFrameSingleValue()` (within `MaglevFrameTranslationBuilder` - seen in part 1, but the concept is reinforced here): This clearly builds the frame information for a single value during deoptimization.
    * `GetProtectedDeoptLiteral()`, `GetDeoptLiteral()`: These methods manage the storage and retrieval of deoptimization literals, avoiding duplication.
    * `RecordDeoptReason()`:  This function captures the reason for deoptimization, which is vital for debugging and understanding program behavior.
    * The calls to `Builtin::kDeoptimizationEntry_Eager` and `Builtin::kDeoptimizationEntry_Lazy` indicate the interaction with the runtime system's deoptimization logic.

5. **Connect the Dots - The Deoptimization Story:** I realize that a significant portion of this code is dedicated to *deoptimization*. It handles how to gracefully fall back from optimized Maglev code to the interpreter when necessary. This involves:
    * Recording where deoptimization can occur.
    * Building the necessary information to reconstruct the interpreter's state.
    * Storing constant values needed by the interpreter.
    * Generating the actual "exit" code that performs the transition.

6. **Identify Interactions with JavaScript:** The prompt specifically asks about JavaScript relevance. Deoptimization is a key concept when optimizing JavaScript. When optimizations become invalid (e.g., due to type changes), the engine needs to revert to a slower, but correct, execution path. The deoptimization data generated by this code is what makes this fallback possible. The literals stored can be JavaScript objects or values. The frame translation helps reconstruct the JavaScript stack.

7. **Structure the Summary:**  I organize the summary logically, starting with the main goal (finalizing code generation and handling deoptimization) and then breaking it down into key areas:
    * Deoptimization handling (eager and lazy).
    * Exception handling.
    * Metadata emission.
    * Final code object construction.
    * Generation of deoptimization data.

8. **Illustrate with JavaScript Examples (If Applicable):**  The example focuses on type changes because that's a common trigger for deoptimization in JavaScript. Showing a simple function that gets optimized and then deoptimizes due to a type change effectively demonstrates the purpose of the generated deoptimization data.

9. **Refine and Clarify:** I review the summary for clarity and accuracy, making sure the language is precise and easy to understand. I ensure I've addressed all parts of the prompt. I emphasize the role of this part in *completing* the code generation process.

By following these steps, I can effectively understand the functionality of this code snippet and provide a comprehensive and informative summary, including its connection to JavaScript.
Based on the provided C++ source code snippet from `v8/src/maglev/maglev-code-generator.cc`, which is the **second part** of the file, here's a summary of its functionality:

**Core Functionality: Finalizing Maglev Code Generation and Handling Deoptimization**

This part of the `MaglevCodeGenerator` class focuses on the final stages of generating optimized machine code for JavaScript functions using the Maglev compiler. Its primary responsibilities include:

1. **Emitting Deoptimization Code:**
   - It generates code for both **eager** and **lazy** deoptimizations. Deoptimization is the process of reverting from optimized code back to the interpreter when assumptions made during optimization are no longer valid.
   - It builds frame translations (`MaglevFrameTranslationBuilder`) to describe the state of the stack and registers at the point of deoptimization, enabling the interpreter to resume execution correctly.
   - It records the reasons for deoptimization (`RecordDeoptReason`).
   - It generates calls to the deoptimization entry points in the V8 runtime (`Builtin::kDeoptimizationEntry_Eager`, `Builtin::kDeoptimizationEntry_Lazy`).

2. **Emitting Exception Handler Trampolines:**
   - If the function has exception handlers, it generates trampolines (small pieces of code) that redirect execution to the appropriate handler when an exception occurs.

3. **Emitting Metadata:**
   - It emits metadata crucial for the generated code, including:
     - **Safepoint Table:**  This table indicates points in the code where garbage collection can safely occur.
     - **Handler Table:**  This table maps program counter offsets to the entry points of exception handlers.

4. **Building the Final Code Object:**
   - It creates the final `Code` object, which represents the compiled machine code. This involves:
     - Using the `CodeDesc` structure to describe the code.
     - Setting properties like stack slot count, parameter count, and deoptimization data.
     - Handling context specialization.

5. **Generating Deoptimization Data:**
   - It creates the `DeoptimizationData` object, which contains all the information needed for deoptimization, including:
     - **Frame Translation Data:**  How to reconstruct the stack frame.
     - **Inlined Function Count:**  The number of functions that were inlined.
     - **Optimization ID:**  A unique identifier for this optimization.
     - **Deoptimization Literal Arrays:**  Arrays of constant values (literals) used during deoptimization. This includes both regular and "protected" literals (likely for trusted objects).
     - **Inlining Positions:** Information about where inlining occurred.
     - **OSR Information:**  Data related to On-Stack Replacement (OSR), if applicable.
     - **Deoptimization Entries:**  Information about each specific deoptimization point (bytecode offset, translation index, program counter).

**Relationship to JavaScript and Examples:**

This code is directly responsible for making optimized JavaScript execution possible in V8. When JavaScript code is deemed hot (executed frequently), Maglev attempts to compile it into more efficient machine code. However, the assumptions made during optimization might not always hold true. That's where deoptimization comes in.

Here are examples of how the functionality relates to JavaScript:

**1. Type Changes Leading to Deoptimization:**

```javascript
function add(a, b) {
  return a + b;
}

// Initially, 'a' and 'b' might be assumed to be numbers.
add(5, 10); // Maglev might optimize this assuming numeric addition.

// Later, if the types change:
add("hello", "world"); // Now string concatenation is needed.
```

In this scenario, the Maglev-compiled version of `add` might have been optimized for numeric addition. When called with strings, the assumption is violated. The deoptimization code generated by `MaglevCodeGenerator` would kick in:

- The generated code at the deoptimization point would use the frame translation data to reconstruct the state of the JavaScript engine (values of `a` and `b`, current execution point).
- The deoptimization literals might contain the original function object or other relevant values.
- The execution would then jump to the interpreter, which can handle the string concatenation correctly.

**2. Accessing Properties of Objects with Different Shapes:**

```javascript
function getX(obj) {
  return obj.x;
}

const obj1 = { x: 1, y: 2 };
getX(obj1); // Maglev might optimize based on the shape of obj1.

const obj2 = { x: 3, z: 4 };
getX(obj2); // If Maglev assumed a specific object shape, this could trigger deoptimization.
```

Maglev might optimize `getX` assuming that the object passed to it always has properties `x` and `y` in a specific order (the "shape" or "hidden class"). If `obj2` is passed, it has a different shape. The deoptimization mechanism would:

- Use the frame translation to restore the state.
- Potentially use deoptimization literals to access the correct property (as the optimized code might have used a more direct memory access based on the assumed shape).
- Revert to the interpreter to handle the property access dynamically.

**In summary, this part of `maglev-code-generator.cc` is crucial for the reliability and performance of V8's Maglev compiler. It ensures that optimized code can be safely abandoned when necessary, allowing the JavaScript engine to fall back to the interpreter and maintain correctness even in dynamically typed scenarios.** The generated deoptimization data acts as a blueprint for this fallback process.

Prompt: 
```
这是目录为v8/src/maglev/maglev-code-generator.cc的一个c++源代码文件， 请归纳一下它的功能, 如果它与javascript的功能有关系，请用javascript举例说明
这是第2部分，共2部分，请归纳一下它的功能

"""
  }
            DCHECK_EQ(i, reg.index());
            BuildDeoptFrameSingleValue(value, input_location, virtual_objects);
            i++;
          });
      while (i < compilation_unit.register_count()) {
        translation_array_builder_->StoreOptimizedOut();
        i++;
      }
    }

    // Accumulator
    {
      if (checkpoint_state->liveness()->AccumulatorIsLive() &&
          !LazyDeoptInfo::InReturnValues(
              interpreter::Register::virtual_accumulator(), result_location,
              result_size)) {
        ValueNode* value = checkpoint_state->accumulator(compilation_unit);
        BuildDeoptFrameSingleValue(value, input_location, virtual_objects);
      } else {
        translation_array_builder_->StoreOptimizedOut();
      }
    }
  }

  int GetProtectedDeoptLiteral(Tagged<TrustedObject> obj) {
    IdentityMapFindResult<int> res =
        protected_deopt_literals_->FindOrInsert(obj);
    if (!res.already_exists) {
      DCHECK_EQ(0, *res.entry);
      *res.entry = protected_deopt_literals_->size() - 1;
    }
    return *res.entry;
  }

  int GetDeoptLiteral(Tagged<Object> obj) {
    IdentityMapFindResult<int> res = deopt_literals_->FindOrInsert(obj);
    if (!res.already_exists) {
      DCHECK_EQ(0, *res.entry);
      *res.entry = deopt_literals_->size() - 1;
    }
    return *res.entry;
  }

  int GetDeoptLiteral(compiler::HeapObjectRef ref) {
    return GetDeoptLiteral(*ref.object());
  }

  LocalIsolate* local_isolate_;
  MaglevAssembler* masm_;
  FrameTranslationBuilder* translation_array_builder_;
  IdentityMap<int, base::DefaultAllocationPolicy>* protected_deopt_literals_;
  IdentityMap<int, base::DefaultAllocationPolicy>* deopt_literals_;

  static const int kNotDuplicated = -1;
  std::vector<intptr_t> object_ids_;
};

}  // namespace

MaglevCodeGenerator::MaglevCodeGenerator(
    LocalIsolate* isolate, MaglevCompilationInfo* compilation_info,
    Graph* graph)
    : local_isolate_(isolate),
      safepoint_table_builder_(compilation_info->zone(),
                               graph->tagged_stack_slots()),
      frame_translation_builder_(compilation_info->zone()),
      code_gen_state_(compilation_info, &safepoint_table_builder_),
      masm_(isolate->GetMainThreadIsolateUnsafe(), compilation_info->zone(),
            &code_gen_state_),
      graph_(graph),
      protected_deopt_literals_(isolate->heap()->heap()),
      deopt_literals_(isolate->heap()->heap()),
      retained_maps_(isolate->heap()),
      is_context_specialized_(
          compilation_info->specialize_to_function_context()),
      zone_(compilation_info->zone()) {
  DCHECK(maglev::IsMaglevEnabled());
  DCHECK_IMPLIES(compilation_info->toplevel_is_osr(),
                 maglev::IsMaglevOsrEnabled());
}

bool MaglevCodeGenerator::Assemble() {
  if (!EmitCode()) {
#ifdef V8_TARGET_ARCH_ARM
    // Even if we fail, we force emit the constant pool, so that it is empty.
    __ CheckConstPool(true, false);
#endif
    return false;
  }

  EmitMetadata();

  if (v8_flags.maglev_build_code_on_background) {
    code_ = local_isolate_->heap()->NewPersistentMaybeHandle(
        BuildCodeObject(local_isolate_));
    Handle<Code> code;
    if (code_.ToHandle(&code)) {
      retained_maps_ = CollectRetainedMaps(code);
    }
  } else if (v8_flags.maglev_deopt_data_on_background) {
    // Only do this if not --maglev-build-code-on-background, since that will do
    // it itself.
    deopt_data_ = local_isolate_->heap()->NewPersistentHandle(
        GenerateDeoptimizationData(local_isolate_));
  }
  return true;
}

MaybeHandle<Code> MaglevCodeGenerator::Generate(Isolate* isolate) {
  if (v8_flags.maglev_build_code_on_background) {
    Handle<Code> code;
    if (code_.ToHandle(&code)) {
      return handle(*code, isolate);
    }
    return kNullMaybeHandle;
  }

  return BuildCodeObject(isolate->main_thread_local_isolate());
}

GlobalHandleVector<Map> MaglevCodeGenerator::RetainedMaps(Isolate* isolate) {
  DisallowGarbageCollection no_gc;
  GlobalHandleVector<Map> maps(isolate->heap());
  maps.Reserve(retained_maps_.size());
  for (DirectHandle<Map> map : retained_maps_) maps.Push(*map);
  return maps;
}

bool MaglevCodeGenerator::EmitCode() {
  GraphProcessor<NodeMultiProcessor<SafepointingNodeProcessor,
                                    MaglevCodeGeneratingNodeProcessor>>
      processor(SafepointingNodeProcessor{local_isolate_},
                MaglevCodeGeneratingNodeProcessor{masm(), zone_});
  RecordInlinedFunctions();

  if (graph_->is_osr()) {
    masm_.Abort(AbortReason::kShouldNotDirectlyEnterOsrFunction);
    masm_.RecordComment("-- OSR entrypoint --");
    masm_.BindJumpTarget(code_gen_state_.osr_entry());
  }

  processor.ProcessGraph(graph_);
  EmitDeferredCode();
  if (!EmitDeopts()) return false;
  EmitExceptionHandlerTrampolines();
  __ FinishCode();

  code_gen_succeeded_ = true;
  return true;
}

void MaglevCodeGenerator::RecordInlinedFunctions() {
  // The inlined functions should be the first literals.
  DCHECK_EQ(0u, deopt_literals_.size());
  for (OptimizedCompilationInfo::InlinedFunctionHolder& inlined :
       graph_->inlined_functions()) {
    IdentityMapFindResult<int> res =
        deopt_literals_.FindOrInsert(inlined.shared_info);
    if (!res.already_exists) {
      DCHECK_EQ(0, *res.entry);
      *res.entry = deopt_literals_.size() - 1;
    }
    inlined.RegisterInlinedFunctionId(*res.entry);
  }
  inlined_function_count_ = static_cast<int>(deopt_literals_.size());
}

void MaglevCodeGenerator::EmitDeferredCode() {
  // Loop over deferred_code() multiple times, clearing the vector on each
  // outer loop, so that deferred code can itself emit deferred code.
  while (!code_gen_state_.deferred_code().empty()) {
    for (DeferredCodeInfo* deferred_code : code_gen_state_.TakeDeferredCode()) {
      __ RecordComment("-- Deferred block");
      __ bind(&deferred_code->deferred_code_label);
      deferred_code->Generate(masm());
      __ Trap();
    }
  }
}

bool MaglevCodeGenerator::EmitDeopts() {
  const size_t num_deopts = code_gen_state_.eager_deopts().size() +
                            code_gen_state_.lazy_deopts().size();
  if (num_deopts > Deoptimizer::kMaxNumberOfEntries) {
    return false;
  }

  MaglevFrameTranslationBuilder translation_builder(
      local_isolate_, &masm_, &frame_translation_builder_,
      &protected_deopt_literals_, &deopt_literals_);

  // Deoptimization exits must be as small as possible, since their count grows
  // with function size. These labels are an optimization which extracts the
  // (potentially large) instruction sequence for the final jump to the
  // deoptimization entry into a single spot per InstructionStream object. All
  // deopt exits can then near-call to this label. Note: not used on all
  // architectures.
  Label eager_deopt_entry;
  Label lazy_deopt_entry;
  __ MaybeEmitDeoptBuiltinsCall(
      code_gen_state_.eager_deopts().size(), &eager_deopt_entry,
      code_gen_state_.lazy_deopts().size(), &lazy_deopt_entry);

  deopt_exit_start_offset_ = __ pc_offset();

  int deopt_index = 0;

  __ RecordComment("-- Non-lazy deopts");
  for (EagerDeoptInfo* deopt_info : code_gen_state_.eager_deopts()) {
    local_isolate_->heap()->Safepoint();
    translation_builder.BuildEagerDeopt(deopt_info);

    if (masm_.compilation_info()->collect_source_positions() ||
        IsDeoptimizationWithoutCodeInvalidation(deopt_info->reason())) {
      // Note: Maglev uses the deopt_reason to tell the deoptimizer not to
      // discard optimized code on deopt during ML-TF OSR. This is why we
      // unconditionally emit the deopt_reason when
      // IsDeoptimizationWithoutCodeInvalidation is true.
      __ RecordDeoptReason(deopt_info->reason(), 0,
                           GetSourcePosition(deopt_info->top_frame()),
                           deopt_index);
    }
    __ bind(deopt_info->deopt_entry_label());

    __ CallForDeoptimization(Builtin::kDeoptimizationEntry_Eager, deopt_index,
                             deopt_info->deopt_entry_label(),
                             DeoptimizeKind::kEager, nullptr,
                             &eager_deopt_entry);

    deopt_index++;
  }

  __ RecordComment("-- Lazy deopts");
  int last_updated_safepoint = 0;
  for (LazyDeoptInfo* deopt_info : code_gen_state_.lazy_deopts()) {
    local_isolate_->heap()->Safepoint();
    translation_builder.BuildLazyDeopt(deopt_info);

    if (masm_.compilation_info()->collect_source_positions()) {
      __ RecordDeoptReason(DeoptimizeReason::kUnknown, 0,
                           GetSourcePosition(deopt_info->top_frame()),
                           deopt_index);
    }
    __ BindExceptionHandler(deopt_info->deopt_entry_label());

    __ CallForDeoptimization(Builtin::kDeoptimizationEntry_Lazy, deopt_index,
                             deopt_info->deopt_entry_label(),
                             DeoptimizeKind::kLazy, nullptr, &lazy_deopt_entry);

    last_updated_safepoint = safepoint_table_builder_.UpdateDeoptimizationInfo(
        deopt_info->deopting_call_return_pc(),
        deopt_info->deopt_entry_label()->pos(), last_updated_safepoint,
        deopt_index);
    deopt_index++;
  }

  return true;
}

void MaglevCodeGenerator::EmitExceptionHandlerTrampolines() {
  if (code_gen_state_.handlers().empty()) return;
  __ RecordComment("-- Exception handler trampolines");
  for (NodeBase* node : code_gen_state_.handlers()) {
    ExceptionHandlerTrampolineBuilder::Build(masm(), node);
  }
}

void MaglevCodeGenerator::EmitMetadata() {
  // Final alignment before starting on the metadata section.
  masm()->Align(InstructionStream::kMetadataAlignment);

  safepoint_table_builder_.Emit(masm(), stack_slot_count_with_fixed_frame());

  // Exception handler table.
  handler_table_offset_ = HandlerTable::EmitReturnTableStart(masm());
  for (NodeBase* node : code_gen_state_.handlers()) {
    ExceptionHandlerInfo* info = node->exception_handler_info();
    DCHECK_IMPLIES(info->ShouldLazyDeopt(), !info->trampoline_entry.is_bound());
    int pos = info->ShouldLazyDeopt() ? HandlerTable::kLazyDeopt
                                      : info->trampoline_entry.pos();
    HandlerTable::EmitReturnEntry(masm(), info->pc_offset, pos);
  }
}

MaybeHandle<Code> MaglevCodeGenerator::BuildCodeObject(
    LocalIsolate* local_isolate) {
  if (!code_gen_succeeded_) return {};

  Handle<DeoptimizationData> deopt_data =
      (v8_flags.maglev_deopt_data_on_background &&
       !v8_flags.maglev_build_code_on_background)
          ? deopt_data_
          : GenerateDeoptimizationData(local_isolate);
  CHECK(!deopt_data.is_null());

  CodeDesc desc;
  masm()->GetCode(local_isolate, &desc, &safepoint_table_builder_,
                  handler_table_offset_);
  auto builder =
      Factory::CodeBuilder{local_isolate, desc, CodeKind::MAGLEV}
          .set_stack_slots(stack_slot_count_with_fixed_frame())
          .set_parameter_count(parameter_count())
          .set_deoptimization_data(deopt_data)
          .set_empty_source_position_table()
          .set_osr_offset(
              code_gen_state_.compilation_info()->toplevel_osr_offset());

  if (is_context_specialized_) {
    builder.set_is_context_specialized();
  }

  return builder.TryBuild();
}

GlobalHandleVector<Map> MaglevCodeGenerator::CollectRetainedMaps(
    DirectHandle<Code> code) {
  DCHECK(code->is_optimized_code());

  DisallowGarbageCollection no_gc;
  GlobalHandleVector<Map> maps(local_isolate_->heap());
  PtrComprCageBase cage_base(local_isolate_);
  int const mode_mask = RelocInfo::EmbeddedObjectModeMask();
  for (RelocIterator it(*code, mode_mask); !it.done(); it.next()) {
    DCHECK(RelocInfo::IsEmbeddedObjectMode(it.rinfo()->rmode()));
    Tagged<HeapObject> target_object = it.rinfo()->target_object(cage_base);
    if (code->IsWeakObjectInOptimizedCode(target_object)) {
      if (IsMap(target_object, cage_base)) {
        maps.Push(Cast<Map>(target_object));
      }
    }
  }
  return maps;
}

Handle<DeoptimizationData> MaglevCodeGenerator::GenerateDeoptimizationData(
    LocalIsolate* local_isolate) {
  int eager_deopt_count =
      static_cast<int>(code_gen_state_.eager_deopts().size());
  int lazy_deopt_count = static_cast<int>(code_gen_state_.lazy_deopts().size());
  int deopt_count = lazy_deopt_count + eager_deopt_count;
  if (deopt_count == 0 && !graph_->is_osr()) {
    return DeoptimizationData::Empty(local_isolate);
  }
  Handle<DeoptimizationData> data =
      DeoptimizationData::New(local_isolate, deopt_count);

  DirectHandle<DeoptimizationFrameTranslation> translations =
      frame_translation_builder_.ToFrameTranslation(local_isolate->factory());

  DirectHandle<SharedFunctionInfoWrapper> sfi_wrapper =
      local_isolate->factory()->NewSharedFunctionInfoWrapper(
          code_gen_state_.compilation_info()
              ->toplevel_compilation_unit()
              ->shared_function_info()
              .object());

  {
    DisallowGarbageCollection no_gc;
    Tagged<DeoptimizationData> raw_data = *data;

    raw_data->SetFrameTranslation(*translations);
    raw_data->SetInlinedFunctionCount(Smi::FromInt(inlined_function_count_));
    raw_data->SetOptimizationId(
        Smi::FromInt(local_isolate->NextOptimizationId()));

    DCHECK_NE(deopt_exit_start_offset_, -1);
    raw_data->SetDeoptExitStart(Smi::FromInt(deopt_exit_start_offset_));
    raw_data->SetEagerDeoptCount(Smi::FromInt(eager_deopt_count));
    raw_data->SetLazyDeoptCount(Smi::FromInt(lazy_deopt_count));
    raw_data->SetWrappedSharedFunctionInfo(*sfi_wrapper);
  }

  int inlined_functions_size =
      static_cast<int>(graph_->inlined_functions().size());
  DirectHandle<ProtectedDeoptimizationLiteralArray> protected_literals =
      local_isolate->factory()->NewProtectedFixedArray(
          protected_deopt_literals_.size());
  DirectHandle<DeoptimizationLiteralArray> literals =
      local_isolate->factory()->NewDeoptimizationLiteralArray(
          deopt_literals_.size());
  DirectHandle<TrustedPodArray<InliningPosition>> inlining_positions =
      TrustedPodArray<InliningPosition>::New(local_isolate,
                                             inlined_functions_size);

  DisallowGarbageCollection no_gc;

  Tagged<ProtectedDeoptimizationLiteralArray> raw_protected_literals =
      *protected_literals;
  {
    IdentityMap<int, base::DefaultAllocationPolicy>::IteratableScope iterate(
        &protected_deopt_literals_);
    for (auto it = iterate.begin(); it != iterate.end(); ++it) {
      raw_protected_literals->set(*it.entry(), Cast<TrustedObject>(it.key()));
    }
  }

  Tagged<DeoptimizationLiteralArray> raw_literals = *literals;
  {
    IdentityMap<int, base::DefaultAllocationPolicy>::IteratableScope iterate(
        &deopt_literals_);
    for (auto it = iterate.begin(); it != iterate.end(); ++it) {
      raw_literals->set(*it.entry(), it.key());
    }
  }

  for (int i = 0; i < inlined_functions_size; i++) {
    auto inlined_function_info = graph_->inlined_functions()[i];
    inlining_positions->set(i, inlined_function_info.position);
  }

  Tagged<DeoptimizationData> raw_data = *data;
  raw_data->SetProtectedLiteralArray(raw_protected_literals);
  raw_data->SetLiteralArray(raw_literals);
  raw_data->SetInliningPositions(*inlining_positions);

  auto info = code_gen_state_.compilation_info();
  raw_data->SetOsrBytecodeOffset(
      Smi::FromInt(info->toplevel_osr_offset().ToInt()));
  if (graph_->is_osr()) {
    raw_data->SetOsrPcOffset(Smi::FromInt(code_gen_state_.osr_entry()->pos()));
  } else {
    raw_data->SetOsrPcOffset(Smi::FromInt(-1));
  }

  // Populate deoptimization entries.
  int i = 0;
  for (EagerDeoptInfo* deopt_info : code_gen_state_.eager_deopts()) {
    DCHECK_NE(deopt_info->translation_index(), -1);
    raw_data->SetBytecodeOffset(i, GetBytecodeOffset(deopt_info->top_frame()));
    raw_data->SetTranslationIndex(
        i, Smi::FromInt(deopt_info->translation_index()));
    raw_data->SetPc(i, Smi::FromInt(deopt_info->deopt_entry_label()->pos()));
#ifdef DEBUG
    raw_data->SetNodeId(i, Smi::FromInt(i));
#endif  // DEBUG
    i++;
  }
  for (LazyDeoptInfo* deopt_info : code_gen_state_.lazy_deopts()) {
    DCHECK_NE(deopt_info->translation_index(), -1);
    raw_data->SetBytecodeOffset(i, GetBytecodeOffset(deopt_info->top_frame()));
    raw_data->SetTranslationIndex(
        i, Smi::FromInt(deopt_info->translation_index()));
    raw_data->SetPc(i, Smi::FromInt(deopt_info->deopt_entry_label()->pos()));
#ifdef DEBUG
    raw_data->SetNodeId(i, Smi::FromInt(i));
#endif  // DEBUG
    i++;
  }

#ifdef DEBUG
  raw_data->Verify(code_gen_state_.compilation_info()
                       ->toplevel_compilation_unit()
                       ->bytecode()
                       .object());
#endif

  return data;
}

}  // namespace maglev
}  // namespace internal
}  // namespace v8

"""


```