Response:
The user wants a summary of the functionality of the Python code provided. I need to go through the code and identify the main actions performed by the `NinjaBackend` class, especially focusing on aspects related to reverse engineering, binary/kernel interactions, logical deductions, potential user errors, and how a user's actions might lead to this code being executed.

Here's a breakdown of the code's functions:

1. **Prelinking:**  Handles a prelinking step, potentially to optimize linking time.
2. **Generating Link Commands:** The core function, responsible for constructing the linker command with various arguments based on the target type, dependencies, and build options.
3. **Shared Library Handling:** Specifically addresses shared libraries, including generating symbol files and aliases.
4. **Custom Target Cleaning:**  Manages cleaning outputs from custom build targets.
5. **Gcov Cleaning:** Handles cleaning files generated by the `gcov` coverage tool.
6. **User Options:** Retrieves and formats user-defined build options.
7. **Distribution:** Creates source packages for distribution.
8. **Static Analysis Tools:** Integrates with static analysis tools like `scan-build`, `clang-format`, and `clang-tidy`.
9. **Tag Generation:** Supports generating tags files for code navigation (e.g., `etags`, `ctags`).
10. **Utility Commands:**  Provides an 'uninstall' command.
11. **Finalizing Build Targets:**  Defines the 'all' target and manages dependencies for building everything.
12. **Cleaning:** Implements the 'clean' target to remove build artifacts.
13. **Regeneration:** Sets up the rule for regenerating the `build.ninja` file.
14. **Introspection Data:**  Provides data for introspection purposes, likely for IDE integration.
15. **Fortran Dependency Scanning:** A separate helper function to scan Fortran source files for dependencies.
这是 `fridaDynamic` instrumentation tool的构建系统中负责生成 Ninja 构建文件的后端模块。它将 Meson 构建系统的抽象描述转换为 Ninja 构建工具能够理解的指令。以下是其功能的详细说明：

**主要功能归纳：**

该模块的主要功能是将 Frida 的构建描述转化为 Ninja 构建系统的指令，以便 Ninja 可以执行实际的编译、链接等构建步骤。它涵盖了编译、链接、清理、测试、打包等多个方面，并针对特定平台和工具进行了适配。

**详细功能列表：**

1. **预链接 (Prelinking):**
    *   生成用于预链接目标文件的 Ninja 指令。
    *   预链接是一种优化技术，可以减少最终链接时间，特别是在大型项目中。
    *   **与逆向的关系：**  预链接本身与逆向没有直接关系。但是，如果逆向工程师想要重新编译 Frida 或其组件，了解构建过程是有帮助的。
    *   **二进制底层知识：**  涉及到目标文件 (`.o`) 的处理，以及链接器的工作原理。

2. **生成链接命令 (generate\_link):**
    *   这是核心功能，负责生成将目标文件链接成可执行文件、共享库或静态库的 Ninja 指令。
    *   它会根据目标类型（静态库、共享库、模块等）、编译器、链接器选项、依赖关系等生成复杂的链接命令。
    *   **与逆向的关系：**  理解链接过程对于逆向工程至关重要。逆向工程师需要知道可执行文件和库是如何组合在一起的，以及符号是如何解析的。
        *   **举例：** 查看生成的链接命令可以了解链接器使用了哪些库 (`-l`) 和库路径 (`-L`)，这对于分析程序依赖项非常重要。
    *   **二进制底层，linux, android内核及框架知识：**
        *   处理不同类型的输出文件（可执行文件、`.so`、`.a`）。
        *   处理运行时路径 (rpath) 的设置，这在 Linux 和 Android 中用于指定动态链接器查找共享库的路径。
        *   处理符号可见性（通过 `generate_shsym` 函数，虽然代码片段中没有完整展示）。
        *   理解静态库和共享库的链接差异。
    *   **逻辑推理：**
        *   根据目标类型选择不同的链接器规则 (`STATIC_LINKER`, `CXX_LINKER` 等)。
        *   根据是否启用调试选项来添加调试符号相关的链接参数 (`-g`, `/DEBUG`, `.pdb` 文件生成等)。
        *   根据目标依赖关系和链接类型（`link_with`）决定链接哪些库。
        *   处理项目级和全局链接参数的优先级。
    *   **假设输入与输出：**
        *   **假设输入：** 一个需要链接的共享库目标 `mylib.so`，依赖于 `libcrypto.so` 和 `libssl.so`。
        *   **输出：** 生成的 Ninja 构建规则中，`LINK_ARGS` 可能会包含 `-lcrypto -lssl` 以及相应的库路径 `-L/path/to/crypto -L/path/to/ssl`。
    *   **用户错误：** 如果用户在 `meson.build` 中错误地指定了链接依赖项或链接参数，可能会导致链接命令不正确，最终导致链接失败。例如，拼写错误的库名或错误的库路径。

3. **生成共享库别名 (generate\_shlib\_aliases):**
    *   为共享库生成别名（符号链接）。这通常用于处理库的版本管理。
    *   **与逆向的关系：**  共享库的版本管理对于逆向分析非常重要，因为不同的版本可能具有不同的符号和行为。
    *   **linux知识：** 涉及到 Linux 系统中共享库的版本命名约定和符号链接的使用。

4. **生成自定义目标清理命令 (generate\_custom\_target\_clean):**
    *   生成清理自定义目标输出的 Ninja 指令。自定义目标是由用户定义的构建步骤。
    *   **与逆向的关系：**  如果自定义目标生成了逆向分析所需的文件（例如，反汇编输出），那么清理这些文件可能会影响逆向工作流程。

5. **生成 Gcov 清理命令 (generate\_gcov\_clean):**
    *   生成用于删除 `gcov` 代码覆盖率工具生成的文件 (`.gcno`, `.gcda`) 的 Ninja 指令。
    *   **与逆向的关系：**  代码覆盖率信息可以帮助逆向工程师理解代码的执行路径。

6. **获取用户选项参数 (get\_user\_option\_args):**
    *   获取用户在 Meson 配置时指定的选项，并将它们格式化为命令行参数。
    *   **与逆向的关系：**  用户选项可能会影响 Frida 的构建方式，例如启用或禁用某些功能，这可能会影响逆向工程师分析的特定组件。

7. **生成分发包 (generate\_dist):**
    *   生成创建源代码分发包的 Ninja 指令。

8. **生成静态分析工具命令 (generate\_scanbuild, generate\_clangformat, generate\_clangtidy):**
    *   集成静态代码分析工具，如 `scan-build`、`clang-format` 和 `clang-tidy`。
    *   生成运行这些工具的 Ninja 指令。
    *   **与逆向的关系：**  静态分析工具可以帮助发现代码中的潜在错误和安全漏洞，这些信息可能对逆向工程师有价值。

9. **生成标签文件命令 (generate\_tags):**
    *   生成用于创建代码标签文件（例如，用于 `etags`、`ctags`）的 Ninja 指令，方便代码导航。
    *   **与逆向的关系：**  标签文件可以帮助逆向工程师在源代码中快速查找定义和引用。

10. **生成通用工具命令 (generate\_utils):**
    *   包含了一些常用的工具命令，例如 `uninstall`。

11. **生成构建结束目标 (generate\_ending):**
    *   生成构建过程结束时需要执行的 Ninja 指令，例如定义 `all` 目标（构建所有内容）和 `clean` 目标（清理构建产物）。
    *   **与逆向的关系：**  `clean` 目标会删除之前编译的二进制文件，逆向工程师可能需要重新构建才能进行分析。

12. **获取自省数据 (get\_introspection\_data):**
    *   提供用于代码自省的数据，这些数据可以被 IDE 或其他工具使用，以了解构建目标的信息。

13. **扫描 Fortran 文件依赖 ( \_scan\_fortran\_file\_deps ):**
    *   一个独立的辅助函数，用于扫描 Fortran 源代码文件以查找模块和包含文件的依赖关系。
    *   **与逆向的关系：** 如果 Frida 的某些部分是用 Fortran 编写的，理解其依赖关系对于理解其构建过程至关重要。

**用户操作如何一步步的到达这里 (作为调试线索):**

1. **用户下载或克隆 Frida 源代码。**
2. **用户在 Frida 源代码根目录下执行 `meson setup <build_directory>` 命令。**  Meson 会读取 `meson.build` 文件，解析构建描述。
3. **Meson 根据 `meson.build` 中的定义，确定需要构建的目标（例如，共享库、可执行文件）。**
4. **对于每个需要构建的目标，Meson 会调用相应的后端模块，在这个例子中是 `ninjabackend.py`。**
5. **`ninjabackend.py` 中的函数（例如 `generate_link`）会被调用，根据目标类型、依赖关系和构建选项生成 Ninja 构建文件的内容。**
6. **Meson 将生成的 Ninja 构建文件 (`build.ninja`) 写入构建目录。**
7. **用户在构建目录下执行 `ninja` 命令。**
8. **Ninja 读取 `build.ninja` 文件，并按照其中的指令执行编译、链接等构建步骤。**

**涉及到用户或编程常见的使用错误：**

*   **在 `meson.build` 文件中错误的指定链接库名称或路径：**  这会导致 `generate_link` 函数生成错误的链接命令，Ninja 执行时会报错，提示找不到指定的库。
*   **自定义目标中的命令错误：** 如果用户定义的自定义目标中的命令不正确，`generate_custom_target_clean` 生成的清理命令也会出错。
*   **Fortran 依赖声明错误：**  在 Fortran 代码中 `use` 或 `submodule` 语句引用的模块或子模块不存在或命名错误，`_scan_fortran_file_deps` 函数会抛出异常。

总而言之，`ninjabackend.py` 是 Frida 构建系统的关键组成部分，它负责将高级的构建描述转换为底层的构建指令，使得实际的编译和链接过程可以顺利进行。它涉及到编译器、链接器、操作系统、构建工具等多个方面的知识，对于理解 Frida 的构建过程和排查构建问题至关重要。

### 提示词
```
这是目录为frida/subprojects/frida-swift/releng/meson/mesonbuild/backend/ninjabackend.py的fridaDynamic instrumentation tool的源代码文件， 请列举一下它的功能, 
如果它与逆向的方法有关系，请做出对应的举例说明，
如果涉及到二进制底层，linux, android内核及框架的知识，请做出对应的举例说明，
如果做了逻辑推理，请给出假设输入与输出,
如果涉及用户或者编程常见的使用错误，请举例说明,
说明用户操作是如何一步步的到达这里，作为调试线索。
这是第6部分，共6部分，请归纳一下它的功能
```

### 源代码
```python
[:]
        cmd += prelinker.get_prelink_args(prelink_name, obj_list)

        cmd = self.replace_paths(target, cmd)
        elem.add_item('COMMAND', cmd)
        elem.add_item('description', f'Prelinking {prelink_name}.')
        self.add_build(elem)
        return [prelink_name]

    def generate_link(self, target: build.BuildTarget, outname, obj_list, linker: T.Union['Compiler', 'StaticLinker'], extra_args=None, stdlib_args=None):
        extra_args = extra_args if extra_args is not None else []
        stdlib_args = stdlib_args if stdlib_args is not None else []
        implicit_outs = []
        if isinstance(target, build.StaticLibrary):
            linker_base = 'STATIC'
        else:
            linker_base = linker.get_language() # Fixme.
        if isinstance(target, build.SharedLibrary):
            self.generate_shsym(target)
        crstr = self.get_rule_suffix(target.for_machine)
        linker_rule = linker_base + '_LINKER' + crstr
        # Create an empty commands list, and start adding link arguments from
        # various sources in the order in which they must override each other
        # starting from hard-coded defaults followed by build options and so on.
        #
        # Once all the linker options have been passed, we will start passing
        # libraries and library paths from internal and external sources.
        commands = linker.compiler_args()
        # First, the trivial ones that are impossible to override.
        #
        # Add linker args for linking this target derived from 'base' build
        # options passed on the command-line, in default_options, etc.
        # These have the lowest priority.
        if isinstance(target, build.StaticLibrary):
            commands += linker.get_base_link_args(target.get_options())
        else:
            commands += compilers.get_base_link_args(target.get_options(),
                                                     linker,
                                                     isinstance(target, build.SharedModule),
                                                     self.environment.get_build_dir())
        # Add -nostdlib if needed; can't be overridden
        commands += self.get_no_stdlib_link_args(target, linker)
        # Add things like /NOLOGO; usually can't be overridden
        commands += linker.get_linker_always_args()
        # Add buildtype linker args: optimization level, etc.
        commands += linker.get_optimization_link_args(target.get_option(OptionKey('optimization')))
        # Add /DEBUG and the pdb filename when using MSVC
        if target.get_option(OptionKey('debug')):
            commands += self.get_link_debugfile_args(linker, target)
            debugfile = self.get_link_debugfile_name(linker, target)
            if debugfile is not None:
                implicit_outs += [debugfile]
        # Add link args specific to this BuildTarget type, such as soname args,
        # PIC, import library generation, etc.
        commands += self.get_target_type_link_args(target, linker)
        # Archives that are copied wholesale in the result. Must be before any
        # other link targets so missing symbols from whole archives are found in those.
        if not isinstance(target, build.StaticLibrary):
            commands += self.get_link_whole_args(linker, target)

        if not isinstance(target, build.StaticLibrary):
            # Add link args added using add_project_link_arguments()
            commands += self.build.get_project_link_args(linker, target.subproject, target.for_machine)
            # Add link args added using add_global_link_arguments()
            # These override per-project link arguments
            commands += self.build.get_global_link_args(linker, target.for_machine)
            # Link args added from the env: LDFLAGS. We want these to override
            # all the defaults but not the per-target link args.
            commands += self.environment.coredata.get_external_link_args(target.for_machine, linker.get_language())

        # Now we will add libraries and library paths from various sources

        # Set runtime-paths so we can run executables without needing to set
        # LD_LIBRARY_PATH, etc in the environment. Doesn't work on Windows.
        if has_path_sep(target.name):
            # Target names really should not have slashes in them, but
            # unfortunately we did not check for that and some downstream projects
            # now have them. Once slashes are forbidden, remove this bit.
            target_slashname_workaround_dir = os.path.join(
                os.path.dirname(target.name),
                self.get_target_dir(target))
        else:
            target_slashname_workaround_dir = self.get_target_dir(target)
        (rpath_args, target.rpath_dirs_to_remove) = (
            linker.build_rpath_args(self.environment,
                                    self.environment.get_build_dir(),
                                    target_slashname_workaround_dir,
                                    self.determine_rpath_dirs(target),
                                    target.build_rpath,
                                    target.install_rpath))
        commands += rpath_args

        # Add link args to link to all internal libraries (link_with:) and
        # internal dependencies needed by this target.
        if linker_base == 'STATIC':
            # Link arguments of static libraries are not put in the command
            # line of the library. They are instead appended to the command
            # line where the static library is used.
            dependencies = []
        else:
            dependencies = target.get_dependencies()
        internal = self.build_target_link_arguments(linker, dependencies)
        commands += internal
        # Only non-static built targets need link args and link dependencies
        if not isinstance(target, build.StaticLibrary):
            # For 'automagic' deps: Boost and GTest. Also dependency('threads').
            # pkg-config puts the thread flags itself via `Cflags:`

            commands += linker.get_target_link_args(target)
            # External deps must be last because target link libraries may depend on them.
            for dep in target.get_external_deps():
                # Extend without reordering or de-dup to preserve `-L -l` sets
                # https://github.com/mesonbuild/meson/issues/1718
                commands.extend_preserving_lflags(linker.get_dependency_link_args(dep))
            for d in target.get_dependencies():
                if isinstance(d, build.StaticLibrary):
                    for dep in d.get_external_deps():
                        commands.extend_preserving_lflags(linker.get_dependency_link_args(dep))

        # Add link args specific to this BuildTarget type that must not be overridden by dependencies
        commands += self.get_target_type_link_args_post_dependencies(target, linker)

        # Add link args for c_* or cpp_* build options. Currently this only
        # adds c_winlibs and cpp_winlibs when building for Windows. This needs
        # to be after all internal and external libraries so that unresolved
        # symbols from those can be found here. This is needed when the
        # *_winlibs that we want to link to are static mingw64 libraries.
        if isinstance(linker, Compiler):
            # The static linker doesn't know what language it is building, so we
            # don't know what option. Fortunately, it doesn't care to see the
            # language-specific options either.
            #
            # We shouldn't check whether we are making a static library, because
            # in the LTO case we do use a real compiler here.
            commands += linker.get_option_link_args(target.get_options())

        dep_targets = []
        dep_targets.extend(self.guess_external_link_dependencies(linker, target, commands, internal))

        # Add libraries generated by custom targets
        custom_target_libraries = self.get_custom_target_provided_libraries(target)
        commands += extra_args
        commands += custom_target_libraries
        commands += stdlib_args # Standard library arguments go last, because they never depend on anything.
        dep_targets.extend([self.get_dependency_filename(t) for t in dependencies])
        dep_targets.extend([self.get_dependency_filename(t)
                            for t in target.link_depends])
        elem = NinjaBuildElement(self.all_outputs, outname, linker_rule, obj_list, implicit_outs=implicit_outs)
        elem.add_dep(dep_targets + custom_target_libraries)
        elem.add_item('LINK_ARGS', commands)
        self.create_target_linker_introspection(target, linker, commands)
        return elem

    def get_dependency_filename(self, t):
        if isinstance(t, build.SharedLibrary):
            return self.get_target_shsym_filename(t)
        elif isinstance(t, mesonlib.File):
            if t.is_built:
                return t.relative_name()
            else:
                return t.absolute_path(self.environment.get_source_dir(),
                                       self.environment.get_build_dir())
        return self.get_target_filename(t)

    def generate_shlib_aliases(self, target, outdir):
        for alias, to, tag in target.get_aliases():
            aliasfile = os.path.join(outdir, alias)
            abs_aliasfile = os.path.join(self.environment.get_build_dir(), outdir, alias)
            try:
                os.remove(abs_aliasfile)
            except Exception:
                pass
            try:
                os.symlink(to, abs_aliasfile)
            except NotImplementedError:
                mlog.debug("Library versioning disabled because symlinks are not supported.")
            except OSError:
                mlog.debug("Library versioning disabled because we do not have symlink creation privileges.")
            else:
                self.implicit_meson_outs.append(aliasfile)

    def generate_custom_target_clean(self, trees: T.List[str]) -> str:
        e = self.create_phony_target('clean-ctlist', 'CUSTOM_COMMAND', 'PHONY')
        d = CleanTrees(self.environment.get_build_dir(), trees)
        d_file = os.path.join(self.environment.get_scratch_dir(), 'cleantrees.dat')
        e.add_item('COMMAND', self.environment.get_build_command() + ['--internal', 'cleantrees', d_file])
        e.add_item('description', 'Cleaning custom target directories')
        self.add_build(e)
        # Write out the data file passed to the script
        with open(d_file, 'wb') as ofile:
            pickle.dump(d, ofile)
        return 'clean-ctlist'

    def generate_gcov_clean(self) -> None:
        gcno_elem = self.create_phony_target('clean-gcno', 'CUSTOM_COMMAND', 'PHONY')
        gcno_elem.add_item('COMMAND', mesonlib.get_meson_command() + ['--internal', 'delwithsuffix', '.', 'gcno'])
        gcno_elem.add_item('description', 'Deleting gcno files')
        self.add_build(gcno_elem)

        gcda_elem = self.create_phony_target('clean-gcda', 'CUSTOM_COMMAND', 'PHONY')
        gcda_elem.add_item('COMMAND', mesonlib.get_meson_command() + ['--internal', 'delwithsuffix', '.', 'gcda'])
        gcda_elem.add_item('description', 'Deleting gcda files')
        self.add_build(gcda_elem)

    def get_user_option_args(self):
        cmds = []
        for (k, v) in self.environment.coredata.options.items():
            if k.is_project():
                cmds.append('-D' + str(k) + '=' + (v.value if isinstance(v.value, str) else str(v.value).lower()))
        # The order of these arguments must be the same between runs of Meson
        # to ensure reproducible output. The order we pass them shouldn't
        # affect behavior in any other way.
        return sorted(cmds)

    def generate_dist(self) -> None:
        elem = self.create_phony_target('dist', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('DESC', 'Creating source packages')
        elem.add_item('COMMAND', self.environment.get_build_command() + ['dist'])
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_scanbuild(self) -> None:
        if not environment.detect_scanbuild():
            return
        if 'scan-build' in self.all_outputs:
            return
        cmd = self.environment.get_build_command() + \
            ['--internal', 'scanbuild', self.environment.source_dir, self.environment.build_dir, self.build.get_subproject_dir()] + \
            self.environment.get_build_command() + ['setup'] + self.get_user_option_args()
        elem = self.create_phony_target('scan-build', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_clangtool(self, name: str, extra_arg: T.Optional[str] = None) -> None:
        target_name = 'clang-' + name
        extra_args = []
        if extra_arg:
            target_name += f'-{extra_arg}'
            extra_args.append(f'--{extra_arg}')
        if not os.path.exists(os.path.join(self.environment.source_dir, '.clang-' + name)) and \
                not os.path.exists(os.path.join(self.environment.source_dir, '_clang-' + name)):
            return
        if target_name in self.all_outputs:
            return
        cmd = self.environment.get_build_command() + \
            ['--internal', 'clang' + name, self.environment.source_dir, self.environment.build_dir] + \
            extra_args
        elem = self.create_phony_target(target_name, 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_clangformat(self) -> None:
        if not environment.detect_clangformat():
            return
        self.generate_clangtool('format')
        self.generate_clangtool('format', 'check')

    def generate_clangtidy(self) -> None:
        import shutil
        if not shutil.which('clang-tidy'):
            return
        self.generate_clangtool('tidy')
        self.generate_clangtool('tidy', 'fix')

    def generate_tags(self, tool: str, target_name: str) -> None:
        import shutil
        if not shutil.which(tool):
            return
        if target_name in self.all_outputs:
            return
        cmd = self.environment.get_build_command() + \
            ['--internal', 'tags', tool, self.environment.source_dir]
        elem = self.create_phony_target(target_name, 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    # For things like scan-build and other helper tools we might have.
    def generate_utils(self) -> None:
        self.generate_scanbuild()
        self.generate_clangformat()
        self.generate_clangtidy()
        self.generate_tags('etags', 'TAGS')
        self.generate_tags('ctags', 'ctags')
        self.generate_tags('cscope', 'cscope')
        cmd = self.environment.get_build_command() + ['--internal', 'uninstall']
        elem = self.create_phony_target('uninstall', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_ending(self) -> None:
        for targ, deps in [
                ('all', self.get_build_by_default_targets()),
                ('meson-test-prereq', self.get_testlike_targets()),
                ('meson-benchmark-prereq', self.get_testlike_targets(True))]:
            targetlist = []
            # These must also be built by default.
            # XXX: Sometime in the future these should be built only before running tests.
            if targ == 'all':
                targetlist.extend(['meson-test-prereq', 'meson-benchmark-prereq'])
            for t in deps.values():
                # Add the first output of each target to the 'all' target so that
                # they are all built
                #Add archive file if shared library in AIX for build all.
                if isinstance(t, build.SharedLibrary) and t.aix_so_archive:
                    if self.environment.machines[t.for_machine].is_aix():
                        linker, stdlib_args = self.determine_linker_and_stdlib_args(t)
                        t.get_outputs()[0] = linker.get_archive_name(t.get_outputs()[0])
                targetlist.append(os.path.join(self.get_target_dir(t), t.get_outputs()[0]))

            elem = NinjaBuildElement(self.all_outputs, targ, 'phony', targetlist)
            self.add_build(elem)

        elem = self.create_phony_target('clean', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', self.ninja_command + ['-t', 'clean'])
        elem.add_item('description', 'Cleaning')

        # If we have custom targets in this project, add all their outputs to
        # the list that is passed to the `cleantrees.py` script. The script
        # will manually delete all custom_target outputs that are directories
        # instead of files. This is needed because on platforms other than
        # Windows, Ninja only deletes directories while cleaning if they are
        # empty. https://github.com/mesonbuild/meson/issues/1220
        ctlist = []
        for t in self.build.get_targets().values():
            if isinstance(t, build.CustomTarget):
                # Create a list of all custom target outputs
                for o in t.get_outputs():
                    ctlist.append(os.path.join(self.get_target_dir(t), o))
        if ctlist:
            elem.add_dep(self.generate_custom_target_clean(ctlist))

        if OptionKey('b_coverage') in self.environment.coredata.options and \
           self.environment.coredata.options[OptionKey('b_coverage')].value:
            self.generate_gcov_clean()
            elem.add_dep('clean-gcda')
            elem.add_dep('clean-gcno')
        self.add_build(elem)

        deps = self.get_regen_filelist()
        elem = NinjaBuildElement(self.all_outputs, 'build.ninja', 'REGENERATE_BUILD', deps)
        elem.add_item('pool', 'console')
        self.add_build(elem)

        # If these files used to be explicitly created, they need to appear on the build graph somehow,
        # otherwise cleandead deletes them. See https://github.com/ninja-build/ninja/issues/2299
        if self.implicit_meson_outs:
            elem = NinjaBuildElement(self.all_outputs, 'meson-implicit-outs', 'phony', self.implicit_meson_outs)
            self.add_build(elem)

        elem = NinjaBuildElement(self.all_outputs, 'reconfigure', 'REGENERATE_BUILD', 'PHONY')
        elem.add_item('pool', 'console')
        self.add_build(elem)

        elem = NinjaBuildElement(self.all_outputs, deps, 'phony', '')
        self.add_build(elem)

    def get_introspection_data(self, target_id: str, target: build.Target) -> T.List[T.Dict[str, T.Union[bool, str, T.List[T.Union[str, T.Dict[str, T.Union[str, T.List[str], bool]]]]]]]:
        data = self.introspection_data.get(target_id)
        if not data:
            return super().get_introspection_data(target_id, target)

        return list(data.values())


def _scan_fortran_file_deps(src: Path, srcdir: Path, dirname: Path, tdeps, compiler) -> T.List[str]:
    """
    scan a Fortran file for dependencies. Needs to be distinct from target
    to allow for recursion induced by `include` statements.er

    It makes a number of assumptions, including

    * `use`, `module`, `submodule` name is not on a continuation line

    Regex
    -----

    * `incre` works for `#include "foo.f90"` and `include "foo.f90"`
    * `usere` works for legacy and Fortran 2003 `use` statements
    * `submodre` is for Fortran >= 2008 `submodule`
    """

    incre = re.compile(FORTRAN_INCLUDE_PAT, re.IGNORECASE)
    usere = re.compile(FORTRAN_USE_PAT, re.IGNORECASE)
    submodre = re.compile(FORTRAN_SUBMOD_PAT, re.IGNORECASE)

    mod_files = []
    src = Path(src)
    with src.open(encoding='ascii', errors='ignore') as f:
        for line in f:
            # included files
            incmatch = incre.match(line)
            if incmatch is not None:
                incfile = src.parent / incmatch.group(1)
                # NOTE: src.parent is most general, in particular for CMake subproject with Fortran file
                # having an `include 'foo.f'` statement.
                if incfile.suffix.lower()[1:] in compiler.file_suffixes:
                    mod_files.extend(_scan_fortran_file_deps(incfile, srcdir, dirname, tdeps, compiler))
            # modules
            usematch = usere.match(line)
            if usematch is not None:
                usename = usematch.group(1).lower()
                if usename == 'intrinsic':  # this keeps the regex simpler
                    continue
                if usename not in tdeps:
                    # The module is not provided by any source file. This
                    # is due to:
                    #   a) missing file/typo/etc
                    #   b) using a module provided by the compiler, such as
                    #      OpenMP
                    # There's no easy way to tell which is which (that I
                    # know of) so just ignore this and go on. Ideally we
                    # would print a warning message to the user but this is
                    # a common occurrence, which would lead to lots of
                    # distracting noise.
                    continue
                srcfile = srcdir / tdeps[usename].fname
                if not srcfile.is_file():
                    if srcfile.name != src.name:  # generated source file
                        pass
                    else:  # subproject
                        continue
                elif srcfile.samefile(src):  # self-reference
                    continue

                mod_name = compiler.module_name_to_filename(usename)
                mod_files.append(str(dirname / mod_name))
            else:  # submodules
                submodmatch = submodre.match(line)
                if submodmatch is not None:
                    parents = submodmatch.group(1).lower().split(':')
                    assert len(parents) in {1, 2}, (
                        'submodule ancestry must be specified as'
                        f' ancestor:parent but Meson found {parents}')

                    ancestor_child = '_'.join(parents)
                    if ancestor_child not in tdeps:
                        raise MesonException("submodule {} relies on ancestor module {} that was not found.".format(submodmatch.group(2).lower(), ancestor_child.split('_', maxsplit=1)[0]))
                    submodsrcfile = srcdir / tdeps[ancestor_child].fname
                    if not submodsrcfile.is_file():
                        if submodsrcfile.name != src.name:  # generated source file
                            pass
                        else:  # subproject
                            continue
                    elif submodsrcfile.samefile(src):  # self-reference
                        continue
                    mod_name = compiler.module_name_to_filename(ancestor_child)
                    mod_files.append(str(dirname / mod_name))
    return mod_files
```