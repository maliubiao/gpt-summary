Response:
The user wants a summary of the functionalities of the provided Python script `deps.py`. I need to go through the code and identify the main actions it performs. Specifically, the prompt asks for:

1. **Functionalities:** A list of what the script does.
2. **Relevance to Reverse Engineering:**  Explain how the script's actions are related to reverse engineering, providing examples.
3. **Binary/Kernel/Framework Knowledge:** Highlight sections that deal with low-level concepts, OS kernels (Linux, Android), and frameworks.
4. **Logical Inferences:**  Identify any parts of the code that perform logical reasoning and provide example inputs and outputs.
5. **Common User Errors:** Point out potential mistakes users might make when using the script, with examples.
6. **User Steps to Reach Here:** Describe how a user would interact with Frida to end up running this script.
7. **Overall Summary of Functionality:** A concise summary of the script's purpose.

Based on the code, the script seems to manage dependencies for the Frida project. It handles downloading, building, and packaging these dependencies for different operating systems and architectures.
è¿™æ˜¯ frida é¡¹ç›®ä¸­è´Ÿè´£ç®¡ç†ä¾èµ–é¡¹çš„è„šæœ¬ `deps.py`ã€‚å…¶ä¸»è¦åŠŸèƒ½æ˜¯ç¡®ä¿ Frida Swift ç»„ä»¶çš„æ„å»ºå’Œè¿è¡Œæ‰€éœ€çš„é¢„æ„å»ºä¾èµ–é¡¹æ˜¯æœ€æ–°çš„ã€‚ä»¥ä¸‹æ˜¯å…¶åŠŸèƒ½çš„è¯¦ç»†å½’çº³ï¼š

**ä¸»è¦åŠŸèƒ½å½’çº³ï¼š**

1. **åŒæ­¥é¢„æ„å»ºä¾èµ– (sync):**
    *   ä¸‹è½½æˆ–éƒ¨ç½²æŒ‡å®š `bundle`ï¼ˆå¦‚ SDK æˆ–å·¥å…·é“¾ï¼‰çš„é¢„æ„å»ºä¾èµ–é¡¹åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿã€‚
    *   æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²å­˜åœ¨æŒ‡å®šç‰ˆæœ¬çš„ä¾èµ–é¡¹ï¼Œå¦‚æœå­˜åœ¨åˆ™è·³è¿‡ä¸‹è½½ã€‚
    *   å¦‚æœæœ¬åœ°å­˜åœ¨æ—§ç‰ˆæœ¬æˆ–ä¸å­˜åœ¨ï¼Œåˆ™åˆ é™¤æ—§ç‰ˆæœ¬å¹¶ä¸‹è½½æ–°ç‰ˆæœ¬ã€‚
    *   æ”¯æŒä»æœ¬åœ°æ–‡ä»¶éƒ¨ç½²ä¾èµ–é¡¹ï¼Œå¦‚æœæœ¬åœ°å­˜åœ¨å¯¹åº”çš„å‹ç¼©åŒ…ã€‚
    *   ä¸‹è½½çš„ä¾èµ–é¡¹ä¼šè¢«è§£å‹åˆ°æŒ‡å®šçš„ `location`ã€‚
    *   å¯¹è§£å‹åçš„æ–‡ä»¶è¿›è¡Œåå¤„ç†ï¼Œæ›¿æ¢ç¡¬ç¼–ç çš„è·¯å¾„ `@FRIDA_TOOLROOT@` ä¸ºå®é™…è·¯å¾„ã€‚

2. **æ„å»ºå’Œä¸Šä¼ é¢„æ„å»ºä¾èµ– (roll):**
    *   æ£€æŸ¥æŒ‡å®š `bundle` å’Œ `host` æ“ä½œç³»ç»Ÿçš„é¢„æ„å»ºä¾èµ–é¡¹æ˜¯å¦å·²ä¸Šä¼ åˆ° S3 å­˜å‚¨ã€‚
    *   å¦‚æœ S3 ä¸Šä¸å­˜åœ¨ï¼Œåˆ™è§¦å‘æœ¬åœ°æ„å»ºè¿‡ç¨‹ (é€šè¿‡ `build` å‘½ä»¤)ã€‚
    *   ï¼ˆå¯é€‰ï¼‰åœ¨æ„å»ºå®Œæˆåæ‰§è¡Œç”¨æˆ·æä¾›çš„åå¤„ç†è„šæœ¬ã€‚
    *   å°†æ„å»ºå¥½çš„ä¾èµ–é¡¹ä¸Šä¼ åˆ° S3 å­˜å‚¨ã€‚
    *   æ¸…é™¤ CDN ç¼“å­˜ï¼Œä½¿æ–°çš„ä¾èµ–é¡¹ç”Ÿæ•ˆã€‚
    *   å¯ä»¥æ¿€æ´»ï¼ˆconfigureï¼‰ç‰¹å®šç‰ˆæœ¬çš„ bootstrapï¼Œç”¨äº SDK å’Œå·¥å…·é“¾ã€‚

3. **æœ¬åœ°æ„å»ºé¢„æ„å»ºä¾èµ– (build):**
    *   åœ¨æœ¬åœ°æ„å»ºæŒ‡å®š `bundle` çš„é¢„æ„å»ºä¾èµ–é¡¹ã€‚
    *   æ”¯æŒæŒ‡å®šæ„å»ºæœºå™¨ (`build`) å’Œç›®æ ‡æœºå™¨ (`host`)ã€‚
    *   å¯ä»¥é€‰æ‹©åªæ„å»ºç‰¹å®šçš„åŒ… (`only`) æˆ–æ’é™¤æŸäº›åŒ… (`exclude`)ã€‚
    *   æ„å»ºè¿‡ç¨‹åŒ…æ‹¬ï¼š
        *   å‡†å¤‡æ„å»ºç¯å¢ƒï¼ŒåŒ…æ‹¬å·¥å…·é“¾ã€‚
        *   å…‹éš†æˆ–æ›´æ–°ä¾èµ–åŒ…çš„ä»£ç ä»“åº“ã€‚
        *   ä¸ºç›®æ ‡æœºå™¨æ„å»ºä¾èµ–åŒ…ã€‚
        *   å°†æ„å»ºäº§ç‰©æ‰“åŒ…ã€‚
    *   æä¾› verbose é€‰é¡¹ä»¥æ˜¾ç¤ºæ›´è¯¦ç»†çš„æ„å»ºè¾“å‡ºã€‚

4. **ç­‰å¾…é¢„æ„å»ºä¾èµ– (wait):**
    *   è¿™ä¸ªåŠŸèƒ½æ¯”è¾ƒç®€å•ï¼Œä¼¼ä¹åªæ˜¯ä¸ºäº†ç­‰å¾…ç‰¹å®šçš„é¢„æ„å»ºä¾èµ–å°±ç»ªã€‚ä»ä»£ç æ¥çœ‹ï¼Œå®ƒç›®å‰åªæ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œå¹¶æ²¡æœ‰å®é™…çš„å®ç°é€»è¾‘ï¼Œè°ƒç”¨åä¼šç«‹å³è¿”å›ã€‚

5. **æ›´æ–°ä¾èµ–ç‰ˆæœ¬ (bump):**
    *   è¿™ä¸ªåŠŸèƒ½ä¹Ÿåªæ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œè¡¨æ˜æœªæ¥å¯èƒ½ä¼šå®ç°æ›´æ–°ä¾èµ–é¡¹ç‰ˆæœ¬çš„åŠŸèƒ½ã€‚

**ä¸é€†å‘æ–¹æ³•çš„å…³è”åŠä¸¾ä¾‹è¯´æ˜ï¼š**

*   **Frida æœ¬èº«æ˜¯é€†å‘å·¥å…·çš„åŸºç¡€:** `deps.py` è´Ÿè´£ç®¡ç† Frida Swift ç»„ä»¶çš„ä¾èµ–ï¼Œè€Œ Frida æ˜¯ä¸€ä¸ªåŠ¨æ€ä»£ç æ’æ¡©å·¥å…·ï¼Œå¹¿æ³›åº”ç”¨äºé€†å‘å·¥ç¨‹ã€å®‰å…¨ç ”ç©¶å’Œæ¼æ´åˆ†æç­‰é¢†åŸŸã€‚å› æ­¤ï¼Œç»´æŠ¤ Frida çš„ä¾èµ–é¡¹ç›´æ¥å…³ç³»åˆ°é€†å‘å·¥å…·çš„æ­£å¸¸è¿è¡Œã€‚
*   **ç›®æ ‡å¹³å°ä¾èµ–é¡¹:** é€†å‘åˆ†æé€šå¸¸éœ€è¦é’ˆå¯¹ç‰¹å®šçš„ç›®æ ‡å¹³å°ï¼ˆå¦‚ Androidã€iOSã€Linuxã€Windowsï¼‰è¿›è¡Œï¼Œ`deps.py` èƒ½å¤Ÿä¸ºä¸åŒçš„æ“ä½œç³»ç»Ÿå’Œæ¶æ„æ„å»ºå’ŒåŒæ­¥ä¾èµ–é¡¹ï¼Œç¡®ä¿ Frida åœ¨è¿™äº›å¹³å°ä¸Šèƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚ä¾‹å¦‚ï¼Œå¦‚æœè¦é€†å‘åˆ†æä¸€ä¸ª Android åº”ç”¨ï¼Œ`deps.py` ä¼šè´Ÿè´£ä¸‹è½½æˆ–æ„å»ºé€‚ç”¨äº Android å¹³å°çš„ Frida SDK å’Œç›¸å…³ä¾èµ–ã€‚
*   **å·¥å…·é“¾ä¾èµ–:** é€†å‘å·¥ç¨‹ä¸­ç»å¸¸éœ€è¦ä½¿ç”¨å„ç§å·¥å…·é“¾ï¼ˆä¾‹å¦‚ç¼–è¯‘å™¨ã€é“¾æ¥å™¨ã€è°ƒè¯•å™¨ï¼‰æ¥åˆ†æå’Œä¿®æ”¹äºŒè¿›åˆ¶ä»£ç ã€‚`deps.py` å¯ä»¥ç®¡ç† Frida æ‰€éœ€çš„å·¥å…·é“¾ä¾èµ–ï¼Œç¡®ä¿æ„å»ºè¿‡ç¨‹èƒ½å¤Ÿé¡ºåˆ©å®Œæˆã€‚ä¾‹å¦‚ï¼Œå®ƒå¯èƒ½ä¼šç®¡ç† LLVM æˆ– GCC ç­‰å·¥å…·é“¾çš„ç‰¹å®šç‰ˆæœ¬ã€‚

**æ¶‰åŠäºŒè¿›åˆ¶åº•å±‚ã€Linuxã€Android å†…æ ¸åŠæ¡†æ¶çš„çŸ¥è¯†åŠä¸¾ä¾‹è¯´æ˜ï¼š**

*   **æ“ä½œç³»ç»Ÿå’Œæ¶æ„ (MachineSpec):**  è„šæœ¬ä¸­å¤§é‡ä½¿ç”¨äº† `MachineSpec` ç±»æ¥å¤„ç†ä¸åŒçš„æ“ä½œç³»ç»Ÿ (å¦‚ Linux, Windows, macOS, Android) å’Œæ¶æ„ (å¦‚ x86, x86\_64, ARM, ARM64)ã€‚è¿™æ¶‰åŠåˆ°å¯¹åº•å±‚æ“ä½œç³»ç»Ÿç‰¹æ€§çš„ç†è§£ã€‚ä¾‹å¦‚ï¼Œåœ¨æ„å»ºé’ˆå¯¹ Android çš„ä¾èµ–é¡¹æ—¶ï¼Œéœ€è¦è€ƒè™‘ Android çš„ ABI (Application Binary Interface)ã€‚
*   **å·¥å…·é“¾ (Toolchain):**  è„šæœ¬ä¸­æ¶‰åŠåˆ°å·¥å…·é“¾çš„ç®¡ç†å’Œä½¿ç”¨ï¼Œå·¥å…·é“¾æ˜¯ç¼–è¯‘å’Œé“¾æ¥äºŒè¿›åˆ¶ä»£ç çš„å…³é”®ç»„ä»¶ã€‚è„šæœ¬éœ€è¦çŸ¥é“å¦‚ä½•ä¸ºä¸åŒçš„ç›®æ ‡å¹³å°è·å–å’Œé…ç½®åˆé€‚çš„å·¥å…·é“¾ã€‚ä¾‹å¦‚ï¼Œäº¤å‰ç¼–è¯‘ Android ä»£ç éœ€è¦ä½¿ç”¨ Android NDK ä¸­çš„å·¥å…·é“¾ã€‚
*   **æ–‡ä»¶ç³»ç»Ÿè·¯å¾„å¤„ç†:** è„šæœ¬ä¸­ä½¿ç”¨äº† `pathlib` æ¨¡å—æ¥å¤„ç†æ–‡ä»¶å’Œç›®å½•è·¯å¾„ï¼Œè¿™åœ¨å¤„ç†ä¸åŒæ“ä½œç³»ç»Ÿçš„æ–‡ä»¶ç³»ç»Ÿå·®å¼‚æ—¶éå¸¸é‡è¦ã€‚
*   **æ‰“åŒ…å’Œå‹ç¼© (tarfile):**  è„šæœ¬ä½¿ç”¨ `tarfile` æ¨¡å—æ¥åˆ›å»ºå’Œæå– `.tar.xz` å‹ç¼©åŒ…ï¼Œè¿™æ˜¯ä¸€ç§å¸¸è§çš„åœ¨ Linux å’Œç±» Unix ç³»ç»Ÿä¸­åˆ†å‘è½¯ä»¶çš„æ–¹å¼ã€‚
*   **æ„å»ºç³»ç»Ÿ (Meson):** è„šæœ¬ä½¿ç”¨ Meson ä½œä¸ºæ„å»ºç³»ç»Ÿæ¥é…ç½®å’Œæ‰§è¡Œæ„å»ºè¿‡ç¨‹ã€‚Meson èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ„å»ºä¾èµ–å…³ç³»ï¼Œå¹¶ç”Ÿæˆç‰¹å®šå¹³å°çš„æ„å»ºæ–‡ä»¶ï¼ˆä¾‹å¦‚ Ninja æ„å»ºæ–‡ä»¶ï¼‰ã€‚
*   **ç¯å¢ƒå˜é‡:** è„šæœ¬ä¸­ä¼šè®¾ç½®å’Œä½¿ç”¨å„ç§ç¯å¢ƒå˜é‡ï¼Œä¾‹å¦‚ `LDFLAGS` ç”¨äºæŒ‡å®šé“¾æ¥å™¨é€‰é¡¹ï¼Œè¿™åœ¨æ§åˆ¶äºŒè¿›åˆ¶æ–‡ä»¶çš„ç”Ÿæˆæ–¹å¼æ—¶éå¸¸é‡è¦ã€‚

**é€»è¾‘æ¨ç†åŠå‡è®¾è¾“å…¥ä¸è¾“å‡ºï¼š**

*   **ä¾èµ–é¡¹é€‰æ‹©:**  `Builder.build` æ–¹æ³•ä¼šæ ¹æ® `only_packages` å’Œ `excluded_packages` å‚æ•°æ¥å†³å®šæ„å»ºå“ªäº›ä¾èµ–é¡¹ã€‚
    *   **å‡è®¾è¾“å…¥:** `only_packages = {"glib"}`ï¼Œ`excluded_packages = set()`
    *   **é€»è¾‘æ¨ç†:**  è„šæœ¬ä¼šè¯†åˆ« `glib` åŒ…åŠå…¶æ‰€æœ‰ä¾èµ–é¡¹ï¼Œå¹¶ä»…æ„å»ºè¿™äº›åŒ…ã€‚
    *   **é¢„æœŸè¾“å‡º:**  æ„å»ºè¿‡ç¨‹ä¸­ä¼šåŒ…å« `glib` åŠå…¶ä¾èµ–é¡¹çš„æ„å»ºæ­¥éª¤ï¼Œæœ€ç»ˆç”Ÿæˆçš„åŒ…ä¼šåŒ…å«è¿™äº›ä¾èµ–é¡¹çš„äº§ç‰©ã€‚
*   **æ¡ä»¶åˆ¤æ–­ (`when`):** `PackageSpec` å’Œå…¶ `options` åŠ `dependencies` å¯ä»¥åŒ…å« `when` æ¡ä»¶ï¼Œç”¨äºæ ¹æ®å½“å‰ç¯å¢ƒå†³å®šæ˜¯å¦åŒ…å«æŸä¸ªé€‰é¡¹æˆ–ä¾èµ–ã€‚
    *   **å‡è®¾è¾“å…¥:** `PackageSpec` ä¸­æœ‰ä¸€ä¸ªä¾èµ–é¡¹ `openssl`ï¼Œå…¶ `when` å€¼ä¸º `"machine.os == 'linux'"`ã€‚å½“å‰æ„å»ºç›®æ ‡ `machine.os` æ˜¯ `"windows"`ã€‚
    *   **é€»è¾‘æ¨ç†:** ç”±äºæ¡ä»¶ä¸æ»¡è¶³ï¼Œ`openssl` å°†ä¸ä¼šè¢«ä½œä¸ºä¾èµ–é¡¹åŒ…å«åœ¨å†…ã€‚
    *   **é¢„æœŸè¾“å‡º:**  æ„å»ºè¿‡ç¨‹ä¸­ä¸ä¼šåŒ…å« `openssl` çš„æ„å»ºæ­¥éª¤ã€‚

**ç”¨æˆ·æˆ–ç¼–ç¨‹å¸¸è§çš„ä½¿ç”¨é”™è¯¯åŠä¸¾ä¾‹è¯´æ˜ï¼š**

*   **é”™è¯¯çš„ bundle åç§°:**  ç”¨æˆ·åœ¨ä½¿ç”¨ `sync` æˆ– `roll` å‘½ä»¤æ—¶å¯èƒ½ä¼šè¾“å…¥é”™è¯¯çš„ `bundle` åç§°ã€‚
    *   **é”™è¯¯ç¤ºä¾‹:**  `./deps.py sync froda android/arm64` (æ­£ç¡®çš„åº”è¯¥æ˜¯ `frida`)
    *   **åæœ:** è„šæœ¬ä¼šæŠ›å‡º `argparse.ArgumentTypeError` å¼‚å¸¸ï¼Œæç¤ºæ— æ•ˆçš„é€‰æ‹©ã€‚
*   **æŒ‡å®šäº†ä¸å­˜åœ¨çš„åŒ…è¿›è¡Œå•ç‹¬æ„å»º:** ç”¨æˆ·åœ¨ä½¿ç”¨ `build` å‘½ä»¤çš„ `--only` å‚æ•°æ—¶ï¼Œå¯èƒ½ä¼šæŒ‡å®šä¸€ä¸ª `deps.toml` æ–‡ä»¶ä¸­ä¸å­˜åœ¨çš„åŒ…åã€‚
    *   **é”™è¯¯ç¤ºä¾‹:** `./deps.py build --only non_existent_package`
    *   **åæœ:** è„šæœ¬åœ¨è§£æä¾èµ–å…³ç³»æ—¶ä¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„åŒ…ï¼Œå¯¼è‡´æ„å»ºå¤±è´¥ã€‚
*   **ç¼ºå°‘å¿…è¦çš„ç³»ç»Ÿä¾èµ–:**  åœ¨æ„å»ºæŸäº›ä¾èµ–é¡¹æ—¶ï¼Œå¯èƒ½éœ€è¦ç³»ç»Ÿä¸Šé¢„å…ˆå®‰è£…ä¸€äº›åº“æˆ–å·¥å…·ã€‚å¦‚æœç¼ºå°‘è¿™äº›ä¾èµ–ï¼Œæ„å»ºè¿‡ç¨‹ä¼šå¤±è´¥ã€‚
    *   **é”™è¯¯ç¤ºä¾‹:**  æ„å»ºæŸä¸ªä¾èµ–éœ€è¦ `cmake`ï¼Œä½†ç”¨æˆ·ç³»ç»Ÿä¸Šæ²¡æœ‰å®‰è£… `cmake`ã€‚
    *   **åæœ:** Meson æ„å»ºé…ç½®é˜¶æ®µä¼šæŠ¥é”™ï¼Œæç¤ºæ‰¾ä¸åˆ° `cmake` å‘½ä»¤ã€‚
*   **ç½‘ç»œé—®é¢˜:**  åœ¨ä¸‹è½½é¢„æ„å»ºä¾èµ–æˆ–å…‹éš†ä»£ç ä»“åº“æ—¶ï¼Œå¦‚æœç½‘ç»œè¿æ¥ä¸ç¨³å®šæˆ–æ— æ³•è®¿é—®ï¼Œä¼šå¯¼è‡´ä¸‹è½½æˆ–å…‹éš†å¤±è´¥ã€‚
    *   **é”™è¯¯ç¤ºä¾‹:**  æ‰§è¡Œ `sync` å‘½ä»¤æ—¶ï¼Œç”±äºç½‘ç»œé—®é¢˜æ— æ³•è¿æ¥åˆ°å­˜å‚¨ä¾èµ–é¡¹çš„æœåŠ¡å™¨ã€‚
    *   **åæœ:** è„šæœ¬ä¼šæŠ›å‡º `urllib.error.HTTPError` æˆ–ç±»ä¼¼çš„å¼‚å¸¸ã€‚

**ç”¨æˆ·æ“ä½œæ˜¯å¦‚ä½•ä¸€æ­¥æ­¥çš„åˆ°è¾¾è¿™é‡Œï¼Œä½œä¸ºè°ƒè¯•çº¿ç´¢ï¼š**

1. **å¼€å‘è€…æˆ–è´¡çŒ®è€…ä¿®æ”¹äº† Frida Swift çš„ä»£ç ï¼Œæˆ–è€…éœ€è¦æ„å»ºç‰¹å®šå¹³å°çš„ Frida ç‰ˆæœ¬ã€‚**
2. **ä»–ä»¬éœ€è¦ç¡®ä¿ Frida Swift çš„ä¾èµ–é¡¹æ˜¯æœ€æ–°çš„ï¼Œæˆ–è€…éœ€è¦ä¸ºæ–°çš„å¹³å°æ„å»ºä¾èµ–é¡¹ã€‚**
3. **ä»–ä»¬ä¼šè¿›å…¥ Frida é¡¹ç›®çš„æ ¹ç›®å½•ï¼Œç„¶åå¯¼èˆªåˆ° `frida/subprojects/frida-swift/releng/` ç›®å½•ã€‚**
4. **ä»–ä»¬ä¼šä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·æ‰§è¡Œ `deps.py` è„šæœ¬ï¼Œå¹¶æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„å­å‘½ä»¤å’Œå‚æ•°ï¼Œä¾‹å¦‚ï¼š**
    *   `./deps.py sync sdk android/arm64 ./deps`  (åŒæ­¥ Android ARM64 å¹³å°çš„ SDK ä¾èµ–åˆ° `./deps` ç›®å½•)
    *   `./deps.py roll sdk linux/x86_64` (æ„å»ºå¹¶ä¸Šä¼  Linux x86\_64 å¹³å°çš„ SDK ä¾èµ–)
    *   `./deps.py build --bundle sdk --host windows/x86_64` (åœ¨æœ¬åœ°æ„å»º Windows x86\_64 å¹³å°çš„ SDK ä¾èµ–)
    *   åœ¨æ‰§è¡Œè„šæœ¬é‡åˆ°é”™è¯¯æ—¶ï¼Œä»–ä»¬å¯èƒ½ä¼šæŸ¥çœ‹è„šæœ¬çš„è¾“å‡ºï¼Œä¾‹å¦‚é”™è¯¯ä¿¡æ¯ã€æ„å»ºæ—¥å¿—ç­‰ï¼Œæ¥å®šä½é—®é¢˜ã€‚ä»–ä»¬ä¹Ÿå¯èƒ½ä¼šæ£€æŸ¥ `deps.toml` æ–‡ä»¶æ¥äº†è§£ä¾èµ–é¡¹çš„é…ç½®ã€‚

æ€»è€Œè¨€ä¹‹ï¼Œ`deps.py` æ˜¯ Frida é¡¹ç›®ä¸­ä¸€ä¸ªè‡³å…³é‡è¦çš„è„šæœ¬ï¼Œå®ƒè´Ÿè´£è‡ªåŠ¨åŒ–ç®¡ç† Frida Swift ç»„ä»¶çš„æ„å»ºä¾èµ–ï¼Œç¡®ä¿å¼€å‘è€…èƒ½å¤Ÿæ–¹ä¾¿åœ°æ„å»ºå’Œä½¿ç”¨ Frida åœ¨å„ç§ç›®æ ‡å¹³å°ä¸Šçš„åŠŸèƒ½ã€‚å®ƒæ¶‰åŠåˆ°æ“ä½œç³»ç»Ÿã€æ¶æ„ã€æ„å»ºå·¥å…·é“¾ã€ç½‘ç»œé€šä¿¡ç­‰å¤šä¸ªæ–¹é¢çš„çŸ¥è¯†ã€‚

### æç¤ºè¯
```
è¿™æ˜¯ç›®å½•ä¸ºfrida/subprojects/frida-swift/releng/deps.pyçš„fridaDynamic instrumentation toolçš„æºä»£ç æ–‡ä»¶ï¼Œ è¯·åˆ—ä¸¾ä¸€ä¸‹å®ƒçš„åŠŸèƒ½, 
å¦‚æœå®ƒä¸é€†å‘çš„æ–¹æ³•æœ‰å…³ç³»ï¼Œè¯·åšå‡ºå¯¹åº”çš„ä¸¾ä¾‹è¯´æ˜ï¼Œ
å¦‚æœæ¶‰åŠåˆ°äºŒè¿›åˆ¶åº•å±‚ï¼Œlinux, androidå†…æ ¸åŠæ¡†æ¶çš„çŸ¥è¯†ï¼Œè¯·åšå‡ºå¯¹åº”çš„ä¸¾ä¾‹è¯´æ˜ï¼Œ
å¦‚æœåšäº†é€»è¾‘æ¨ç†ï¼Œè¯·ç»™å‡ºå‡è®¾è¾“å…¥ä¸è¾“å‡º,
å¦‚æœæ¶‰åŠç”¨æˆ·æˆ–è€…ç¼–ç¨‹å¸¸è§çš„ä½¿ç”¨é”™è¯¯ï¼Œè¯·ä¸¾ä¾‹è¯´æ˜,
è¯´æ˜ç”¨æˆ·æ“ä½œæ˜¯å¦‚ä½•ä¸€æ­¥æ­¥çš„åˆ°è¾¾è¿™é‡Œï¼Œä½œä¸ºè°ƒè¯•çº¿ç´¢ã€‚
è¿™æ˜¯ç¬¬1éƒ¨åˆ†ï¼Œå…±2éƒ¨åˆ†ï¼Œè¯·å½’çº³ä¸€ä¸‹å®ƒçš„åŠŸèƒ½
```

### æºä»£ç 
```python
#!/usr/bin/env python3
from __future__ import annotations
import argparse
import base64
from configparser import ConfigParser
import dataclasses
from dataclasses import dataclass, field
from enum import Enum
import graphlib
import itertools
import json
import os
from pathlib import Path
import re
import shlex
import shutil
import subprocess
import sys
import tarfile
import tempfile
import time
from typing import Callable, Iterator, Optional, Mapping, Sequence, Union
import urllib.request

RELENG_DIR = Path(__file__).resolve().parent
ROOT_DIR = RELENG_DIR.parent

if __name__ == "__main__":
    # TODO: Refactor
    sys.path.insert(0, str(ROOT_DIR))
sys.path.insert(0, str(RELENG_DIR / "tomlkit"))

from tomlkit.toml_file import TOMLFile

from releng import env
from releng.progress import Progress, ProgressCallback, print_progress
from releng.machine_spec import MachineSpec


def main():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    default_machine = MachineSpec.make_from_local_system().identifier

    bundle_opt_kwargs = {
        "help": "bundle (default: sdk)",
        "type": parse_bundle_option_value,
    }
    machine_opt_kwargs = {
        "help": f"os/arch (default: {default_machine})",
        "type": MachineSpec.parse,
    }

    command = subparsers.add_parser("sync", help="ensure prebuilt dependencies are up-to-date")
    command.add_argument("bundle", **bundle_opt_kwargs)
    command.add_argument("host", **machine_opt_kwargs)
    command.add_argument("location", help="filesystem location", type=Path)
    command.set_defaults(func=lambda args: sync(args.bundle, args.host, args.location.resolve()))

    command = subparsers.add_parser("roll", help="build and upload prebuilt dependencies if needed")
    command.add_argument("bundle", **bundle_opt_kwargs)
    command.add_argument("host", **machine_opt_kwargs)
    command.add_argument("--build", default=default_machine, **machine_opt_kwargs)
    command.add_argument("--activate", default=False, action='store_true')
    command.add_argument("--post", help="post-processing script")
    command.set_defaults(func=lambda args: roll(args.bundle, args.build, args.host, args.activate,
                                                Path(args.post) if args.post is not None else None))

    command = subparsers.add_parser("build", help="build prebuilt dependencies")
    command.add_argument("--bundle", default=Bundle.SDK, **bundle_opt_kwargs)
    command.add_argument("--build", default=default_machine, **machine_opt_kwargs)
    command.add_argument("--host", default=default_machine, **machine_opt_kwargs)
    command.add_argument("--only", help="only build packages A, B, and C", metavar="A,B,C",
                         type=parse_set_option_value)
    command.add_argument("--exclude", help="exclude packages A, B, and C", metavar="A,B,C",
                         type=parse_set_option_value, default=set())
    command.add_argument("-v", "--verbose", help="be verbose", action="store_true")
    command.set_defaults(func=lambda args: build(args.bundle, args.build, args.host,
                                                 args.only, args.exclude, args.verbose))

    command = subparsers.add_parser("wait", help="wait for prebuilt dependencies if needed")
    command.add_argument("bundle", **bundle_opt_kwargs)
    command.add_argument("host", **machine_opt_kwargs)
    command.set_defaults(func=lambda args: wait(args.bundle, args.host))

    command = subparsers.add_parser("bump", help="bump dependency versions")
    command.set_defaults(func=lambda args: bump())

    args = parser.parse_args()
    if 'func' in args:
        try:
            args.func(args)
        except CommandError as e:
            print(e, file=sys.stderr)
            sys.exit(1)
    else:
        parser.print_usage(file=sys.stderr)
        sys.exit(1)


def parse_bundle_option_value(raw_bundle: str) -> Bundle:
    try:
        return Bundle[raw_bundle.upper()]
    except KeyError:
        choices = "', '".join([e.name.lower() for e in Bundle])
        raise argparse.ArgumentTypeError(f"invalid choice: {raw_bundle} (choose from '{choices}')")


def parse_set_option_value(v: str) -> set[str]:
    return set([v.strip() for v in v.split(",")])


def query_toolchain_prefix(machine: MachineSpec,
                           cache_dir: Path) -> Path:
    if machine.os == "windows":
        identifier = "windows-x86" if machine.arch in {"x86", "x86_64"} else machine.os_dash_arch
    else:
        identifier = machine.identifier
    return cache_dir / f"toolchain-{identifier}"


def ensure_toolchain(machine: MachineSpec,
                     cache_dir: Path,
                     version: Optional[str] = None,
                     on_progress: ProgressCallback = print_progress) -> tuple[Path, SourceState]:
    toolchain_prefix = query_toolchain_prefix(machine, cache_dir)
    state = sync(Bundle.TOOLCHAIN, machine, toolchain_prefix, version, on_progress)
    return (toolchain_prefix, state)


def query_sdk_prefix(machine: MachineSpec,
                     cache_dir: Path) -> Path:
    return cache_dir / f"sdk-{machine.identifier}"


def ensure_sdk(machine: MachineSpec,
               cache_dir: Path,
               version: Optional[str] = None,
               on_progress: ProgressCallback = print_progress) -> tuple[Path, SourceState]:
    sdk_prefix = query_sdk_prefix(machine, cache_dir)
    state = sync(Bundle.SDK, machine, sdk_prefix, version, on_progress)
    return (sdk_prefix, state)


def detect_cache_dir(sourcedir: Path) -> Path:
    raw_location = os.environ.get("FRIDA_DEPS", None)
    if raw_location is not None:
        location = Path(raw_location)
    else:
        location = sourcedir / "deps"
    return location


def sync(bundle: Bundle,
         machine: MachineSpec,
         location: Path,
         version: Optional[str] = None,
         on_progress: ProgressCallback = print_progress) -> SourceState:
    state = SourceState.PRISTINE

    if version is None:
        version = load_dependency_parameters().deps_version

    bundle_nick = bundle.name.lower() if bundle != Bundle.SDK else bundle.name

    if location.exists():
        try:
            cached_version = (location / "VERSION.txt").read_text(encoding="utf-8").strip()
            if cached_version == version:
                return state
        except:
            pass
        shutil.rmtree(location)
        state = SourceState.MODIFIED

    (url, filename) = compute_bundle_parameters(bundle, machine, version)

    local_bundle = location.parent / filename
    if local_bundle.exists():
        on_progress(Progress("Deploying local {}".format(bundle_nick)))
        archive_path = local_bundle
        archive_is_temporary = False
    else:
        if bundle == Bundle.SDK:
            on_progress(Progress(f"Downloading SDK {version} for {machine.identifier}"))
        else:
            on_progress(Progress(f"Downloading {bundle_nick} {version}"))
        try:
            with urllib.request.urlopen(url) as response, \
                    tempfile.NamedTemporaryFile(delete=False) as archive:
                shutil.copyfileobj(response, archive)
                archive_path = Path(archive.name)
                archive_is_temporary = True
            on_progress(Progress(f"Extracting {bundle_nick}"))
        except urllib.error.HTTPError as e:
            if e.code == 404:
                raise BundleNotFoundError(f"missing bundle at {url}") from e
            raise e

    try:
        staging_dir = location.parent / f"_{location.name}"
        if staging_dir.exists():
            shutil.rmtree(staging_dir)
        staging_dir.mkdir(parents=True)

        with tarfile.open(archive_path, "r:xz") as tar:
            tar.extractall(staging_dir)

        suffix_len = len(".frida.in")
        raw_location = location.as_posix()
        for f in staging_dir.rglob("*.frida.in"):
            target = f.parent / f.name[:-suffix_len]
            f.write_text(f.read_text(encoding="utf-8").replace("@FRIDA_TOOLROOT@", raw_location),
                         encoding="utf-8")
            f.rename(target)

        staging_dir.rename(location)
    finally:
        if archive_is_temporary:
            archive_path.unlink()

    return state


def roll(bundle: Bundle,
         build_machine: MachineSpec,
         host_machine: MachineSpec,
         activate: bool,
         post: Optional[Path]):
    params = load_dependency_parameters()
    version = params.deps_version

    if activate and bundle == Bundle.SDK:
        configure_bootstrap_version(version)

    (public_url, filename) = compute_bundle_parameters(bundle, host_machine, version)

    # First do a quick check to avoid hitting S3 in most cases.
    request = urllib.request.Request(public_url)
    request.get_method = lambda: "HEAD"
    try:
        with urllib.request.urlopen(request) as r:
            return
    except urllib.request.HTTPError as e:
        if e.code != 404:
            raise CommandError("network error") from e

    s3_url = "s3://build.frida.re/deps/{version}/{filename}".format(version=version, filename=filename)

    # We will most likely need to build, but let's check S3 to be certain.
    r = subprocess.run(["aws", "s3", "ls", s3_url], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, encoding="utf-8")
    if r.returncode == 0:
        return
    if r.returncode != 1:
        raise CommandError(f"unable to access S3: {r.stdout.strip()}")

    artifact = build(bundle, build_machine, host_machine)

    if post is not None:
        post_script = RELENG_DIR / post
        if not post_script.exists():
            raise CommandError("post-processing script not found")

        subprocess.run([
                           sys.executable, post_script,
                           "--bundle=" + bundle.name.lower(),
                           "--host=" + host_machine.identifier,
                           "--artifact=" + str(artifact),
                           "--version=" + version,
                       ],
                       check=True)

    subprocess.run(["aws", "s3", "cp", artifact, s3_url], check=True)

    # Use the shell for Windows compatibility, where npm generates a .bat script.
    subprocess.run("cfcli purge " + public_url, shell=True, check=True)

    if activate and bundle == Bundle.TOOLCHAIN:
        configure_bootstrap_version(version)


def build(bundle: Bundle,
          build_machine: MachineSpec,
          host_machine: MachineSpec,
          only_packages: Optional[set[str]] = None,
          excluded_packages: set[str] = set(),
          verbose: bool = False) -> Path:
    builder = Builder(bundle, build_machine, host_machine, verbose)
    try:
        return builder.build(only_packages, excluded_packages)
    except subprocess.CalledProcessError as e:
        print(e, file=sys.stderr)
        if e.stdout is not None:
            print("\n=== stdout ===\n" + e.stdout, file=sys.stderr)
        if e.stderr is not None:
            print("\n=== stderr ===\n" + e.stderr, file=sys.stderr)
        sys.exit(1)


class Builder:
    def __init__(self,
                 bundle: Bundle,
                 build_machine: MachineSpec,
                 host_machine: MachineSpec,
                 verbose: bool):
        self._bundle = bundle
        self._host_machine = host_machine.default_missing()
        self._build_machine = build_machine.default_missing().maybe_adapt_to_host(self._host_machine)
        self._verbose = verbose
        self._default_library = "static"

        self._params = load_dependency_parameters()
        self._cachedir = detect_cache_dir(ROOT_DIR)
        self._workdir = self._cachedir / "src"

        self._toolchain_prefix: Optional[Path] = None
        self._build_config: Optional[env.MachineConfig] = None
        self._host_config: Optional[env.MachineConfig] = None
        self._build_env: dict[str, str] = {}
        self._host_env: dict[str, str] = {}

        self._ansi_supported = os.environ.get("TERM") != "dumb" \
                    and (self._build_machine.os != "windows" or "WT_SESSION" in os.environ)

    def build(self,
              only_packages: Optional[list[str]],
              excluded_packages: set[str]) -> Path:
        started_at = time.time()
        prepare_ended_at = None
        clone_time_elapsed = None
        build_time_elapsed = None
        build_ended_at = None
        packaging_ended_at = None
        try:
            all_packages = {i: self._resolve_package(p) for i, p in self._params.packages.items() \
                    if self._can_build(p)}
            if only_packages is not None:
                toplevel_packages = [all_packages[identifier] for identifier in only_packages]
                selected_packages = self._resolve_dependencies(toplevel_packages, all_packages)
            elif self._bundle is Bundle.TOOLCHAIN:
                toplevel_packages = [p for p in all_packages.values() if p.scope == "toolchain"]
                selected_packages = self._resolve_dependencies(toplevel_packages, all_packages)
            else:
                selected_packages = {i: p for i, p, in all_packages.items() if p.scope is None}
            selected_packages = {i: p for i, p in selected_packages.items() if i not in excluded_packages}

            packages = [selected_packages[i] for i in iterate_package_ids_in_dependency_order(selected_packages.values())]
            all_deps = itertools.chain.from_iterable([pkg.dependencies for pkg in packages])
            deps_for_build_machine = {dep.identifier for dep in all_deps if dep.for_machine == "build"}

            self._prepare()
            prepare_ended_at = time.time()

            clone_time_elapsed = 0
            build_time_elapsed = 0
            for pkg in packages:
                self._print_package_banner(pkg)

                t1 = time.time()
                self._clone_repo_if_needed(pkg)
                t2 = time.time()
                clone_time_elapsed += t2 - t1

                machines = [self._host_machine]
                if pkg.identifier in deps_for_build_machine:
                    machines += [self._build_machine]
                self._build_package(pkg, machines)
                t3 = time.time()
                build_time_elapsed += t3 - t2
            build_ended_at = time.time()

            artifact_file = self._package()
            packaging_ended_at = time.time()
        finally:
            ended_at = time.time()

            if prepare_ended_at is not None:
                self._print_summary_banner()
                print("      Total: {}".format(format_duration(ended_at - started_at)))

            if prepare_ended_at is not None:
                print("    Prepare: {}".format(format_duration(prepare_ended_at - started_at)))

            if clone_time_elapsed is not None:
                print("      Clone: {}".format(format_duration(clone_time_elapsed)))

            if build_time_elapsed is not None:
                print("      Build: {}".format(format_duration(build_time_elapsed)))

            if packaging_ended_at is not None:
                print("  Packaging: {}".format(format_duration(packaging_ended_at - build_ended_at)))

            print("", flush=True)

        return artifact_file

    def _can_build(self, pkg: PackageSpec) -> bool:
        return self._evaluate_condition(pkg.when)

    def _resolve_package(self, pkg: PackageSpec) -> bool:
        resolved_opts = [opt for opt in pkg.options if self._evaluate_condition(opt.when)]
        resolved_deps = [dep for dep in pkg.dependencies if self._evaluate_condition(dep.when)]
        return dataclasses.replace(pkg,
                                   options=resolved_opts,
                                   dependencies=resolved_deps)

    def _resolve_dependencies(self,
                              packages: Sequence[PackageSpec],
                              all_packages: Mapping[str, PackageSpec]) -> dict[str, PackageSpec]:
        result = {p.identifier: p for p in packages}
        for p in packages:
            self._resolve_package_dependencies(p, all_packages, result)
        return result

    def _resolve_package_dependencies(self,
                                      package: PackageSpec,
                                      all_packages: Mapping[str, PackageSpec],
                                      resolved_packages: Mapping[str, PackageSpec]):
        for dep in package.dependencies:
            identifier = dep.identifier
            if identifier in resolved_packages:
                continue
            p = all_packages[identifier]
            resolved_packages[identifier] = p
            self._resolve_package_dependencies(p, all_packages, resolved_packages)

    def _evaluate_condition(self, cond: Optional[str]) -> bool:
        if cond is None:
            return True
        global_vars = {
            "Bundle": Bundle,
            "bundle": self._bundle,
            "machine": self._host_machine,
        }
        return eval(cond, global_vars)

    def _prepare(self):
        self._toolchain_prefix, toolchain_state = \
                ensure_toolchain(self._build_machine,
                                 self._cachedir,
                                 version=self._params.bootstrap_version)
        if toolchain_state == SourceState.MODIFIED:
            self._wipe_build_state()

        envdir = self._get_builddir_container()
        envdir.mkdir(parents=True, exist_ok=True)

        menv = {**os.environ}

        if self._bundle is Bundle.TOOLCHAIN:
            extra_ldflags = []
            if self._host_machine.is_apple:
                symfile = envdir / "toolchain-executable.symbols"
                symfile.write_text("# No exported symbols.\n", encoding="utf-8")
                extra_ldflags += [f"-Wl,-exported_symbols_list,{symfile}"]
            elif self._host_machine.os != "windows":
                verfile = envdir / "toolchain-executable.version"
                verfile.write_text("\n".join([
                                                 "{",
                                                 "  global:",
                                                 "    # FreeBSD needs these two:",
                                                 "    __progname;",
                                                 "    environ;",
                                                 "",
                                                 "  local:",
                                                 "    *;",
                                                 "};",
                                                 ""
                                             ]),
                                   encoding="utf-8")
                extra_ldflags += [f"-Wl,--version-script,{verfile}"]
            if extra_ldflags:
                menv["LDFLAGS"] = shlex.join(extra_ldflags + shlex.split(menv.get("LDFLAGS", "")))

        build_sdk_prefix = None
        host_sdk_prefix = None

        self._build_config, self._host_config = \
                env.generate_machine_configs(self._build_machine,
                                             self._host_machine,
                                             menv,
                                             self._toolchain_prefix,
                                             build_sdk_prefix,
                                             host_sdk_prefix,
                                             self._call_meson,
                                             self._default_library,
                                             envdir)
        self._build_env = self._build_config.make_merged_environment(os.environ)
        self._host_env = self._host_config.make_merged_environment(os.environ)

    def _clone_repo_if_needed(self, pkg: PackageSpec):
        sourcedir = self._get_sourcedir(pkg)

        git = lambda *args, **kwargs: subprocess.run(["git", *args],
                                                     **kwargs,
                                                     capture_output=True,
                                                     encoding="utf-8")

        if sourcedir.exists():
            self._print_status(pkg.name, "Reusing existing checkout")
            current_rev = git("rev-parse", "FETCH_HEAD", cwd=sourcedir, check=True).stdout.strip()
            if current_rev != pkg.version:
                self._print_status(pkg.name, "WARNING: Checkout does not match version in deps.toml")
        else:
            self._print_status(pkg.name, "Cloning")
            clone_shallow(pkg, sourcedir, git)

    def _wipe_build_state(self):
        for path in (self._get_outdir(), self._get_builddir_container()):
            if path.exists():
                self._print_status(path.relative_to(self._workdir).as_posix(), "Wiping")
                shutil.rmtree(path)

    def _build_package(self, pkg: PackageSpec, machines: Sequence[MachineSpec]):
        for machine in machines:
            manifest_path = self._get_manifest_path(pkg, machine)
            action = "skip" if manifest_path.exists() else "build"

            message = "Building" if action == "build" else "Already built"
            message += f" for {machine.identifier}"
            self._print_status(pkg.name, message)

            if action == "build":
                self._build_package_for_machine(pkg, machine)
                assert manifest_path.exists()

    def _build_package_for_machine(self, pkg: PackageSpec, machine: MachineSpec):
        sourcedir = self._get_sourcedir(pkg)
        builddir = self._get_builddir(pkg, machine)

        prefix = self._get_prefix(machine)
        libdir = prefix / "lib"

        strip = "true" if machine.toolchain_can_strip else "false"

        if builddir.exists():
            shutil.rmtree(builddir)

        machine_file_opts = [f"--native-file={self._build_config.machine_file}"]
        pc_opts = [f"-Dpkg_config_path={prefix / machine.libdatadir / 'pkgconfig'}"]
        if self._host_config is not self._build_config and machine is self._host_machine:
            machine_file_opts += [f"--cross-file={self._host_config.machine_file}"]
            pc_path_for_build = self._get_prefix(self._build_machine) / self._build_machine.libdatadir / "pkgconfig"
            pc_opts += [f"-Dbuild.pkg_config_path={pc_path_for_build}"]

        menv = self._host_env if machine is self._host_machine else self._build_env

        meson_kwargs = {
            "env": menv,
            "check": True,
        }
        if not self._verbose:
            meson_kwargs["capture_output"] = True
            meson_kwargs["encoding"] = "utf-8"

        self._call_meson([
                             "setup",
                             builddir,
                             *machine_file_opts,
                             f"-Dprefix={prefix}",
                             f"-Dlibdir={libdir}",
                             *pc_opts,
                             f"-Ddefault_library={self._default_library}",
                             f"-Dbackend=ninja",
                             *machine.meson_optimization_options,
                             f"-Dstrip={strip}",
                             *[opt.value for opt in pkg.options],
                         ],
                         cwd=sourcedir,
                         **meson_kwargs)

        self._call_meson(["install"],
                         cwd=builddir,
                         **meson_kwargs)

        manifest_lines = []
        install_locations = json.loads(self._call_meson(["introspect", "--installed"],
                                                        cwd=builddir,
                                                        capture_output=True,
                                                        encoding="utf-8",
                                                        env=menv).stdout)
        for installed_path in install_locations.values():
            manifest_lines.append(Path(installed_path).relative_to(prefix).as_posix())
        manifest_lines.sort()
        manifest_path = self._get_manifest_path(pkg, machine)
        manifest_path.parent.mkdir(parents=True, exist_ok=True)
        manifest_path.write_text("\n".join(manifest_lines) + "\n", encoding="utf-8")

    def _call_meson(self, argv, *args, **kwargs):
        if self._verbose and argv[0] in {"setup", "install"}:
            vanilla_env = os.environ
            meson_env = kwargs["env"]
            changed_env = {k: v for k, v in meson_env.items() if k not in vanilla_env or v != vanilla_env[k]}

            indent = "  "
            env_summary = f" \\\n{indent}".join([f"{k}={shlex.quote(v)}" for k, v in changed_env.items()])
            argv_summary = f" \\\n{3 * indent}".join([str(arg) for arg in argv])

            print(f"> {env_summary} \\\n{indent}meson {argv_summary}", flush=True)

        return env.call_meson(argv, use_submodule=True, *args, **kwargs)

    def _package(self):
        outfile = self._cachedir / f"{self._bundle.name.lower()}-{self._host_machine.identifier}.tar.xz"

        self._print_packaging_banner()
        with tempfile.TemporaryDirectory(prefix="frida-deps") as raw_tempdir:
            tempdir = Path(raw_tempdir)

            self._print_status(outfile.name, "Staging files")
            if self._bundle is Bundle.TOOLCHAIN:
                self._stage_toolchain_files(tempdir)
            else:
                self._stage_sdk_files(tempdir)

            self._adjust_manifests(tempdir)
            self._adjust_files_containing_hardcoded_paths(tempdir)

            (tempdir / "VERSION.txt").write_text(self._params.deps_version + "\n", encoding="utf-8")

            self._print_status(outfile.name, "Assembling")
            with tarfile.open(outfile, "w:xz") as tar:
                tar.add(tempdir, ".")

            self._print_status(outfile.name, "All done")

        return outfile

    def _stage_toolchain_files(self, location: Path) -> list[Path]:
        if self._host_machine.os == "windows":
            toolchain_prefix = self._toolchain_prefix
            mixin_files = [f for f in self._walk_plain_files(toolchain_prefix)
                           if self._file_should_be_mixed_into_toolchain(f)]
            copy_files(toolchain_prefix, mixin_files, location)

        prefix = self._get_prefix(self._host_machine)
        files = [f for f in self._walk_plain_files(prefix)
                 if self._file_is_toolchain_related(f)]
        copy_files(prefix, files, location)

    def _stage_sdk_files(self, location: Path) -> list[Path]:
        prefix = self._get_prefix(self._host_machine)
        files = [f for f in self._walk_plain_files(prefix)
                 if self._file_is_sdk_related(f)]
        copy_files(prefix, files, location)

    def _adjust_files_containing_hardcoded_paths(self, bundledir: Path):
        prefix = self._get_prefix(self._host_machine)

        raw_prefixes = [str(prefix)]
        if self._host_machine.os == "windows":
            raw_prefixes.append(prefix.as_posix())

        for f in self._walk_plain_files(bundledir):
            filepath = bundledir / f
            try:
                text = filepath.read_text(encoding="utf-8")

                new_text = text
                is_pcfile = filepath.suffix == ".pc"
                replacement = "${frida_sdk_prefix}" if is_pcfile else "@FRIDA_TOOLROOT@"
                for p in raw_prefixes:
                    new_text = new_text.replace(p, replacement)

                if new_text != text:
                    filepath.write_text(new_text, encoding="utf-8")
                    if not is_pcfile:
                        filepath.rename(filepath.parent / f"{f.name}.frida.in")
            except UnicodeDecodeError:
                pass

    @staticmethod
    def _walk_plain_files(rootdir: Path) -> Iterator[Path]:
        for dirpath, dirnames, filenames in os.walk(rootdir):
            for filename in filenames:
                f = Path(dirpath) / filename
                if f.is_symlink():
                    continue
                yield f.relative_to(rootdir)

    @staticmethod
    def _adjust_manifests(bundledir: Path):
        for manifest_path in (bundledir / "manifest").glob("*.pkg"):
            lines = []

            prefix = manifest_path.parent.parent
            for entry in manifest_path.read_text(encoding="utf-8").strip().split("\n"):
                if prefix.joinpath(entry).exists():
                    lines.append(entry)

            if lines:
                lines.sort()
                manifest_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
            else:
                manifest_path.unlink()

    def _file_should_be_mixed_into_toolchain(self, f: Path) -> bool:
        parts = f.parts
        if parts[0] == "VERSION.txt":
            return False
        if parts[0] == "bin":
            stem = f.stem
            return stem in {"bison", "flex", "m4", "nasm", "vswhere"} or stem.startswith("msys-")
        if parts[0] == "manifest":
            return False

        if self._file_is_vala_toolchain_related(f):
            return False

        return True

    def _file_is_toolchain_related(self, f: Path) -> bool:
        if self._file_is_vala_toolchain_related(f):
            return True

        parts = f.parts
        if parts[0] == "bin":
            if f.suffix == ".pdb":
                return False
            stem = f.stem
            if stem in {"gdbus", "gio", "gobject-query", "gsettings"}:
                return False
            if stem.startswith("gspawn-"):
                return False
            return True
        if parts[0] == "manifest":
            return True

        return False

    def _file_is_vala_toolchain_related(self, f: Path) -> bool:
        if f.suffix in {".vapi", ".deps"}:
            return True

        name = f.name
        if f.suffix == self._host_machine.executable_suffix:
            return name.startswith("vala") or name.startswith("vapi") or name.startswith("gen-introspect")
        if f.parts[0] == "bin" and name.startswith("vala-gen-introspect"):
            return True

        return False

    def _file_is_sdk_related(self, f: Path) -> bool:
        suffix = f.suffix
        if suffix == ".pdb":
            return False
        if suffix in [".vapi", ".deps"]:
            return True

        parts = f.parts
        if parts[0] == "bin":
            return f.name.startswith("v8-mksnapshot-")

        return "share" not in parts

    def _get_outdir(self) -> Path:
        return self._workdir / f"_{self._bundle.name.lower()}.out"

    def _get_sourcedir(self, pkg: PackageSpec) -> Path:
        return self._workdir / pkg.identifier

    def _get_builddir(self, pkg: PackageSpec, machine: MachineSpec) -> Path:
        return self._get_builddir_container() / machine.identifier / pkg.identifier

    def _get_builddir_container(self) -> Path:
        return self._workdir / f"_{self._bundle.name.lower()}.tmp"

    def _get_prefix(self, machine: MachineSpec) -> Path:
        return self._get_outdir() / machine.identifier

    def _get_manifest_path(self, pkg: PackageSpec, machine: MachineSpec) -> Path:
        return self._get_prefix(machine) / "manifest" / f"{pkg.identifier}.pkg"

    def _print_package_banner(self, pkg: PackageSpec):
        if self._ansi_supported:
            print("\n".join([
                "",
                "â•­â”€â”€â”€â”€",
                f"â”‚ ğŸ“¦ \033[1m{pkg.name}\033[0m",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®",
                f"â”‚ URL: {pkg.url}",
                f"â”‚ CID: {pkg.version}",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯",
            ]), flush=True)
        else:
            print("\n".join([
                "",
                f"# {pkg.name}",
                f"- URL: {pkg.url}",
                f"- CID: {pkg.version}",
            ]), flush=True)

    def _print_packaging_banner(self):
        if self._ansi_supported:
            print("\n".join([
                "",
                "â•­â”€â”€â”€â”€",
                f"â”‚ ğŸ—ï¸  \033[1mPackaging\033[0m",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®",
            ]), flush=True)
        else:
            print("\n".join([
                "",
                f"# Packaging",
            ]), flush=True)

    def _print_summary_banner(self):
        if self._ansi_supported:
            print("\n".join([
                "",
                "â•­â”€â”€â”€â”€",
                f"â”‚ ğŸ‰ \033[1mDone\033[0m",
                "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®",
            ]), flush=True)
        else:
            print("\n".join([
                "",
                f"# Done",
```