Response:
Let's break down the thought process for analyzing this Python code.

1. **Understand the Goal:** The request asks for a functional breakdown of a specific Python file within the Frida project. It also asks to relate the functionality to reverse engineering, low-level concepts, and potential user errors, along with providing debugging context. Finally, a high-level summary is requested.

2. **Initial Scan and Context:** I quickly scan the file to understand its overall structure. I see a Python class `AllPlatformsTests` inheriting from `BasePlatformTests`. This immediately suggests it's a test suite. The presence of methods starting with `test_` reinforces this. The file path `frida/subprojects/frida-core/releng/meson/unittests/allplatformstests.py` tells me it's part of the Frida Core project's release engineering (`releng`), specifically for unit tests within the Meson build system. The "allplatforms" part hints that these tests are likely designed to be run across different operating systems and architectures.

3. **Analyze Individual Test Methods:** I go through each `test_` method, trying to understand what it's testing. For each test, I ask myself:
    * What is the setup? (What files/directories are involved? What commands are being run in `self.init`?)
    * What action is being tested? (What `self.build()` or `self._run()` calls are made?)
    * What is the assertion or verification? (What `self.assertEqual`, `self.assertIn`, `self.assertRaises`, etc., are used to check the outcome?)

4. **Categorize Functionality:** As I analyze the tests, I start grouping them by the type of functionality they are verifying. Common themes emerge:
    * **Build System Interaction:** Many tests deal with Meson's configuration (`self.init`, `self.setconf`), building (`self.build`), and installation (`self.install`). This is expected for a file within a build system's test suite.
    * **Environment Variables:** Several tests manipulate and verify the handling of environment variables (`override_envvars`).
    * **Installation Process:**  Tests like `test_install_skip_subprojects` and `test_install_tag` specifically focus on the installation process, including options for skipping subprojects and tagging installed files.
    * **Developer Environment:**  `test_devenv` examines the creation of developer environment scripts.
    * **Code Formatting:** `test_clang_format_check` deals with code formatting checks.
    * **Custom Targets:** Several tests involve custom build targets (`test_custom_target_implicit_include`, `test_custom_target_name`).
    * **Subprojects:**  Tests cover the inclusion and handling of subprojects (`test_install_skip_subprojects`, `test_adding_subproject_to_configure_project`, `test_symlinked_subproject`).
    * **Compiler/Linker Flags:** `test_env_flags_to_linker` checks how compiler and linker flags are passed.
    * **Introspection:** `test_introspect_install_plan` verifies the output of Meson's introspection capabilities.
    * **Language-Specific Features:** Tests with `@skip_if_not_language` highlight testing for specific languages like Rust.
    * **Configuration Persistence:** `test_configure_same_noop` tests whether re-configuring with the same settings is a no-op.
    * **Language Standards:** `test_c_cpp_stds` verifies handling of C and C++ standard versions.

5. **Relate to Reverse Engineering, Low-Level Concepts, etc.:**  After understanding the individual tests, I go back and consider how they relate to the specific points raised in the prompt:

    * **Reverse Engineering:** I look for tests that indirectly relate to understanding software behavior. Tests involving inspecting build outputs, compiler flags, and how libraries are linked can be relevant in a reverse engineering context. Frida itself is a dynamic instrumentation tool, so understanding how its components are built and configured is valuable.
    * **Binary/Low-Level:** Tests involving compiler flags (like LTO), shared libraries, static libraries, and the installation of binaries directly touch on binary-level concepts. The mention of PDB files (debugging symbols) is another indicator.
    * **Linux/Android Kernels/Frameworks:**  While this specific test file doesn't directly interact with kernel code, the fact that Frida *does* interact with these layers makes testing the build process relevant. The mention of `exe_suffix` and handling of different operating systems points to cross-platform concerns.
    * **Logical Inference:** I try to identify tests where a specific input or configuration should lead to a predictable output or behavior. The "assumptions" and "outputs" in the analysis are examples of this.
    * **User Errors:**  I look for tests that implicitly cover common mistakes, like providing invalid configuration options or having issues with dependencies.

6. **Debugging Context:**  I consider how a developer might end up looking at this file. They might be:
    * **Debugging build issues:**  If Frida isn't building correctly on a certain platform.
    * **Adding a new feature:** To ensure their changes don't break existing functionality.
    * **Investigating installation problems:** If files aren't being installed where they should be.
    * **Understanding the build system:** To contribute to Frida's development.

7. **High-Level Summary:** Finally, I synthesize the information gathered into a concise summary that captures the main purpose of the file. The key takeaway is that it's a unit test suite for Frida's core build process using Meson.

8. **Refinement and Organization:**  Throughout the process, I refine my explanations, ensuring clarity and accuracy. I organize the information logically using headings and bullet points to make it easier to understand. I also try to use the correct terminology related to build systems and software development.

Essentially, the process involves a combination of code comprehension, pattern recognition, and connecting the specific details to the broader context of the Frida project and the principles of software development and testing.
This Python file, `allplatformstests.py`, is a crucial part of the Frida dynamic instrumentation tool's build system tests. It contains a comprehensive suite of unit tests designed to verify the correct behavior of the Frida Core build process across various platforms. It leverages the Meson build system for defining and managing the build.

Here's a breakdown of its functions:

**Core Functionality: Testing the Frida Core Build Process**

The primary goal of this file is to ensure that the Frida Core library and its associated components can be built, configured, and installed correctly under different conditions and on various operating systems. It tests various aspects of the build system, including:

* **Basic Compilation and Linking:**  Ensures that simple C/C++ code can be compiled and linked into executables and libraries.
* **Handling of Build Options:** Tests the ability to configure the build using various Meson options (e.g., defining variables, enabling/disabling features, setting install prefixes).
* **Subproject Management:** Verifies the correct handling of subprojects, including building them, skipping them during installation, and adding new ones.
* **Installation Procedures:** Tests the installation process, including dry runs, specifying installation directories, and selectively installing components based on tags.
* **Environment Variable Handling:** Checks how the build system interacts with environment variables (e.g., `CFLAGS`, `LDFLAGS`).
* **Custom Targets:**  Tests the functionality of custom build targets and their dependencies.
* **Code Formatting Checks:** Includes tests for enforcing code style using `clang-format`.
* **Introspection Capabilities:** Verifies Meson's introspection features, allowing inspection of the build plan.
* **Language-Specific Features:**  Contains tests for specific languages like Rust, including linting with `clippy`.
* **Configuration Persistence:**  Ensures that re-configuring the build with the same options doesn't trigger unnecessary rebuilds.
* **Handling of C/C++ Standards:** Tests the ability to specify and enforce C and C++ language standards.

**Relationship to Reverse Engineering:**

While the file itself doesn't directly perform reverse engineering, it's *fundamental* to ensuring that the Frida tool, which *is* used for reverse engineering, is built correctly. Here's how it connects:

* **Correctly Built Frida Core:**  A properly built Frida Core is essential for reliable dynamic instrumentation. These tests guarantee that the core components are functional. Without a working core, reverse engineering tasks using Frida would be impossible.
* **Understanding Build Dependencies:**  The tests implicitly reveal the dependencies and build process of Frida Core. Understanding how Frida is built can be helpful for advanced users or those looking to contribute to the project or debug issues. Knowing how libraries are linked, for example, can be relevant when analyzing Frida's behavior.
* **Testing Core Functionality Indirectly:** Some tests, like those involving custom targets and shared libraries, touch upon concepts relevant to how Frida interacts with target processes during instrumentation. Ensuring these build components are working correctly indirectly validates the foundation for Frida's reverse engineering capabilities.

**Example:**  Imagine a test that verifies the building of a shared library (`.so` on Linux, `.dylib` on macOS, `.dll` on Windows). This shared library might contain essential Frida functionality used for attaching to processes or injecting code. If this test fails, it indicates a problem in the core build process that would directly hinder Frida's ability to perform its reverse engineering tasks.

**Involvement of Binary, Linux, Android Kernel/Framework Knowledge:**

This test suite heavily relies on knowledge of binary formats, operating system specifics (especially Linux and potentially Android), and build system mechanics:

* **Binary Formats and Linking:** Tests involving shared and static libraries, executables, and debugging symbols (`.pdb`) demonstrate an understanding of binary formats and the linking process. The tests need to know what kind of output to expect on different platforms.
* **Linux/macOS/Windows Differences:** The code often includes platform-specific checks (e.g., using `is_windows()`, `is_osx()`, `exe_suffix`) to handle variations in file extensions, library naming conventions, and executable formats across different operating systems. This is crucial because Frida aims to be cross-platform.
* **Kernel Interaction (Indirect):**  While the *tests* don't directly touch the kernel, the *components being tested* (Frida Core) do. The correct building and linking of these components are prerequisites for Frida's kernel-level instrumentation capabilities on Linux and Android.
* **Android Framework (Indirect):**  If Frida Core targets Android, the build process might involve specific steps related to the Android NDK (Native Development Kit) and framework libraries. While not explicitly shown in this snippet, the broader test suite likely includes tests relevant to Android builds.
* **Build System Internals (Meson):** The tests deeply interact with Meson's API, using functions like `self.init`, `self.build`, `self.setconf`, and inspecting Meson's output and introspection data.

**Example:** The `test_install_tag` function demonstrates awareness of different shared library naming conventions (`lib<name>.so`, `lib<name>.dylib`, `<name>.dll`) on various platforms, reflecting knowledge of operating system specifics.

**Logical Inference (Hypothetical Inputs and Outputs):**

Let's take the `test_env_flags_to_linker` function as an example of logical inference:

* **Hypothetical Input:** The test sets environment variables `CFLAGS` to `-DCFLAG` and `LDFLAGS` to `-flto`. It then checks different compiler behaviors (`INVOKES_LINKER` being True or False).
* **Logical Rule:** If the compiler acts as a linker driver (`INVOKES_LINKER` is True), then the flags in `CFLAGS` should also be passed to the linker, in addition to `LDFLAGS`. If it doesn't, only `LDFLAGS` should be passed.
* **Expected Output:**
    * When `INVOKES_LINKER` is True, the `link_args` should contain both `-DCFLAG` and `-flto`.
    * When `INVOKES_LINKER` is False, the `link_args` should only contain `-flto`.

**User or Programming Common Usage Errors:**

This test suite helps prevent common errors that users or developers might encounter:

* **Incorrect Build Options:** Tests like those involving `-D` options (defining variables) ensure that users can configure the build correctly. If a user provides an invalid option or value, the build system (and ideally, these tests) should catch it.
* **Missing Dependencies:** While not explicitly shown here, other parts of the test suite likely verify that required dependencies are present. If a user tries to build Frida without necessary libraries, the build should fail, and tests help ensure this happens predictably.
* **Platform-Specific Issues:** The cross-platform nature of the tests helps identify and prevent issues that might only occur on specific operating systems. A user might encounter a build error on Windows that wouldn't happen on Linux, and these tests aim to catch such discrepancies.
* **Incorrect Installation Paths:** Tests related to installation (`test_install_tag`, `test_install_skip_subprojects`) ensure that files are placed in the expected locations. If a user installs Frida and can't find the binaries or libraries, it could be due to an installation problem that these tests are designed to prevent.

**Example:** The `test_c_cpp_stds` function validates the handling of C and C++ standard options. If a user tries to specify an invalid standard (e.g., `-Dc_std=invalid`), this test will raise an error, preventing the build from proceeding with an incorrect configuration.

**User Operation Steps to Reach Here (Debugging Context):**

A developer or advanced user might end up examining this file while debugging various issues:

1. **Build Failure:** A user attempts to build Frida Core and encounters an error during the build process. They might look at the build logs, which might point to a failure in one of the unit tests defined in `allplatformstests.py`.
2. **Installation Problems:** After a successful build, the user finds that Frida is not installed correctly (e.g., binaries are missing, libraries are in the wrong place). They might investigate the installation-related tests in this file to understand how the installation process is supposed to work and identify potential issues.
3. **Contributing to Frida:** A developer wants to contribute a new feature or fix a bug in Frida Core. They might examine this test suite to understand the existing testing framework and add new tests to verify their changes.
4. **Understanding the Build System:** A developer wants to understand how Frida Core is built and configured using Meson. They might browse through this file to see examples of how different build options and features are tested.
5. **Investigating a Test Failure:** During development or continuous integration, one of the tests in this file might fail. Developers would then examine the specific test case and the code it tests to diagnose the root cause of the failure.

**Summary of Functionality (Part 7 of 7):**

As the final part of a multi-part exploration of this file, we can summarize its overall function:

This `allplatformstests.py` file serves as the **comprehensive integration test suite for the Frida Core build process, utilizing the Meson build system.** It ensures the reliability and correctness of the core Frida library across various platforms by verifying a wide range of build configurations, installation procedures, and interactions with the underlying operating system and build tools. Its purpose is to catch potential errors and inconsistencies in the build process, guaranteeing that users and developers can build and install Frida Core correctly, which is fundamental for its dynamic instrumentation capabilities. It plays a crucial role in maintaining the quality and cross-platform compatibility of the Frida project.

### 提示词
```
这是目录为frida/subprojects/frida-core/releng/meson/unittests/allplatformstests.py的fridaDynamic instrumentation tool的源代码文件， 请列举一下它的功能, 
如果它与逆向的方法有关系，请做出对应的举例说明，
如果涉及到二进制底层，linux, android内核及框架的知识，请做出对应的举例说明，
如果做了逻辑推理，请给出假设输入与输出,
如果涉及用户或者编程常见的使用错误，请举例说明,
说明用户操作是如何一步步的到达这里，作为调试线索。
这是第7部分，共7部分，请归纳一下它的功能
```

### 源代码
```python
DCXXFLAG'}
        srcdir = os.path.join(self.unit_test_dir, '88 multiple envvars')
        self.init(srcdir, override_envvars=envs)
        self.build()

    def test_build_b_options(self) -> None:
        # Currently (0.57) these do nothing, but they've always been allowed
        srcdir = os.path.join(self.common_test_dir, '2 cpp')
        self.init(srcdir, extra_args=['-Dbuild.b_lto=true'])

    def test_install_skip_subprojects(self):
        testdir = os.path.join(self.unit_test_dir, '92 install skip subprojects')
        self.init(testdir)
        self.build()

        main_expected = [
            '',
            'share',
            'include',
            'foo',
            'bin',
            'share/foo',
            'share/foo/foo.dat',
            'include/foo.h',
            'foo/foofile',
            'bin/foo' + exe_suffix,
        ]
        bar_expected = [
            'bar',
            'share/bar',
            'share/bar/bar.dat',
            'include/bar.h',
            'bin/bar' + exe_suffix,
            'bar/barfile'
        ]
        env = get_fake_env(testdir, self.builddir, self.prefix)
        cc = detect_c_compiler(env, MachineChoice.HOST)
        if cc.get_argument_syntax() == 'msvc':
            main_expected.append('bin/foo.pdb')
            bar_expected.append('bin/bar.pdb')
        prefix = destdir_join(self.installdir, self.prefix)
        main_expected = [Path(prefix, p) for p in main_expected]
        bar_expected = [Path(prefix, p) for p in bar_expected]
        all_expected = main_expected + bar_expected

        def check_installed_files(extra_args, expected):
            args = ['install', '--destdir', self.installdir] + extra_args
            self._run(self.meson_command + args, workdir=self.builddir)
            all_files = [p for p in Path(self.installdir).rglob('*')]
            self.assertEqual(sorted(expected), sorted(all_files))
            windows_proof_rmtree(self.installdir)

        check_installed_files([], all_expected)
        check_installed_files(['--skip-subprojects'], main_expected)
        check_installed_files(['--skip-subprojects', 'bar'], main_expected)
        check_installed_files(['--skip-subprojects', 'another'], all_expected)

    def test_adding_subproject_to_configure_project(self) -> None:
        srcdir = os.path.join(self.unit_test_dir, '93 new subproject in configured project')
        self.init(srcdir)
        self.build()
        self.setconf('-Duse-sub=true')
        self.build()

    def test_devenv(self):
        testdir = os.path.join(self.unit_test_dir, '90 devenv')
        self.init(testdir)
        self.build()

        cmd = self.meson_command + ['devenv', '-C', self.builddir]
        script = os.path.join(testdir, 'test-devenv.py')
        app = os.path.join(self.builddir, 'app')
        self._run(cmd + python_command + [script])
        self.assertEqual('This is text.', self._run(cmd + [app]).strip())

        cmd = self.meson_command + ['devenv', '-C', self.builddir, '--dump']
        o = self._run(cmd)
        expected = os.pathsep.join(['/prefix', '$TEST_C', '/suffix'])
        self.assertIn(f'TEST_C="{expected}"', o)
        self.assertIn('export TEST_C', o)

        cmd = self.meson_command + ['devenv', '-C', self.builddir, '--dump', '--dump-format', 'sh']
        o = self._run(cmd)
        expected = os.pathsep.join(['/prefix', '$TEST_C', '/suffix'])
        self.assertIn(f'TEST_C="{expected}"', o)
        self.assertNotIn('export', o)

        cmd = self.meson_command + ['devenv', '-C', self.builddir, '--dump', '--dump-format', 'vscode']
        o = self._run(cmd)
        expected = os.pathsep.join(['/prefix', '/suffix'])
        self.assertIn(f'TEST_C="{expected}"', o)
        self.assertNotIn('export', o)

        fname = os.path.join(self.builddir, 'dump.env')
        cmd = self.meson_command + ['devenv', '-C', self.builddir, '--dump', fname]
        o = self._run(cmd)
        self.assertEqual(o, '')
        o = Path(fname).read_text(encoding='utf-8')
        expected = os.pathsep.join(['/prefix', '$TEST_C', '/suffix'])
        self.assertIn(f'TEST_C="{expected}"', o)
        self.assertIn('export TEST_C', o)

    def test_clang_format_check(self):
        if self.backend is not Backend.ninja:
            raise SkipTest(f'Skipping clang-format tests with {self.backend.name} backend')
        if not shutil.which('clang-format'):
            raise SkipTest('clang-format not found')

        testdir = os.path.join(self.unit_test_dir, '94 clangformat')
        newdir = os.path.join(self.builddir, 'testdir')
        shutil.copytree(testdir, newdir)
        self.new_builddir()
        self.init(newdir)

        # Should reformat 1 file but not return error
        output = self.build('clang-format')
        self.assertEqual(1, output.count('File reformatted:'))

        # Reset source tree then try again with clang-format-check, it should
        # return an error code this time.
        windows_proof_rmtree(newdir)
        shutil.copytree(testdir, newdir)
        with self.assertRaises(subprocess.CalledProcessError):
            output = self.build('clang-format-check')
            self.assertEqual(1, output.count('File reformatted:'))

        # The check format should not touch any files. Thus
        # running format again has some work to do.
        output = self.build('clang-format')
        self.assertEqual(1, output.count('File reformatted:'))
        self.build('clang-format-check')

    def test_custom_target_implicit_include(self):
        testdir = os.path.join(self.unit_test_dir, '95 custominc')
        self.init(testdir)
        self.build()
        compdb = self.get_compdb()
        matches = 0
        for c in compdb:
            if 'prog.c' in c['file']:
                self.assertNotIn('easytogrepfor', c['command'])
                matches += 1
        self.assertEqual(matches, 1)
        matches = 0
        for c in compdb:
            if 'prog2.c' in c['file']:
                self.assertIn('easytogrepfor', c['command'])
                matches += 1
        self.assertEqual(matches, 1)

    def test_env_flags_to_linker(self) -> None:
        # Compilers that act as drivers should add their compiler flags to the
        # linker, those that do not shouldn't
        with mock.patch.dict(os.environ, {'CFLAGS': '-DCFLAG', 'LDFLAGS': '-flto'}):
            env = get_fake_env()

            # Get the compiler so we know which compiler class to mock.
            cc =  detect_compiler_for(env, 'c', MachineChoice.HOST, True, '')
            cc_type = type(cc)

            # Test a compiler that acts as a linker
            with mock.patch.object(cc_type, 'INVOKES_LINKER', True):
                cc =  detect_compiler_for(env, 'c', MachineChoice.HOST, True, '')
                link_args = env.coredata.get_external_link_args(cc.for_machine, cc.language)
                self.assertEqual(sorted(link_args), sorted(['-DCFLAG', '-flto']))

            # And one that doesn't
            with mock.patch.object(cc_type, 'INVOKES_LINKER', False):
                cc =  detect_compiler_for(env, 'c', MachineChoice.HOST, True, '')
                link_args = env.coredata.get_external_link_args(cc.for_machine, cc.language)
                self.assertEqual(sorted(link_args), sorted(['-flto']))

    def test_install_tag(self) -> None:
        testdir = os.path.join(self.unit_test_dir, '99 install all targets')
        self.init(testdir)
        self.build()

        env = get_fake_env(testdir, self.builddir, self.prefix)
        cc = detect_c_compiler(env, MachineChoice.HOST)

        def shared_lib_name(name):
            if cc.get_id() in {'msvc', 'clang-cl'}:
                return f'bin/{name}.dll'
            elif is_windows():
                return f'bin/lib{name}.dll'
            elif is_cygwin():
                return f'bin/cyg{name}.dll'
            elif is_osx():
                return f'lib/lib{name}.dylib'
            return f'lib/lib{name}.so'

        def exe_name(name):
            if is_windows() or is_cygwin():
                return f'{name}.exe'
            return name

        installpath = Path(self.installdir)

        expected_common = {
            installpath,
            Path(installpath, 'usr'),
        }

        expected_devel = expected_common | {
            Path(installpath, 'usr/include'),
            Path(installpath, 'usr/include/bar-devel.h'),
            Path(installpath, 'usr/include/bar2-devel.h'),
            Path(installpath, 'usr/include/foo1-devel.h'),
            Path(installpath, 'usr/include/foo2-devel.h'),
            Path(installpath, 'usr/include/foo3-devel.h'),
            Path(installpath, 'usr/include/out-devel.h'),
            Path(installpath, 'usr/lib'),
            Path(installpath, 'usr/lib/libstatic.a'),
            Path(installpath, 'usr/lib/libboth.a'),
            Path(installpath, 'usr/lib/libboth2.a'),
            Path(installpath, 'usr/include/ct-header1.h'),
            Path(installpath, 'usr/include/ct-header3.h'),
            Path(installpath, 'usr/include/subdir-devel'),
            Path(installpath, 'usr/include/custom_files'),
            Path(installpath, 'usr/include/custom_files/data.txt'),
        }

        if cc.get_id() in {'msvc', 'clang-cl'}:
            expected_devel |= {
                Path(installpath, 'usr/bin'),
                Path(installpath, 'usr/bin/app.pdb'),
                Path(installpath, 'usr/bin/app2.pdb'),
                Path(installpath, 'usr/bin/both.pdb'),
                Path(installpath, 'usr/bin/both2.pdb'),
                Path(installpath, 'usr/bin/bothcustom.pdb'),
                Path(installpath, 'usr/bin/shared.pdb'),
                Path(installpath, 'usr/bin/versioned_shared-1.pdb'),
                Path(installpath, 'usr/lib/both.lib'),
                Path(installpath, 'usr/lib/both2.lib'),
                Path(installpath, 'usr/lib/bothcustom.lib'),
                Path(installpath, 'usr/lib/shared.lib'),
                Path(installpath, 'usr/lib/versioned_shared.lib'),
                Path(installpath, 'usr/otherbin'),
                Path(installpath, 'usr/otherbin/app-otherdir.pdb'),
            }
        elif is_windows() or is_cygwin():
            expected_devel |= {
                Path(installpath, 'usr/lib/libboth.dll.a'),
                Path(installpath, 'usr/lib/libboth2.dll.a'),
                Path(installpath, 'usr/lib/libshared.dll.a'),
                Path(installpath, 'usr/lib/libbothcustom.dll.a'),
                Path(installpath, 'usr/lib/libversioned_shared.dll.a'),
            }
        else:
            expected_devel |= {
                Path(installpath, 'usr/' + shared_lib_name('versioned_shared')),
            }

        expected_runtime = expected_common | {
            Path(installpath, 'usr/bin'),
            Path(installpath, 'usr/bin/' + exe_name('app')),
            Path(installpath, 'usr/otherbin'),
            Path(installpath, 'usr/otherbin/' + exe_name('app-otherdir')),
            Path(installpath, 'usr/bin/' + exe_name('app2')),
            Path(installpath, 'usr/' + shared_lib_name('shared')),
            Path(installpath, 'usr/' + shared_lib_name('both')),
            Path(installpath, 'usr/' + shared_lib_name('both2')),
        }

        if is_windows() or is_cygwin():
            expected_runtime |= {
                Path(installpath, 'usr/' + shared_lib_name('versioned_shared-1')),
            }
        elif is_osx():
            expected_runtime |= {
                Path(installpath, 'usr/' + shared_lib_name('versioned_shared.1')),
            }
        else:
            expected_runtime |= {
                Path(installpath, 'usr/' + shared_lib_name('versioned_shared') + '.1'),
                Path(installpath, 'usr/' + shared_lib_name('versioned_shared') + '.1.2.3'),
            }

        expected_custom = expected_common | {
            Path(installpath, 'usr/share'),
            Path(installpath, 'usr/share/bar-custom.txt'),
            Path(installpath, 'usr/share/foo-custom.h'),
            Path(installpath, 'usr/share/out1-custom.txt'),
            Path(installpath, 'usr/share/out2-custom.txt'),
            Path(installpath, 'usr/share/out3-custom.txt'),
            Path(installpath, 'usr/share/custom_files'),
            Path(installpath, 'usr/share/custom_files/data.txt'),
            Path(installpath, 'usr/share/excludes'),
            Path(installpath, 'usr/share/excludes/installed.txt'),
            Path(installpath, 'usr/lib'),
            Path(installpath, 'usr/lib/libbothcustom.a'),
            Path(installpath, 'usr/' + shared_lib_name('bothcustom')),
        }

        if is_windows() or is_cygwin():
            expected_custom |= {Path(installpath, 'usr/bin')}
        else:
            expected_runtime |= {Path(installpath, 'usr/lib')}

        expected_runtime_custom = expected_runtime | expected_custom

        expected_all = expected_devel | expected_runtime | expected_custom | {
            Path(installpath, 'usr/share/foo-notag.h'),
            Path(installpath, 'usr/share/bar-notag.txt'),
            Path(installpath, 'usr/share/out1-notag.txt'),
            Path(installpath, 'usr/share/out2-notag.txt'),
            Path(installpath, 'usr/share/out3-notag.txt'),
            Path(installpath, 'usr/share/foo2.h'),
            Path(installpath, 'usr/share/out1.txt'),
            Path(installpath, 'usr/share/out2.txt'),
            Path(installpath, 'usr/share/subproject'),
            Path(installpath, 'usr/share/subproject/aaa.txt'),
            Path(installpath, 'usr/share/subproject/bbb.txt'),
        }

        def do_install(tags, expected_files, expected_scripts):
            cmd = self.meson_command + ['install', '--dry-run', '--destdir', self.installdir]
            cmd += ['--tags', tags] if tags else []
            stdout = self._run(cmd, workdir=self.builddir)
            installed = self.read_install_logs()
            self.assertEqual(sorted(expected_files), sorted(installed))
            self.assertEqual(expected_scripts, stdout.count('Running custom install script'))

        do_install('devel', expected_devel, 0)
        do_install('runtime', expected_runtime, 0)
        do_install('custom', expected_custom, 1)
        do_install('runtime,custom', expected_runtime_custom, 1)
        do_install(None, expected_all, 2)


    def test_install_script_dry_run(self):
        testdir = os.path.join(self.common_test_dir, '53 install script')
        self.init(testdir)
        self.build()

        cmd = self.meson_command + ['install', '--dry-run', '--destdir', self.installdir]
        outputs = self._run(cmd, workdir=self.builddir)

        installpath = Path(self.installdir)
        self.assertFalse((installpath / 'usr/diiba/daaba/file.dat').exists())
        self.assertIn("DRYRUN: Writing file file.dat", outputs)


    def test_introspect_install_plan(self):
        testdir = os.path.join(self.unit_test_dir, '99 install all targets')
        introfile = os.path.join(self.builddir, 'meson-info', 'intro-install_plan.json')
        self.init(testdir)
        self.assertPathExists(introfile)
        with open(introfile, encoding='utf-8') as fp:
            res = json.load(fp)

        env = get_fake_env(testdir, self.builddir, self.prefix)

        def output_name(name, type_):
            target = type_(name=name, subdir=None, subproject=None,
                           for_machine=MachineChoice.HOST, sources=[],
                           structured_sources=None,
                           objects=[], environment=env, compilers=env.coredata.compilers[MachineChoice.HOST],
                           build_only_subproject=False, kwargs={})
            target.process_compilers_late()
            return target.filename

        shared_lib_name = lambda name: output_name(name, SharedLibrary)
        static_lib_name = lambda name: output_name(name, StaticLibrary)
        exe_name = lambda name: output_name(name, Executable)

        expected = {
            'targets': {
                f'{self.builddir}/out1-notag.txt': {
                    'destination': '{datadir}/out1-notag.txt',
                    'tag': None,
                    'subproject': None,
                },
                f'{self.builddir}/out2-notag.txt': {
                    'destination': '{datadir}/out2-notag.txt',
                    'tag': None,
                    'subproject': None,
                },
                f'{self.builddir}/libstatic.a': {
                    'destination': '{libdir_static}/libstatic.a',
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{self.builddir}/' + exe_name('app'): {
                    'destination': '{bindir}/' + exe_name('app'),
                    'tag': 'runtime',
                    'subproject': None,
                },
                f'{self.builddir}/' + exe_name('app-otherdir'): {
                    'destination': '{prefix}/otherbin/' + exe_name('app-otherdir'),
                    'tag': 'runtime',
                    'subproject': None,
                },
                f'{self.builddir}/subdir/' + exe_name('app2'): {
                    'destination': '{bindir}/' + exe_name('app2'),
                    'tag': 'runtime',
                    'subproject': None,
                },
                f'{self.builddir}/' + shared_lib_name('shared'): {
                    'destination': '{libdir_shared}/' + shared_lib_name('shared'),
                    'tag': 'runtime',
                    'subproject': None,
                },
                f'{self.builddir}/' + shared_lib_name('both'): {
                    'destination': '{libdir_shared}/' + shared_lib_name('both'),
                    'tag': 'runtime',
                    'subproject': None,
                },
                f'{self.builddir}/' + static_lib_name('both'): {
                    'destination': '{libdir_static}/' + static_lib_name('both'),
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{self.builddir}/' + shared_lib_name('bothcustom'): {
                    'destination': '{libdir_shared}/' + shared_lib_name('bothcustom'),
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{self.builddir}/' + static_lib_name('bothcustom'): {
                    'destination': '{libdir_static}/' + static_lib_name('bothcustom'),
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{self.builddir}/subdir/' + shared_lib_name('both2'): {
                    'destination': '{libdir_shared}/' + shared_lib_name('both2'),
                    'tag': 'runtime',
                    'subproject': None,
                },
                f'{self.builddir}/subdir/' + static_lib_name('both2'): {
                    'destination': '{libdir_static}/' + static_lib_name('both2'),
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{self.builddir}/out1-custom.txt': {
                    'destination': '{datadir}/out1-custom.txt',
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{self.builddir}/out2-custom.txt': {
                    'destination': '{datadir}/out2-custom.txt',
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{self.builddir}/out3-custom.txt': {
                    'destination': '{datadir}/out3-custom.txt',
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{self.builddir}/subdir/out1.txt': {
                    'destination': '{datadir}/out1.txt',
                    'tag': None,
                    'subproject': None,
                },
                f'{self.builddir}/subdir/out2.txt': {
                    'destination': '{datadir}/out2.txt',
                    'tag': None,
                    'subproject': None,
                },
                f'{self.builddir}/out-devel.h': {
                    'destination': '{includedir}/out-devel.h',
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{self.builddir}/out3-notag.txt': {
                    'destination': '{datadir}/out3-notag.txt',
                    'tag': None,
                    'subproject': None,
                },
            },
            'configure': {
                f'{self.builddir}/foo-notag.h': {
                    'destination': '{datadir}/foo-notag.h',
                    'tag': None,
                    'subproject': None,
                },
                f'{self.builddir}/foo2-devel.h': {
                    'destination': '{includedir}/foo2-devel.h',
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{self.builddir}/foo-custom.h': {
                    'destination': '{datadir}/foo-custom.h',
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{self.builddir}/subdir/foo2.h': {
                    'destination': '{datadir}/foo2.h',
                    'tag': None,
                    'subproject': None,
                },
            },
            'data': {
                f'{testdir}/bar-notag.txt': {
                    'destination': '{datadir}/bar-notag.txt',
                    'tag': None,
                    'subproject': None,
                },
                f'{testdir}/bar-devel.h': {
                    'destination': '{includedir}/bar-devel.h',
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{testdir}/bar-custom.txt': {
                    'destination': '{datadir}/bar-custom.txt',
                    'tag': 'custom',
                    'subproject': None,
                },
                f'{testdir}/subdir/bar2-devel.h': {
                    'destination': '{includedir}/bar2-devel.h',
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{testdir}/subprojects/subproject/aaa.txt': {
                    'destination': '{datadir}/subproject/aaa.txt',
                    'tag': None,
                    'subproject': 'subproject',
                },
                f'{testdir}/subprojects/subproject/bbb.txt': {
                    'destination': '{datadir}/subproject/bbb.txt',
                    'tag': 'data',
                    'subproject': 'subproject',
                },
            },
            'headers': {
                f'{testdir}/foo1-devel.h': {
                    'destination': '{includedir}/foo1-devel.h',
                    'tag': 'devel',
                    'subproject': None,
                },
                f'{testdir}/subdir/foo3-devel.h': {
                    'destination': '{includedir}/foo3-devel.h',
                    'tag': 'devel',
                    'subproject': None,
                },
            },
            'install_subdirs': {
                f'{testdir}/custom_files': {
                    'destination': '{datadir}/custom_files',
                    'tag': 'custom',
                    'subproject': None,
                    'exclude_dirs': [],
                    'exclude_files': [],
                },
                f'{testdir}/excludes': {
                    'destination': '{datadir}/excludes',
                    'tag': 'custom',
                    'subproject': None,
                    'exclude_dirs': ['excluded'],
                    'exclude_files': ['excluded.txt'],
                }
            }
        }

        fix_path = lambda path: os.path.sep.join(path.split('/'))
        expected_fixed = {
            data_type: {
                fix_path(source): {
                    key: fix_path(value) if key == 'destination' else value
                    for key, value in attributes.items()
                }
                for source, attributes in files.items()
            }
            for data_type, files in expected.items()
        }

        for data_type, files in expected_fixed.items():
            for file, details in files.items():
                with self.subTest(key='{}.{}'.format(data_type, file)):
                    self.assertEqual(res[data_type][file], details)

    @skip_if_not_language('rust')
    @unittest.skipIf(not shutil.which('clippy-driver'), 'Test requires clippy-driver')
    def test_rust_clippy(self) -> None:
        if self.backend is not Backend.ninja:
            raise unittest.SkipTest('Rust is only supported with ninja currently')
        # When clippy is used, we should get an exception since a variable named
        # "foo" is used, but is on our denylist
        testdir = os.path.join(self.rust_test_dir, '1 basic')
        self.init(testdir, extra_args=['--werror'], override_envvars={'RUSTC': 'clippy-driver'})
        with self.assertRaises(subprocess.CalledProcessError) as cm:
            self.build()
        self.assertTrue('error: use of a blacklisted/placeholder name `foo`' in cm.exception.stdout or
                        'error: use of a disallowed/placeholder name `foo`' in cm.exception.stdout)

    @skip_if_not_language('rust')
    def test_rust_rlib_linkage(self) -> None:
        if self.backend is not Backend.ninja:
            raise unittest.SkipTest('Rust is only supported with ninja currently')
        template = textwrap.dedent('''\
                use std::process::exit;

                pub fn fun() {{
                    exit({});
                }}
            ''')

        testdir = os.path.join(self.unit_test_dir, '102 rlib linkage')
        gen_file = os.path.join(testdir, 'lib.rs')
        with open(gen_file, 'w', encoding='utf-8') as f:
            f.write(template.format(0))
        self.addCleanup(windows_proof_rm, gen_file)

        self.init(testdir)
        self.build()
        self.run_tests()

        with open(gen_file, 'w', encoding='utf-8') as f:
            f.write(template.format(39))

        self.build()
        with self.assertRaises(subprocess.CalledProcessError) as cm:
            self.run_tests()
        self.assertEqual(cm.exception.returncode, 1)
        self.assertIn('exit status 39', cm.exception.stdout)

    @skip_if_not_language('rust')
    def test_bindgen_drops_invalid(self) -> None:
        if self.backend is not Backend.ninja:
            raise unittest.SkipTest('Rust is only supported with ninja currently')
        testdir = os.path.join(self.rust_test_dir, '12 bindgen')
        env = get_fake_env(testdir, self.builddir, self.prefix)
        cc = detect_c_compiler(env, MachineChoice.HOST)
        # bindgen understands compiler args that clang understands, but not
        # flags by other compilers
        if cc.get_id() == 'gcc':
            bad_arg = '-fdse'
        elif cc.get_id() == 'msvc':
            bad_arg = '/fastfail'
        else:
            raise unittest.SkipTest('Test only supports GCC and MSVC')
        self.init(testdir, extra_args=[f"-Dc_args=['-DCMD_ARG', '{bad_arg}']"])
        intro = self.introspect(['--targets'])
        for i in intro:
            if i['type'] == 'custom' and i['id'].startswith('rustmod-bindgen'):
                args = i['target_sources'][0]['compiler']
                self.assertIn('-DCMD_ARG', args)
                self.assertIn('-DPROJECT_ARG', args)
                self.assertIn('-DGLOBAL_ARG', args)
                self.assertNotIn(bad_arg, args)
                self.assertNotIn('-mtls-dialect=gnu2', args)
                self.assertNotIn('/fp:fast', args)
                return

    def test_custom_target_name(self):
        testdir = os.path.join(self.unit_test_dir, '100 custom target name')
        self.init(testdir)
        out = self.build()
        if self.backend is Backend.ninja:
            self.assertIn('Generating file.txt with a custom command', out)
            self.assertIn('Generating subdir/file.txt with a custom command', out)

    def test_symlinked_subproject(self):
        testdir = os.path.join(self.unit_test_dir, '107 subproject symlink')
        subproject_dir = os.path.join(testdir, 'subprojects')
        subproject = os.path.join(testdir, 'symlinked_subproject')
        symlinked_subproject = os.path.join(testdir, 'subprojects', 'symlinked_subproject')
        if not os.path.exists(subproject_dir):
            os.mkdir(subproject_dir)
        try:
            os.symlink(subproject, symlinked_subproject)
        except OSError:
            raise SkipTest("Symlinks are not available on this machine")
        self.addCleanup(os.remove, symlinked_subproject)

        self.init(testdir)
        self.build()

    def test_configure_same_noop(self):
        testdir = os.path.join(self.unit_test_dir, '109 configure same noop')
        args = [
            '-Dstring=val',
            '-Dboolean=true',
            '-Dcombo=two',
            '-Dinteger=7',
            '-Darray=[\'three\']',
            '-Dfeature=disabled',
            '--buildtype=plain',
            '--prefix=/abc',
        ]
        self.init(testdir, extra_args=args)

        filename = Path(self.privatedir) / 'coredata.dat'

        olddata = filename.read_bytes()
        oldmtime = os.path.getmtime(filename)

        for opt in ('-Dstring=val', '--buildtype=plain', '-Dfeature=disabled', '-Dprefix=/abc'):
            self.setconf([opt])
            newdata = filename.read_bytes()
            newmtime = os.path.getmtime(filename)
            self.assertEqual(oldmtime, newmtime)
            self.assertEqual(olddata, newdata)
            olddata = newdata
            oldmtime = newmtime

        for opt in ('-Dstring=abc', '--buildtype=release', '-Dfeature=enabled', '-Dprefix=/def'):
            self.setconf([opt])
            newdata = filename.read_bytes()
            newmtime = os.path.getmtime(filename)
            self.assertGreater(newmtime, oldmtime)
            self.assertNotEqual(olddata, newdata)
            olddata = newdata
            oldmtime = newmtime

    def test_c_cpp_stds(self):
        testdir = os.path.join(self.unit_test_dir, '115 c cpp stds')
        self.init(testdir)
        # Invalid values should fail whatever compiler we have
        with self.assertRaises(subprocess.CalledProcessError):
            self.setconf('-Dc_std=invalid')
        with self.assertRaises(subprocess.CalledProcessError):
            self.setconf('-Dc_std=c89,invalid')
        with self.assertRaises(subprocess.CalledProcessError):
            self.setconf('-Dc_std=c++11')
        env = get_fake_env()
        cc = detect_c_compiler(env, MachineChoice.HOST)
        if cc.get_id() == 'msvc':
            # default_option should have selected those
            self.assertEqual(self.getconf('c_std'), 'c89')
            self.assertEqual(self.getconf('cpp_std'), 'vc++11')
            # This is deprecated but works for C
            self.setconf('-Dc_std=gnu99')
            self.assertEqual(self.getconf('c_std'), 'c99')
            # C++ however never accepted that fallback
            with self.assertRaises(subprocess.CalledProcessError):
                self.setconf('-Dcpp_std=gnu++11')
            # The first supported std should be selected
            self.setconf('-Dcpp_std=gnu++11,vc++11,c++11')
            self.assertEqual(self.getconf('cpp_std'), 'vc++11')
        elif cc.get_id() == 'gcc':
            # default_option should have selected those
            self.assertEqual(self.getconf('c_std'), 'gnu89')
            self.assertEqual(self.getconf('cpp_std'), 'gnu++98')
            # The first supported std should be selected
            self.setconf('-Dcpp_std=c++11,gnu++11,vc++11')
            self.assertEqual(self.getconf('cpp_std'), 'c++11')
```