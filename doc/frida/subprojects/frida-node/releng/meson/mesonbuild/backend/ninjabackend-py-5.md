Response:
The user wants a summary of the functionality of the provided Python code, which is a part of the Ninja backend for the Meson build system. I need to analyze the code and identify its key actions, especially concerning:

1. **Core Functionality:** What does this code do in the build process?
2. **Relevance to Reverse Engineering:** Does it facilitate or relate to reverse engineering techniques?
3. **Binary/Kernel/Framework Interactions:** Does it deal with low-level aspects like binaries, Linux/Android kernels or frameworks?
4. **Logical Reasoning:** Are there parts where the code makes decisions based on input?
5. **Common User Errors:** What mistakes might a user make that would lead to this code being executed?
6. **User Operations as Debugging Clues:** How does a user's interaction with Meson lead to this code being run?
7. **Overall Summary:** A concise overview of the file's purpose.

Let's go through the code section by section:

*   **`generate_prelink`:** Deals with prelinking, which can be related to optimizing the linking process and potentially hindering simple reverse engineering.
*   **`generate_link`:**  Handles the core linking process, involving compilers, linkers, libraries, and various link arguments. This is crucial for generating executable binaries and libraries.
*   **`get_dependency_filename`:** Resolves filenames of dependencies, essential for the linking stage.
*   **`generate_shlib_aliases`:** Creates symbolic links for shared libraries, useful for versioning and can be relevant in understanding library dependencies.
*   **`generate_custom_target_clean`:**  Handles cleaning up outputs of custom build steps.
*   **`generate_gcov_clean`:** Cleans up files generated by the `gcov` coverage tool.
*   **`get_user_option_args`:**  Collects user-defined options, influencing the build process.
*   **`generate_dist`:** Creates distribution packages.
*   **`generate_scanbuild`:** Integrates with static analysis tools like `scan-build`.
*   **`generate_clangtool`**, **`generate_clangformat`**, **`generate_clangtidy`**, **`generate_tags`:**  Integrate with various clang tools for formatting, linting, and generating code tags.
*   **`generate_utils`:** A collection of utility target generations.
*   **`generate_ending`:** Generates final build targets like 'all', 'clean', and 'reconfigure'.
*   **`get_introspection_data`:** Provides data for Meson's introspection features.
*   **`_scan_fortran_file_deps`:**  Specifically handles dependency scanning for Fortran files.

Now, I will construct the answer based on these observations.
This Python code snippet is part of the Ninja backend for the Meson build system, specifically within the `ninjabackend.py` file. Its primary function is to translate Meson's build description into Ninja build files. Ninja is a small build system focused on speed, and this code helps bridge the gap between Meson's higher-level build concepts and Ninja's execution model.

Here's a breakdown of its functionalities:

**1. Generation of Ninja Build Rules for Linking:**

*   **`generate_prelink(self, target, prelink_name, obj_list, prelinker)`:** This function generates the Ninja commands necessary for prelinking. Prelinking is an optimization technique where some of the linking process is done ahead of time on relocatable object files.
    *   **Relevance to Reverse Engineering:** Prelinking can slightly complicate reverse engineering efforts as some address resolution is done early. This means the final linked binary might have addresses already assigned, which could differ from a simply linked binary. For instance, if you disassemble a prelinked shared library, the GOT (Global Offset Table) entries might already be populated with addresses from the prelinking stage.
    *   **Binary Bottom Layer:**  Prelinking operates at the level of object files and their relocations, which are fundamental concepts in binary formats.
    *   **Logical Reasoning (Example):**
        *   **Input:** A shared library target `mylib.so`, a prelinker command `ld.gold`, and a list of object files `[obj1.o, obj2.o]`.
        *   **Output:**  Ninja build rules that instruct Ninja to execute `ld.gold` with arguments specific to prelinking `mylib.so` from `obj1.o` and `obj2.o`. The output would be a prelinked object file.

*   **`generate_link(self, target: build.BuildTarget, outname, obj_list, linker: T.Union['Compiler', 'StaticLinker'], extra_args=None, stdlib_args=None)`:** This is a central function responsible for generating the Ninja commands for linking object files into executables, shared libraries, or static libraries. It meticulously constructs the linker command line, taking into account various factors like:
    *   Target type (executable, shared library, static library)
    *   Compiler and linker specifics
    *   Dependencies (internal and external libraries)
    *   Linker flags (optimization, debugging, RPATH)
    *   User-defined link arguments
    *   Standard library requirements
    *   **Relevance to Reverse Engineering:** The linker is the tool that creates the final binary. Understanding the linker flags and linked libraries is crucial for reverse engineering. For example, the presence of debug symbols (`-g` or `/DEBUG`) makes reverse engineering significantly easier. The libraries linked provide clues about the functionality and dependencies of the target.
    *   **Binary Bottom Layer:** This function directly interacts with the compiler and linker, which are fundamental tools in the binary creation process. Linker arguments control how different binary sections are merged and how symbols are resolved.
    *   **Linux/Android Kernel & Framework:** The generation of RPATH (`-Wl,-rpath`) is directly relevant to how shared libraries are located at runtime on Linux and Android. Understanding RPATH is vital when analyzing how applications load their dependencies. Linking against system libraries or framework components involves knowledge of the target operating system's structure.
    *   **Logical Reasoning (Example):**
        *   **Input:** An executable target `myprogram`, a list of object files `[main.o, utils.o]`, a C++ linker `g++`, and an external dependency `libcurl`.
        *   **Output:** Ninja build rules that invoke `g++` with `main.o`, `utils.o`, linker flags for an executable, and `-lcurl` to link against the `libcurl` library.

**2. Handling Dependencies:**

*   **`get_dependency_filename(self, t)`:** This function determines the filename of a dependency, whether it's another build target (like a shared library) or a pre-built file. This is essential for constructing the dependency graph in the Ninja build file.
*   **Binary Bottom Layer:** Understanding dependencies between binaries is fundamental in reverse engineering, allowing you to trace the execution flow and identify shared components.

**3. Managing Shared Library Aliases:**

*   **`generate_shlib_aliases(self, target, outdir)`:** Creates symbolic links (aliases) for shared libraries. This is common for versioning, where a base name might point to a specific versioned library.
    *   **Relevance to Reverse Engineering:** Shared library aliases can be important for understanding which specific version of a library is being used by an application. This can be crucial when dealing with vulnerabilities or different functionalities across library versions.
    *   **Linux/Android Kernel & Framework:** Symbolic links are a fundamental feature of the Linux filesystem, directly impacting how shared libraries are loaded.

**4. Cleaning Build Artifacts:**

*   **`generate_custom_target_clean(self, trees: T.List[str])`:** Generates Ninja rules for cleaning up the output of custom build steps.
*   **`generate_gcov_clean(self)`:** Creates rules to delete files generated by the `gcov` code coverage tool.

**5. Handling User Options and Distribution:**

*   **`get_user_option_args(self)`:** Retrieves user-defined build options. These options can significantly affect the final binary.
*   **`generate_dist(self)`:** Generates rules for creating source distribution packages.

**6. Integration with Static Analysis and Code Quality Tools:**

*   **`generate_scanbuild(self)`:**  Sets up a Ninja target to run the `scan-build` static analysis tool.
*   **`generate_clangtool(self, name: str, extra_arg: T.Optional[str] = None)`**, **`generate_clangformat(self)`**, **`generate_clangtidy(self)`:**  Integrates with various Clang tools for formatting and static analysis. These tools can help identify potential bugs and vulnerabilities before deployment.

**7. Generating Code Tags:**

*   **`generate_tags(self, tool: str, target_name: str)`:** Creates Ninja rules to generate code tags (like those used by `etags` or `ctags`), which are helpful for code navigation.

**8. Finalizing the Build:**

*   **`generate_utils(self)`:** Groups together the generation of various utility targets.
*   **`generate_ending(self)`:**  Generates the final Ninja rules, including the "all" target (which builds everything), the "clean" target, and the rule for regenerating the `build.ninja` file itself when the Meson configuration changes.

**User Operation and Debugging Clues:**

A user's interaction with Meson leads to this code being executed in the following steps:

1. **User runs `meson setup <build_directory>`:** This command configures the build based on the `meson.build` file in the source directory.
2. **Meson interprets the `meson.build` file:** It creates an internal representation of the build graph, including targets, dependencies, and compiler settings.
3. **Meson selects the Ninja backend:** Based on the user's configuration (or the default), Meson chooses the Ninja backend to generate the actual build instructions.
4. **`ninjabackend.py` is invoked:**  Meson iterates through the build graph and calls the corresponding functions in `ninjabackend.py` to translate each build step into Ninja rules. For example, when it encounters a `shared_library()` or `executable()` call in `meson.build`, the `generate_link` function in this file is called.
5. **Ninja build file is created (`build.ninja`):** The output of `ninjabackend.py` is a `build.ninja` file containing all the commands Ninja needs to execute to build the project.
6. **User runs `ninja` (or `ninja -C <build_directory>`):** Ninja reads the `build.ninja` file and executes the commands in parallel to build the project.

**Common User Errors Leading Here (as debugging clues):**

*   **Incorrectly specifying link dependencies in `meson.build`:** If a user forgets to link against a necessary library, the `generate_link` function will be executed without the correct `-l` flag, leading to linker errors during the `ninja` stage. Examining the generated `build.ninja` file would show the missing library.
*   **Problems with RPATH:** If a user encounters runtime linking errors (e.g., "shared library not found"), they might investigate the RPATH settings. The `generate_link` function is responsible for generating the RPATH flags, so inspecting the `build.ninja` for the `-Wl,-rpath` arguments can provide clues.
*   **Issues with prelinking:** If prelinking is enabled (perhaps through a Meson option) and causes issues, examining the output of `generate_prelink` in the `build.ninja` might reveal problems with the prelinker command or its arguments.
*   **Debugging issues:** If a user wants to debug their application, they might enable debug symbols. This will trigger the parts of `generate_link` that add `-g` or `/DEBUG` flags. Observing the `build.ninja` can confirm whether debug symbols are being included.

**归纳一下它的功能 (Summary of its Functionality):**

This code file, `ninjabackend.py`, is a crucial component of the Meson build system. Its core function is to translate Meson's abstract build descriptions into concrete build instructions for the Ninja build system. It handles various aspects of the build process, including:

*   Compiling source code.
*   Linking object files into executables and libraries.
*   Managing dependencies between build targets and external libraries.
*   Generating rules for cleaning build artifacts.
*   Integrating with code quality and static analysis tools.
*   Handling user-defined build options.
*   Creating distribution packages.

Essentially, it acts as a translator, taking Meson's high-level instructions and converting them into the low-level commands that Ninja executes to build the software project. It embodies the backend logic for the Ninja build system within the Meson framework.

Prompt: 
```
这是目录为frida/subprojects/frida-node/releng/meson/mesonbuild/backend/ninjabackend.py的fridaDynamic instrumentation tool的源代码文件， 请列举一下它的功能, 
如果它与逆向的方法有关系，请做出对应的举例说明，
如果涉及到二进制底层，linux, android内核及框架的知识，请做出对应的举例说明，
如果做了逻辑推理，请给出假设输入与输出,
如果涉及用户或者编程常见的使用错误，请举例说明,
说明用户操作是如何一步步的到达这里，作为调试线索。
这是第6部分，共6部分，请归纳一下它的功能

"""
[:]
        cmd += prelinker.get_prelink_args(prelink_name, obj_list)

        cmd = self.replace_paths(target, cmd)
        elem.add_item('COMMAND', cmd)
        elem.add_item('description', f'Prelinking {prelink_name}.')
        self.add_build(elem)
        return [prelink_name]

    def generate_link(self, target: build.BuildTarget, outname, obj_list, linker: T.Union['Compiler', 'StaticLinker'], extra_args=None, stdlib_args=None):
        extra_args = extra_args if extra_args is not None else []
        stdlib_args = stdlib_args if stdlib_args is not None else []
        implicit_outs = []
        if isinstance(target, build.StaticLibrary):
            linker_base = 'STATIC'
        else:
            linker_base = linker.get_language() # Fixme.
        if isinstance(target, build.SharedLibrary):
            self.generate_shsym(target)
        crstr = self.get_rule_suffix(target.for_machine)
        linker_rule = linker_base + '_LINKER' + crstr
        # Create an empty commands list, and start adding link arguments from
        # various sources in the order in which they must override each other
        # starting from hard-coded defaults followed by build options and so on.
        #
        # Once all the linker options have been passed, we will start passing
        # libraries and library paths from internal and external sources.
        commands = linker.compiler_args()
        # First, the trivial ones that are impossible to override.
        #
        # Add linker args for linking this target derived from 'base' build
        # options passed on the command-line, in default_options, etc.
        # These have the lowest priority.
        if isinstance(target, build.StaticLibrary):
            commands += linker.get_base_link_args(target.get_options())
        else:
            commands += compilers.get_base_link_args(target.get_options(),
                                                     linker,
                                                     isinstance(target, build.SharedModule),
                                                     self.environment.get_build_dir())
        # Add -nostdlib if needed; can't be overridden
        commands += self.get_no_stdlib_link_args(target, linker)
        # Add things like /NOLOGO; usually can't be overridden
        commands += linker.get_linker_always_args()
        # Add buildtype linker args: optimization level, etc.
        commands += linker.get_optimization_link_args(target.get_option(OptionKey('optimization')))
        # Add /DEBUG and the pdb filename when using MSVC
        if target.get_option(OptionKey('debug')):
            commands += self.get_link_debugfile_args(linker, target)
            debugfile = self.get_link_debugfile_name(linker, target)
            if debugfile is not None:
                implicit_outs += [debugfile]
        # Add link args specific to this BuildTarget type, such as soname args,
        # PIC, import library generation, etc.
        commands += self.get_target_type_link_args(target, linker)
        # Archives that are copied wholesale in the result. Must be before any
        # other link targets so missing symbols from whole archives are found in those.
        if not isinstance(target, build.StaticLibrary):
            commands += self.get_link_whole_args(linker, target)

        if not isinstance(target, build.StaticLibrary):
            # Add link args added using add_project_link_arguments()
            commands += self.build.get_project_link_args(linker, target.subproject, target.for_machine)
            # Add link args added using add_global_link_arguments()
            # These override per-project link arguments
            commands += self.build.get_global_link_args(linker, target.for_machine)
            # Link args added from the env: LDFLAGS. We want these to override
            # all the defaults but not the per-target link args.
            commands += self.environment.coredata.get_external_link_args(target.for_machine, linker.get_language())

        # Now we will add libraries and library paths from various sources

        # Set runtime-paths so we can run executables without needing to set
        # LD_LIBRARY_PATH, etc in the environment. Doesn't work on Windows.
        if has_path_sep(target.name):
            # Target names really should not have slashes in them, but
            # unfortunately we did not check for that and some downstream projects
            # now have them. Once slashes are forbidden, remove this bit.
            target_slashname_workaround_dir = os.path.join(
                os.path.dirname(target.name),
                self.get_target_dir(target))
        else:
            target_slashname_workaround_dir = self.get_target_dir(target)
        (rpath_args, target.rpath_dirs_to_remove) = (
            linker.build_rpath_args(self.environment,
                                    self.environment.get_build_dir(),
                                    target_slashname_workaround_dir,
                                    self.determine_rpath_dirs(target),
                                    target.build_rpath,
                                    target.install_rpath))
        commands += rpath_args

        # Add link args to link to all internal libraries (link_with:) and
        # internal dependencies needed by this target.
        if linker_base == 'STATIC':
            # Link arguments of static libraries are not put in the command
            # line of the library. They are instead appended to the command
            # line where the static library is used.
            dependencies = []
        else:
            dependencies = target.get_dependencies()
        internal = self.build_target_link_arguments(linker, dependencies)
        commands += internal
        # Only non-static built targets need link args and link dependencies
        if not isinstance(target, build.StaticLibrary):
            # For 'automagic' deps: Boost and GTest. Also dependency('threads').
            # pkg-config puts the thread flags itself via `Cflags:`

            commands += linker.get_target_link_args(target)
            # External deps must be last because target link libraries may depend on them.
            for dep in target.get_external_deps():
                # Extend without reordering or de-dup to preserve `-L -l` sets
                # https://github.com/mesonbuild/meson/issues/1718
                commands.extend_preserving_lflags(linker.get_dependency_link_args(dep))
            for d in target.get_dependencies():
                if isinstance(d, build.StaticLibrary):
                    for dep in d.get_external_deps():
                        commands.extend_preserving_lflags(linker.get_dependency_link_args(dep))

        # Add link args specific to this BuildTarget type that must not be overridden by dependencies
        commands += self.get_target_type_link_args_post_dependencies(target, linker)

        # Add link args for c_* or cpp_* build options. Currently this only
        # adds c_winlibs and cpp_winlibs when building for Windows. This needs
        # to be after all internal and external libraries so that unresolved
        # symbols from those can be found here. This is needed when the
        # *_winlibs that we want to link to are static mingw64 libraries.
        if isinstance(linker, Compiler):
            # The static linker doesn't know what language it is building, so we
            # don't know what option. Fortunately, it doesn't care to see the
            # language-specific options either.
            #
            # We shouldn't check whether we are making a static library, because
            # in the LTO case we do use a real compiler here.
            commands += linker.get_option_link_args(target.get_options())

        dep_targets = []
        dep_targets.extend(self.guess_external_link_dependencies(linker, target, commands, internal))

        # Add libraries generated by custom targets
        custom_target_libraries = self.get_custom_target_provided_libraries(target)
        commands += extra_args
        commands += custom_target_libraries
        commands += stdlib_args # Standard library arguments go last, because they never depend on anything.
        dep_targets.extend([self.get_dependency_filename(t) for t in dependencies])
        dep_targets.extend([self.get_dependency_filename(t)
                            for t in target.link_depends])
        elem = NinjaBuildElement(self.all_outputs, outname, linker_rule, obj_list, implicit_outs=implicit_outs)
        elem.add_dep(dep_targets + custom_target_libraries)
        elem.add_item('LINK_ARGS', commands)
        self.create_target_linker_introspection(target, linker, commands)
        return elem

    def get_dependency_filename(self, t):
        if isinstance(t, build.SharedLibrary):
            return self.get_target_shsym_filename(t)
        elif isinstance(t, mesonlib.File):
            if t.is_built:
                return t.relative_name()
            else:
                return t.absolute_path(self.environment.get_source_dir(),
                                       self.environment.get_build_dir())
        return self.get_target_filename(t)

    def generate_shlib_aliases(self, target, outdir):
        for alias, to, tag in target.get_aliases():
            aliasfile = os.path.join(outdir, alias)
            abs_aliasfile = os.path.join(self.environment.get_build_dir(), outdir, alias)
            try:
                os.remove(abs_aliasfile)
            except Exception:
                pass
            try:
                os.symlink(to, abs_aliasfile)
            except NotImplementedError:
                mlog.debug("Library versioning disabled because symlinks are not supported.")
            except OSError:
                mlog.debug("Library versioning disabled because we do not have symlink creation privileges.")
            else:
                self.implicit_meson_outs.append(aliasfile)

    def generate_custom_target_clean(self, trees: T.List[str]) -> str:
        e = self.create_phony_target('clean-ctlist', 'CUSTOM_COMMAND', 'PHONY')
        d = CleanTrees(self.environment.get_build_dir(), trees)
        d_file = os.path.join(self.environment.get_scratch_dir(), 'cleantrees.dat')
        e.add_item('COMMAND', self.environment.get_build_command() + ['--internal', 'cleantrees', d_file])
        e.add_item('description', 'Cleaning custom target directories')
        self.add_build(e)
        # Write out the data file passed to the script
        with open(d_file, 'wb') as ofile:
            pickle.dump(d, ofile)
        return 'clean-ctlist'

    def generate_gcov_clean(self) -> None:
        gcno_elem = self.create_phony_target('clean-gcno', 'CUSTOM_COMMAND', 'PHONY')
        gcno_elem.add_item('COMMAND', mesonlib.get_meson_command() + ['--internal', 'delwithsuffix', '.', 'gcno'])
        gcno_elem.add_item('description', 'Deleting gcno files')
        self.add_build(gcno_elem)

        gcda_elem = self.create_phony_target('clean-gcda', 'CUSTOM_COMMAND', 'PHONY')
        gcda_elem.add_item('COMMAND', mesonlib.get_meson_command() + ['--internal', 'delwithsuffix', '.', 'gcda'])
        gcda_elem.add_item('description', 'Deleting gcda files')
        self.add_build(gcda_elem)

    def get_user_option_args(self):
        cmds = []
        for (k, v) in self.environment.coredata.options.items():
            if k.is_project():
                cmds.append('-D' + str(k) + '=' + (v.value if isinstance(v.value, str) else str(v.value).lower()))
        # The order of these arguments must be the same between runs of Meson
        # to ensure reproducible output. The order we pass them shouldn't
        # affect behavior in any other way.
        return sorted(cmds)

    def generate_dist(self) -> None:
        elem = self.create_phony_target('dist', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('DESC', 'Creating source packages')
        elem.add_item('COMMAND', self.environment.get_build_command() + ['dist'])
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_scanbuild(self) -> None:
        if not environment.detect_scanbuild():
            return
        if 'scan-build' in self.all_outputs:
            return
        cmd = self.environment.get_build_command() + \
            ['--internal', 'scanbuild', self.environment.source_dir, self.environment.build_dir, self.build.get_subproject_dir()] + \
            self.environment.get_build_command() + ['setup'] + self.get_user_option_args()
        elem = self.create_phony_target('scan-build', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_clangtool(self, name: str, extra_arg: T.Optional[str] = None) -> None:
        target_name = 'clang-' + name
        extra_args = []
        if extra_arg:
            target_name += f'-{extra_arg}'
            extra_args.append(f'--{extra_arg}')
        if not os.path.exists(os.path.join(self.environment.source_dir, '.clang-' + name)) and \
                not os.path.exists(os.path.join(self.environment.source_dir, '_clang-' + name)):
            return
        if target_name in self.all_outputs:
            return
        cmd = self.environment.get_build_command() + \
            ['--internal', 'clang' + name, self.environment.source_dir, self.environment.build_dir] + \
            extra_args
        elem = self.create_phony_target(target_name, 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_clangformat(self) -> None:
        if not environment.detect_clangformat():
            return
        self.generate_clangtool('format')
        self.generate_clangtool('format', 'check')

    def generate_clangtidy(self) -> None:
        import shutil
        if not shutil.which('clang-tidy'):
            return
        self.generate_clangtool('tidy')
        self.generate_clangtool('tidy', 'fix')

    def generate_tags(self, tool: str, target_name: str) -> None:
        import shutil
        if not shutil.which(tool):
            return
        if target_name in self.all_outputs:
            return
        cmd = self.environment.get_build_command() + \
            ['--internal', 'tags', tool, self.environment.source_dir]
        elem = self.create_phony_target(target_name, 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    # For things like scan-build and other helper tools we might have.
    def generate_utils(self) -> None:
        self.generate_scanbuild()
        self.generate_clangformat()
        self.generate_clangtidy()
        self.generate_tags('etags', 'TAGS')
        self.generate_tags('ctags', 'ctags')
        self.generate_tags('cscope', 'cscope')
        cmd = self.environment.get_build_command() + ['--internal', 'uninstall']
        elem = self.create_phony_target('uninstall', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', cmd)
        elem.add_item('pool', 'console')
        self.add_build(elem)

    def generate_ending(self) -> None:
        for targ, deps in [
                ('all', self.get_build_by_default_targets()),
                ('meson-test-prereq', self.get_testlike_targets()),
                ('meson-benchmark-prereq', self.get_testlike_targets(True))]:
            targetlist = []
            # These must also be built by default.
            # XXX: Sometime in the future these should be built only before running tests.
            if targ == 'all':
                targetlist.extend(['meson-test-prereq', 'meson-benchmark-prereq'])
            for t in deps.values():
                # Add the first output of each target to the 'all' target so that
                # they are all built
                #Add archive file if shared library in AIX for build all.
                if isinstance(t, build.SharedLibrary) and t.aix_so_archive:
                    if self.environment.machines[t.for_machine].is_aix():
                        linker, stdlib_args = self.determine_linker_and_stdlib_args(t)
                        t.get_outputs()[0] = linker.get_archive_name(t.get_outputs()[0])
                targetlist.append(os.path.join(self.get_target_dir(t), t.get_outputs()[0]))

            elem = NinjaBuildElement(self.all_outputs, targ, 'phony', targetlist)
            self.add_build(elem)

        elem = self.create_phony_target('clean', 'CUSTOM_COMMAND', 'PHONY')
        elem.add_item('COMMAND', self.ninja_command + ['-t', 'clean'])
        elem.add_item('description', 'Cleaning')

        # If we have custom targets in this project, add all their outputs to
        # the list that is passed to the `cleantrees.py` script. The script
        # will manually delete all custom_target outputs that are directories
        # instead of files. This is needed because on platforms other than
        # Windows, Ninja only deletes directories while cleaning if they are
        # empty. https://github.com/mesonbuild/meson/issues/1220
        ctlist = []
        for t in self.build.get_targets().values():
            if isinstance(t, build.CustomTarget):
                # Create a list of all custom target outputs
                for o in t.get_outputs():
                    ctlist.append(os.path.join(self.get_target_dir(t), o))
        if ctlist:
            elem.add_dep(self.generate_custom_target_clean(ctlist))

        if OptionKey('b_coverage') in self.environment.coredata.options and \
           self.environment.coredata.options[OptionKey('b_coverage')].value:
            self.generate_gcov_clean()
            elem.add_dep('clean-gcda')
            elem.add_dep('clean-gcno')
        self.add_build(elem)

        deps = self.get_regen_filelist()
        elem = NinjaBuildElement(self.all_outputs, 'build.ninja', 'REGENERATE_BUILD', deps)
        elem.add_item('pool', 'console')
        self.add_build(elem)

        # If these files used to be explicitly created, they need to appear on the build graph somehow,
        # otherwise cleandead deletes them. See https://github.com/ninja-build/ninja/issues/2299
        if self.implicit_meson_outs:
            elem = NinjaBuildElement(self.all_outputs, 'meson-implicit-outs', 'phony', self.implicit_meson_outs)
            self.add_build(elem)

        elem = NinjaBuildElement(self.all_outputs, 'reconfigure', 'REGENERATE_BUILD', 'PHONY')
        elem.add_item('pool', 'console')
        self.add_build(elem)

        elem = NinjaBuildElement(self.all_outputs, deps, 'phony', '')
        self.add_build(elem)

    def get_introspection_data(self, target_id: str, target: build.Target) -> T.List[T.Dict[str, T.Union[bool, str, T.List[T.Union[str, T.Dict[str, T.Union[str, T.List[str], bool]]]]]]]:
        data = self.introspection_data.get(target_id)
        if not data:
            return super().get_introspection_data(target_id, target)

        return list(data.values())


def _scan_fortran_file_deps(src: Path, srcdir: Path, dirname: Path, tdeps, compiler) -> T.List[str]:
    """
    scan a Fortran file for dependencies. Needs to be distinct from target
    to allow for recursion induced by `include` statements.er

    It makes a number of assumptions, including

    * `use`, `module`, `submodule` name is not on a continuation line

    Regex
    -----

    * `incre` works for `#include "foo.f90"` and `include "foo.f90"`
    * `usere` works for legacy and Fortran 2003 `use` statements
    * `submodre` is for Fortran >= 2008 `submodule`
    """

    incre = re.compile(FORTRAN_INCLUDE_PAT, re.IGNORECASE)
    usere = re.compile(FORTRAN_USE_PAT, re.IGNORECASE)
    submodre = re.compile(FORTRAN_SUBMOD_PAT, re.IGNORECASE)

    mod_files = []
    src = Path(src)
    with src.open(encoding='ascii', errors='ignore') as f:
        for line in f:
            # included files
            incmatch = incre.match(line)
            if incmatch is not None:
                incfile = src.parent / incmatch.group(1)
                # NOTE: src.parent is most general, in particular for CMake subproject with Fortran file
                # having an `include 'foo.f'` statement.
                if incfile.suffix.lower()[1:] in compiler.file_suffixes:
                    mod_files.extend(_scan_fortran_file_deps(incfile, srcdir, dirname, tdeps, compiler))
            # modules
            usematch = usere.match(line)
            if usematch is not None:
                usename = usematch.group(1).lower()
                if usename == 'intrinsic':  # this keeps the regex simpler
                    continue
                if usename not in tdeps:
                    # The module is not provided by any source file. This
                    # is due to:
                    #   a) missing file/typo/etc
                    #   b) using a module provided by the compiler, such as
                    #      OpenMP
                    # There's no easy way to tell which is which (that I
                    # know of) so just ignore this and go on. Ideally we
                    # would print a warning message to the user but this is
                    # a common occurrence, which would lead to lots of
                    # distracting noise.
                    continue
                srcfile = srcdir / tdeps[usename].fname
                if not srcfile.is_file():
                    if srcfile.name != src.name:  # generated source file
                        pass
                    else:  # subproject
                        continue
                elif srcfile.samefile(src):  # self-reference
                    continue

                mod_name = compiler.module_name_to_filename(usename)
                mod_files.append(str(dirname / mod_name))
            else:  # submodules
                submodmatch = submodre.match(line)
                if submodmatch is not None:
                    parents = submodmatch.group(1).lower().split(':')
                    assert len(parents) in {1, 2}, (
                        'submodule ancestry must be specified as'
                        f' ancestor:parent but Meson found {parents}')

                    ancestor_child = '_'.join(parents)
                    if ancestor_child not in tdeps:
                        raise MesonException("submodule {} relies on ancestor module {} that was not found.".format(submodmatch.group(2).lower(), ancestor_child.split('_', maxsplit=1)[0]))
                    submodsrcfile = srcdir / tdeps[ancestor_child].fname
                    if not submodsrcfile.is_file():
                        if submodsrcfile.name != src.name:  # generated source file
                            pass
                        else:  # subproject
                            continue
                    elif submodsrcfile.samefile(src):  # self-reference
                        continue
                    mod_name = compiler.module_name_to_filename(ancestor_child)
                    mod_files.append(str(dirname / mod_name))
    return mod_files

"""


```