Response:
Let's break down the thought process for analyzing this Go code snippet.

1. **Identify the Core Purpose:** The file name `package_text.go` and the `gc_parser` struct strongly suggest this code is about parsing some textual representation of Go packages. The presence of `go/ast` imports confirms it's building Abstract Syntax Trees (ASTs). The copyright notice mentioning the Go authors reinforces the idea that this is related to Go's internal workings or a tool that works closely with Go code.

2. **Analyze the `gc_parser` Struct:**  This is the central data structure. Each field gives a clue:
    * `scanner`:  Standard Go library for lexical analysis (tokenizing).
    * `tok`, `lit`:  Current token and its literal value – fundamental for parsing.
    * `path_to_name`:  A map for tracking import paths and their aliases. Essential for handling imports.
    * `beautify`: Likely a flag for formatting or processing output. (Though not used in this snippet).
    * `pfc`:  `package_file_cache`. This indicates the parser is likely part of a larger system that caches information about package files.

3. **Examine Key Methods:**  Start with the initialization (`init`) and core parsing logic (`next`, `expect`, error handling).
    * `init`:  Sets up the scanner, defines error handling, and initializes the `path_to_name` map (importantly including "unsafe"). It also receives the `package_file_cache`.
    * `next`: Advances the scanner to the next token.
    * `expect`:  Ensures the current token is what's expected, a crucial part of parser correctness.
    * Error methods (`error`, `errorf`): Standard error reporting.

4. **Look for Parsing Rules (Grammar-like Structures):** The comments like `// dotIdentifier = "?" | ( ident | '·' ) { ident | int | '·' } .` are explicit definitions of the grammar being parsed. These are the most direct hints about the input format. Go through these rules and try to understand what each one represents.

5. **Focus on AST Construction:**  Notice methods like `parse_package`, `parse_exported_name`, `parse_field`, `parse_parameters`, `parse_signature`, and the various `parse_*_type` methods. These methods create `ast` nodes. This confirms that the parser's primary output is an AST.

6. **Trace Data Flow:** How does the input data (`data []byte` in `init`) get transformed?  It goes through the `scanner`, is broken into tokens, and then the parsing methods use these tokens to build the AST. The `path_to_name` map is populated and used during parsing.

7. **Identify Potential Input Format:** Based on the grammar rules, try to infer what the input looks like. The `parse_package` method expecting a string literal suggests import paths are quoted. The `@` symbol in `parse_exported_name` is a strong indicator of a specific syntax for referencing exported names from other packages.

8. **Infer the Purpose (gocode connection):** Knowing the file path (`go/src/github.com/nsf/gocode/package_text.go`) provides the context. `gocode` is a popular autocompletion daemon for Go. This parser is likely used by `gocode` to quickly analyze package information without needing to fully compile the code. This helps explain the specialized input format – it's likely an output format generated by the Go compiler or a related tool to represent package information concisely.

9. **Construct Examples:** Based on the identified input format and the AST construction, create concrete examples. The `@` notation strongly suggests something like `@ "fmt".Println`. Import declarations would involve the `import` keyword.

10. **Consider Command-line Arguments and Errors:**  Since this snippet is part of `gocode`, think about how `gocode` itself is used. It runs as a daemon, and it likely receives input related to the code being edited. Common errors would involve incorrect syntax in the input format.

11. **Refine and Organize:**  Structure the answer logically, starting with the main function, then detailing specific features, providing code examples, and discussing potential issues. Use clear and concise language.

**Self-Correction/Refinement During the Process:**

* **Initial thought:**  Maybe this is a full Go parser. **Correction:** The file name and the specific grammar rules point to a *specialized* parser for package information, not arbitrary Go code.
* **Uncertainty about input format:** The grammar rules are key here. Focusing on them clarifies the expected input structure. The `@` symbol is a significant clue.
* **Figuring out the "why":**  Connecting it to `gocode` provides a strong motivation for this kind of parser. It needs to be fast and efficient for autocompletion.

By following these steps, and iteratively refining understanding, one can effectively analyze and explain the functionality of the provided Go code snippet.
这段代码是 Go 代码编辑器或 IDE 的一个组成部分，特别是与 `gocode` 这个工具密切相关。它的主要功能是**解析 Go 语言包的导出信息**，这些信息通常以一种特定的文本格式存在。

**具体功能列表:**

1. **初始化解析器 (`init` 函数):**
   - 接收一个字节切片 `data`，这个切片包含了需要解析的包信息的文本内容。
   - 初始化一个 `scanner.Scanner`，用于词法分析，将文本分解成 token。
   - 设置 scanner 的行为，例如识别标识符、整数、字符串、注释等，并跳过注释。
   - 初始化一个 `path_to_name` 映射，用于存储导入路径和对应的别名。默认包含 "unsafe" 包。
   - 关联一个 `package_file_cache`，表明这个解析器可能会用到缓存的包信息。

2. **词法分析 (`next` 函数):**
   - 使用 `scanner.Scan()` 读取下一个 token。
   - 如果 token 是标识符、整数或字符串，则将其文本内容存储在 `lit` 字段中。

3. **错误处理 (`error`, `errorf` 函数):**
   - 提供基本的错误报告机制，当解析过程中遇到错误时会抛出 panic。

4. **期望特定 Token (`expect` 函数):**
   - 检查当前的 token 是否是期望的类型。
   - 如果不是，则抛出错误。
   - 如果是，则读取 token 的文本内容并移动到下一个 token。

5. **期望特定关键字 (`expect_keyword` 函数):**
   - 期望当前的 token 是一个标识符，并且其文本内容是指定的关键字。

6. **期望特定特殊字符序列 (`expect_special` 函数):**
   - 期望接下来的字符序列与给定的字符串匹配。

7. **解析点分隔的标识符 (`parse_dot_ident` 函数):**
   - 解析类似 `fmt.Println` 这样的标识符，也处理一些特殊情况，例如包含特殊字符 '·'。

8. **解析包导入路径 (`parse_package` 函数):**
   - 期望一个字符串字面量，表示导入路径。
   - 返回一个 `ast.Ident` 类型的节点，其 `Name` 字段是 unquote 后的路径。

9. **解析导出的名称 (`parse_exported_name` 函数):**
   - 期望以 `@` 开头，后跟导入路径和一个点分隔的标识符，例如 `@ "fmt".Println`。
   - 返回一个 `ast.SelectorExpr` 类型的节点，表示选择器表达式。

10. **解析名称 (`parse_name` 函数):**
    - 解析标识符、问号 `?` 或导出的名称。
    - 返回名称的字符串表示和对应的 `ast.Expr` 节点。

11. **解析字段 (`parse_field` 函数):**
    - 解析结构体或接口中的字段，包括名称、类型和可选的标签。

12. **解析参数 (`parse_parameter` 函数):**
    - 解析函数或方法的参数，包括名称、是否是变参、类型和可选的标签。

13. **解析参数列表 (`parse_parameters` 函数):**
    - 解析函数或方法的参数列表，用括号括起来，参数之间用逗号分隔。

14. **解析函数签名 (`parse_signature` 函数):**
    - 解析函数或方法的签名，包括参数列表和返回值类型（或参数列表）。

15. **解析方法或嵌入规范 (`parse_method_or_embed_spec` 函数):**
    - 解析接口中的方法定义或嵌入的类型。

16. **解析整数 (`parse_int` 函数) 和数字 (`parse_number` 函数):**
    - 解析整数和浮点数（尽管浮点数在这里的实现可能不完整）。

17. **解析各种类型 (`parse_*_type` 函数):**
    - 解析接口类型 (`parse_interface_type`)。
    - 解析结构体类型 (`parse_struct_type`)。
    - 解析 map 类型 (`parse_map_type`)。
    - 解析 channel 类型 (`parse_chan_type`)。
    - 解析数组或切片类型 (`parse_array_or_slice_type`)。
    - 解析通用的类型 (`parse_type`)，根据不同的 token 调用相应的解析函数。

18. **解析声明 (`parse_*_decl` 函数):**
    - 解析导入声明 (`parse_import_decl`)，将导入路径和别名添加到 `path_to_name` 映射和 `package_file_cache` 中。
    - 解析常量声明 (`parse_const_decl`)，提取常量名称和类型。
    - 解析类型声明 (`parse_type_decl`)，提取类型名称和定义。
    - 解析变量声明 (`parse_var_decl`)，提取变量名称和类型。
    - 解析函数声明 (`parse_func_decl`)，提取函数名称和签名。
    - 解析方法声明 (`parse_method_decl`)，提取接收者、方法名称和签名。

19. **解析函数体 (`parse_func_body` 函数):**
    - 跳过函数体的内容，用于快速解析而不需要完全分析函数实现。

20. **去除方法接收者的包路径 (`strip_method_receiver` 函数):**
    - 从方法接收者的类型中提取包路径，并修改接收者类型，这可能是为了简化后续处理。

21. **解析顶层声明 (`parse_decl` 函数):**
    - 根据当前的 token 判断是哪种声明，并调用相应的解析函数。

22. **解析导出信息 (`parse_export` 函数):**
    - 解析包声明行，提取包名和别名。
    - 循环解析包中的所有声明，并调用一个回调函数 `callback` 来处理每个解析到的声明。
    - 期望以 `$$` 结束。

**推断其实现的 Go 语言功能:**

这段代码实现的功能是**解析 Go 包的导出信息文本格式**。这种格式不是标准的 Go 源代码，而是 Go 编译器或相关工具生成的一种简化表示，包含了包的导出常量、类型、变量、函数和方法的信息。`gocode` 等代码补全工具会使用这种格式来快速获取包的符号信息，而无需完整地编译整个包。

**Go 代码举例说明 (假设的输入与输出):**

假设有以下 `package.go` 文件编译后生成的导出信息文本内容：

```
package fmt
import io "io"
const @ "fmt".Errorf func(format string, a ...interface {}) error
type @ "fmt".Formatter interface {
	Format(s fmt.State, verb rune)
}
var @ "fmt".Errorf func(format string, a ...interface {}) error
func @ "fmt".Println(a ...interface {}) (n int, err error)
func ( io.Writer ).Write(p []byte) (n int, err error)
$$
```

当这段文本作为 `data` 传入 `gc_parser` 并调用 `parse_export` 函数后，会得到以下类型的 `ast.Decl` 节点：

- 一个 `ast.GenDecl`，`Tok` 为 `token.CONST`，表示常量 `Errorf`。
- 一个 `ast.GenDecl`，`Tok` 为 `token.TYPE`，表示接口类型 `Formatter`。
- 一个 `ast.GenDecl`，`Tok` 为 `token.VAR`，表示变量 `Errorf`。
- 一个 `ast.FuncDecl`，表示函数 `Println`。
- 一个 `ast.FuncDecl`，表示方法 `Write`。

**代码推理:**

- 当解析到 `const @ "fmt".Errorf ...` 时，`parse_const_decl` 会被调用，它会解析出常量名 `Errorf` 和类型 `func(format string, a ...interface {}) error`，并创建一个 `ast.GenDecl` 节点。
    - **假设输入:** 当前 token 为 `const`。
    - **输出:**  `name.X.(*ast.Ident).Name` 为 `"fmt"`，返回的 `ast.GenDecl` 结构体表示常量 `Errorf`。

- 当解析到 `type @ "fmt".Formatter interface { ... }` 时，`parse_type_decl` 会被调用，它会解析出类型名 `Formatter` 和接口定义，并创建一个 `ast.GenDecl` 节点。
    - **假设输入:** 当前 token 为 `type`。
    - **输出:** `name.X.(*ast.Ident).Name` 为 `"fmt"`，返回的 `ast.GenDecl` 结构体表示类型 `Formatter`。

- 当解析到 `func @ "fmt".Println(...)` 时，`parse_func_decl` 会被调用，它会解析出函数名 `Println` 和签名，并创建一个 `ast.FuncDecl` 节点。
    - **假设输入:** 当前 token 为 `func`，下一个 token 不是 `(`。
    - **输出:** `name.X.(*ast.Ident).Name` 为 `"fmt"`，返回的 `ast.FuncDecl` 结构体表示函数 `Println`。

- 当解析到 `func ( io.Writer ).Write(...)` 时，`parse_method_decl` 会被调用，它会解析出接收者类型 `io.Writer`，方法名 `Write` 和签名，并创建一个 `ast.FuncDecl` 节点。
    - **假设输入:** 当前 token 为 `func`，下一个 token 是 `(`。
    - **输出:** `pkg` 为 `"io"`，返回的 `ast.FuncDecl` 结构体表示方法 `Write`。

**命令行参数:**

这段代码本身不直接处理命令行参数。它是一个解析器，通常会被其他工具调用，例如 `gocode`。`gocode` 可能会有自己的命令行参数，用于指定要分析的代码、输入位置等。例如，`gocode` 常用的参数可能包括：

- `-s`:  显示服务器状态。
- `-c`:  运行在当前目录。
- `autocomplete`:  触发代码补全。
- `drop-cache`: 清空缓存。

**使用者易犯错的点:**

由于这段代码是解析一种特定的、非标准的文本格式，普通 Go 开发者不会直接使用它。只有在开发类似 `gocode` 这样的工具时才会涉及到。

如果有人试图手动生成或修改这种格式的文本，可能会犯以下错误：

- **语法错误:**  例如，`@` 符号使用不当，引号缺失，括号不匹配等。
- **类型表示错误:**  例如，类型名称拼写错误，或者使用了不正确的类型表示方法。
- **顺序错误:**  例如，声明的顺序不符合预期。

**总结:**

这段 `package_text.go` 文件是 `gocode` 工具中用于解析 Go 包导出信息文本格式的核心部分。它定义了一个 `gc_parser` 结构体和一系列方法，用于词法分析和语法分析，最终将文本表示转换为 Go 语言的抽象语法树 (AST) 节点。这使得 `gocode` 能够快速了解包的结构和提供的符号，从而实现代码补全等功能。

Prompt: 
```
这是路径为go/src/github.com/nsf/gocode/package_text.go的go语言实现的一部分， 请列举一下它的功能, 　
如果你能推理出它是什么go语言功能的实现，请用go代码举例说明, 
如果涉及代码推理，需要带上假设的输入与输出，
如果涉及命令行参数的具体处理，请详细介绍一下，
如果有哪些使用者易犯错的点，请举例说明，没有则不必说明，
请用中文回答。

"""
package main

import (
	"bytes"
	"errors"
	"fmt"
	"go/ast"
	"go/token"
	"strconv"
	"text/scanner"
)

//-------------------------------------------------------------------------
// gc_parser
//
// The following part of the code may contain portions of the code from the Go
// standard library, which tells me to retain their copyright notice:
//
// Copyright (c) 2009 The Go Authors. All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//    * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//    * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//    * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//-------------------------------------------------------------------------

type gc_parser struct {
	scanner      scanner.Scanner
	tok          rune
	lit          string
	path_to_name map[string]string
	beautify     bool
	pfc          *package_file_cache
}

func (p *gc_parser) init(data []byte, pfc *package_file_cache) {
	p.scanner.Init(bytes.NewReader(data))
	p.scanner.Error = func(_ *scanner.Scanner, msg string) { p.error(msg) }
	p.scanner.Mode = scanner.ScanIdents | scanner.ScanInts | scanner.ScanStrings |
		scanner.ScanComments | scanner.ScanChars | scanner.SkipComments
	p.scanner.Whitespace = 1<<'\t' | 1<<' ' | 1<<'\r' | 1<<'\v' | 1<<'\f'
	p.scanner.Filename = "package.go"
	p.next()
	// and the built-in "unsafe" package to the path_to_name map
	p.path_to_name = map[string]string{"unsafe": "unsafe"}
	p.pfc = pfc
}

func (p *gc_parser) next() {
	p.tok = p.scanner.Scan()
	switch p.tok {
	case scanner.Ident, scanner.Int, scanner.String:
		p.lit = p.scanner.TokenText()
	default:
		p.lit = ""
	}
}

func (p *gc_parser) error(msg string) {
	panic(errors.New(msg))
}

func (p *gc_parser) errorf(format string, args ...interface{}) {
	p.error(fmt.Sprintf(format, args...))
}

func (p *gc_parser) expect(tok rune) string {
	lit := p.lit
	if p.tok != tok {
		p.errorf("expected %s, got %s (%q)", scanner.TokenString(tok),
			scanner.TokenString(p.tok), lit)
	}
	p.next()
	return lit
}

func (p *gc_parser) expect_keyword(keyword string) {
	lit := p.expect(scanner.Ident)
	if lit != keyword {
		p.errorf("expected keyword: %s, got: %q", keyword, lit)
	}
}

func (p *gc_parser) expect_special(what string) {
	i := 0
	for i < len(what) {
		if p.tok != rune(what[i]) {
			break
		}

		nc := p.scanner.Peek()
		if i != len(what)-1 && nc <= ' ' {
			break
		}

		p.next()
		i++
	}

	if i < len(what) {
		p.errorf("expected: %q, got: %q", what, what[0:i])
	}
}

// dotIdentifier = "?" | ( ident | '·' ) { ident | int | '·' } .
// we're doing lexer job here, kind of
func (p *gc_parser) parse_dot_ident() string {
	if p.tok == '?' {
		p.next()
		return "?"
	}

	ident := ""
	sep := 'x'
	i, j := 0, -1
	for (p.tok == scanner.Ident || p.tok == scanner.Int || p.tok == '·') && sep > ' ' {
		ident += p.lit
		if p.tok == '·' {
			ident += "·"
			j = i
			i++
		}
		i += len(p.lit)
		sep = p.scanner.Peek()
		p.next()
	}
	// middot = \xc2\xb7
	if j != -1 && i > j+1 {
		c := ident[j+2]
		if c >= '0' && c <= '9' {
			ident = ident[0:j]
		}
	}
	return ident
}

// ImportPath = string_lit .
// quoted name of the path, but we return it as an identifier, taking an alias
// from 'pathToAlias' map, it is filled by import statements
func (p *gc_parser) parse_package() *ast.Ident {
	path, err := strconv.Unquote(p.expect(scanner.String))
	if err != nil {
		panic(err)
	}

	return ast.NewIdent(path)
}

// ExportedName = "@" ImportPath "." dotIdentifier .
func (p *gc_parser) parse_exported_name() *ast.SelectorExpr {
	p.expect('@')
	pkg := p.parse_package()
	if pkg.Name == "" {
		pkg.Name = "!" + p.pfc.name + "!" + p.pfc.defalias
	} else {
		pkg.Name = p.path_to_name[pkg.Name]
	}
	p.expect('.')
	name := ast.NewIdent(p.parse_dot_ident())
	return &ast.SelectorExpr{X: pkg, Sel: name}
}

// Name = identifier | "?" | ExportedName .
func (p *gc_parser) parse_name() (string, ast.Expr) {
	switch p.tok {
	case scanner.Ident:
		name := p.lit
		p.next()
		return name, ast.NewIdent(name)
	case '?':
		p.next()
		return "?", ast.NewIdent("?")
	case '@':
		en := p.parse_exported_name()
		return en.Sel.Name, en
	}
	p.error("name expected")
	return "", nil
}

// Field = Name Type [ string_lit ] .
func (p *gc_parser) parse_field() *ast.Field {
	var tag string
	name, _ := p.parse_name()
	typ := p.parse_type()
	if p.tok == scanner.String {
		tag = p.expect(scanner.String)
	}

	var names []*ast.Ident
	if name != "?" {
		names = []*ast.Ident{ast.NewIdent(name)}
	}

	return &ast.Field{
		Names: names,
		Type:  typ,
		Tag:   &ast.BasicLit{Kind: token.STRING, Value: tag},
	}
}

// Parameter = ( identifier | "?" ) [ "..." ] Type [ string_lit ] .
func (p *gc_parser) parse_parameter() *ast.Field {
	// name
	name, _ := p.parse_name()

	// type
	var typ ast.Expr
	if p.tok == '.' {
		p.expect_special("...")
		typ = &ast.Ellipsis{Elt: p.parse_type()}
	} else {
		typ = p.parse_type()
	}

	var tag string
	if p.tok == scanner.String {
		tag = p.expect(scanner.String)
	}

	return &ast.Field{
		Names: []*ast.Ident{ast.NewIdent(name)},
		Type:  typ,
		Tag:   &ast.BasicLit{Kind: token.STRING, Value: tag},
	}
}

// Parameters = "(" [ ParameterList ] ")" .
// ParameterList = { Parameter "," } Parameter .
func (p *gc_parser) parse_parameters() *ast.FieldList {
	flds := []*ast.Field{}
	parse_parameter := func() {
		par := p.parse_parameter()
		flds = append(flds, par)
	}

	p.expect('(')
	if p.tok != ')' {
		parse_parameter()
		for p.tok == ',' {
			p.next()
			parse_parameter()
		}
	}
	p.expect(')')
	return &ast.FieldList{List: flds}
}

// Signature = Parameters [ Result ] .
// Result = Type | Parameters .
func (p *gc_parser) parse_signature() *ast.FuncType {
	var params *ast.FieldList
	var results *ast.FieldList

	params = p.parse_parameters()
	switch p.tok {
	case scanner.Ident, '[', '*', '<', '@':
		fld := &ast.Field{Type: p.parse_type()}
		results = &ast.FieldList{List: []*ast.Field{fld}}
	case '(':
		results = p.parse_parameters()
	}
	return &ast.FuncType{Params: params, Results: results}
}

// MethodOrEmbedSpec = Name [ Signature ] .
func (p *gc_parser) parse_method_or_embed_spec() *ast.Field {
	name, nameexpr := p.parse_name()
	if p.tok == '(' {
		typ := p.parse_signature()
		return &ast.Field{
			Names: []*ast.Ident{ast.NewIdent(name)},
			Type:  typ,
		}
	}

	return &ast.Field{
		Type: nameexpr,
	}
}

// int_lit = [ "-" | "+" ] { "0" ... "9" } .
func (p *gc_parser) parse_int() {
	switch p.tok {
	case '-', '+':
		p.next()
	}
	p.expect(scanner.Int)
}

// number = int_lit [ "p" int_lit ] .
func (p *gc_parser) parse_number() {
	p.parse_int()
	if p.lit == "p" {
		p.next()
		p.parse_int()
	}
}

//-------------------------------------------------------------------------------
// gc_parser.types
//-------------------------------------------------------------------------------

// InterfaceType = "interface" "{" [ MethodOrEmbedList ] "}" .
// MethodOrEmbedList = MethodOrEmbedSpec { ";" MethodOrEmbedSpec } .
func (p *gc_parser) parse_interface_type() ast.Expr {
	var methods []*ast.Field
	parse_method := func() {
		meth := p.parse_method_or_embed_spec()
		methods = append(methods, meth)
	}

	p.expect_keyword("interface")
	p.expect('{')
	if p.tok != '}' {
		parse_method()
		for p.tok == ';' {
			p.next()
			parse_method()
		}
	}
	p.expect('}')
	return &ast.InterfaceType{Methods: &ast.FieldList{List: methods}}
}

// StructType = "struct" "{" [ FieldList ] "}" .
// FieldList = Field { ";" Field } .
func (p *gc_parser) parse_struct_type() ast.Expr {
	var fields []*ast.Field
	parse_field := func() {
		fld := p.parse_field()
		fields = append(fields, fld)
	}

	p.expect_keyword("struct")
	p.expect('{')
	if p.tok != '}' {
		parse_field()
		for p.tok == ';' {
			p.next()
			parse_field()
		}
	}
	p.expect('}')
	return &ast.StructType{Fields: &ast.FieldList{List: fields}}
}

// MapType = "map" "[" Type "]" Type .
func (p *gc_parser) parse_map_type() ast.Expr {
	p.expect_keyword("map")
	p.expect('[')
	key := p.parse_type()
	p.expect(']')
	elt := p.parse_type()
	return &ast.MapType{Key: key, Value: elt}
}

// ChanType = ( "chan" [ "<-" ] | "<-" "chan" ) Type .
func (p *gc_parser) parse_chan_type() ast.Expr {
	dir := ast.SEND | ast.RECV
	if p.tok == scanner.Ident {
		p.expect_keyword("chan")
		if p.tok == '<' {
			p.expect_special("<-")
			dir = ast.SEND
		}
	} else {
		p.expect_special("<-")
		p.expect_keyword("chan")
		dir = ast.RECV
	}

	elt := p.parse_type()
	return &ast.ChanType{Dir: dir, Value: elt}
}

// ArrayOrSliceType = ArrayType | SliceType .
// ArrayType = "[" int_lit "]" Type .
// SliceType = "[" "]" Type .
func (p *gc_parser) parse_array_or_slice_type() ast.Expr {
	p.expect('[')
	if p.tok == ']' {
		// SliceType
		p.next() // skip ']'
		return &ast.ArrayType{Len: nil, Elt: p.parse_type()}
	}

	// ArrayType
	lit := p.expect(scanner.Int)
	p.expect(']')
	return &ast.ArrayType{
		Len: &ast.BasicLit{Kind: token.INT, Value: lit},
		Elt: p.parse_type(),
	}
}

// Type =
//	BasicType | TypeName | ArrayType | SliceType | StructType |
//      PointerType | FuncType | InterfaceType | MapType | ChanType |
//      "(" Type ")" .
// BasicType = ident .
// TypeName = ExportedName .
// SliceType = "[" "]" Type .
// PointerType = "*" Type .
// FuncType = "func" Signature .
func (p *gc_parser) parse_type() ast.Expr {
	switch p.tok {
	case scanner.Ident:
		switch p.lit {
		case "struct":
			return p.parse_struct_type()
		case "func":
			p.next()
			return p.parse_signature()
		case "interface":
			return p.parse_interface_type()
		case "map":
			return p.parse_map_type()
		case "chan":
			return p.parse_chan_type()
		default:
			lit := p.lit
			p.next()
			return ast.NewIdent(lit)
		}
	case '@':
		return p.parse_exported_name()
	case '[':
		return p.parse_array_or_slice_type()
	case '*':
		p.next()
		return &ast.StarExpr{X: p.parse_type()}
	case '<':
		return p.parse_chan_type()
	case '(':
		p.next()
		typ := p.parse_type()
		p.expect(')')
		return typ
	}
	p.errorf("unexpected token: %s", scanner.TokenString(p.tok))
	return nil
}

//-------------------------------------------------------------------------------
// gc_parser.declarations
//-------------------------------------------------------------------------------

// ImportDecl = "import" identifier string_lit .
func (p *gc_parser) parse_import_decl() {
	p.expect_keyword("import")
	alias := p.expect(scanner.Ident)
	path := p.parse_package()
	fullName := "!" + path.Name + "!" + alias
	p.path_to_name[path.Name] = fullName
	p.pfc.add_package_to_scope(fullName, path.Name)
}

// ConstDecl   = "const" ExportedName [ Type ] "=" Literal .
// Literal     = bool_lit | int_lit | float_lit | complex_lit | string_lit .
// bool_lit    = "true" | "false" .
// complex_lit = "(" float_lit "+" float_lit ")" .
// rune_lit    = "(" int_lit "+" int_lit ")" .
// string_lit  = `"` { unicode_char } `"` .
func (p *gc_parser) parse_const_decl() (string, *ast.GenDecl) {
	// TODO: do we really need actual const value? gocode doesn't use this
	p.expect_keyword("const")
	name := p.parse_exported_name()

	var typ ast.Expr
	if p.tok != '=' {
		typ = p.parse_type()
	}

	p.expect('=')

	// skip the value
	switch p.tok {
	case scanner.Ident:
		// must be bool, true or false
		p.next()
	case '-', '+', scanner.Int:
		// number
		p.parse_number()
	case '(':
		// complex_lit or rune_lit
		p.next() // skip '('
		if p.tok == scanner.Char {
			p.next()
		} else {
			p.parse_number()
		}
		p.expect('+')
		p.parse_number()
		p.expect(')')
	case scanner.Char:
		p.next()
	case scanner.String:
		p.next()
	default:
		p.error("expected literal")
	}

	return name.X.(*ast.Ident).Name, &ast.GenDecl{
		Tok: token.CONST,
		Specs: []ast.Spec{
			&ast.ValueSpec{
				Names:  []*ast.Ident{name.Sel},
				Type:   typ,
				Values: []ast.Expr{&ast.BasicLit{Kind: token.INT, Value: "0"}},
			},
		},
	}
}

// TypeDecl = "type" ExportedName Type .
func (p *gc_parser) parse_type_decl() (string, *ast.GenDecl) {
	p.expect_keyword("type")
	name := p.parse_exported_name()
	typ := p.parse_type()
	return name.X.(*ast.Ident).Name, &ast.GenDecl{
		Tok: token.TYPE,
		Specs: []ast.Spec{
			&ast.TypeSpec{
				Name: name.Sel,
				Type: typ,
			},
		},
	}
}

// VarDecl = "var" ExportedName Type .
func (p *gc_parser) parse_var_decl() (string, *ast.GenDecl) {
	p.expect_keyword("var")
	name := p.parse_exported_name()
	typ := p.parse_type()
	return name.X.(*ast.Ident).Name, &ast.GenDecl{
		Tok: token.VAR,
		Specs: []ast.Spec{
			&ast.ValueSpec{
				Names: []*ast.Ident{name.Sel},
				Type:  typ,
			},
		},
	}
}

// FuncBody = "{" ... "}" .
func (p *gc_parser) parse_func_body() {
	p.expect('{')
	for i := 1; i > 0; p.next() {
		switch p.tok {
		case '{':
			i++
		case '}':
			i--
		}
	}
}

// FuncDecl = "func" ExportedName Signature [ FuncBody ] .
func (p *gc_parser) parse_func_decl() (string, *ast.FuncDecl) {
	// "func" was already consumed by lookahead
	name := p.parse_exported_name()
	typ := p.parse_signature()
	if p.tok == '{' {
		p.parse_func_body()
	}
	return name.X.(*ast.Ident).Name, &ast.FuncDecl{
		Name: name.Sel,
		Type: typ,
	}
}

func strip_method_receiver(recv *ast.FieldList) string {
	var sel *ast.SelectorExpr

	// find selector expression
	typ := recv.List[0].Type
	switch t := typ.(type) {
	case *ast.StarExpr:
		sel, _ = t.X.(*ast.SelectorExpr)
	case *ast.SelectorExpr:
		sel = t
	}

	// extract package path
	if sel != nil {
		pkg := sel.X.(*ast.Ident).Name

		// write back stripped type
		switch typ.(type) {
		case *ast.StarExpr:
			*recv = ast.FieldList{
				List: []*ast.Field{{Names: recv.List[0].Names, Type: &ast.StarExpr{X: sel.Sel}}},
			}
		case *ast.SelectorExpr:
			*recv = ast.FieldList{
				List: []*ast.Field{{Names: recv.List[0].Names, Type: sel.Sel}},
			}
		}
		return pkg
	} else {
		return ""
	}
}

// MethodDecl = "func" Receiver Name Signature .
// Receiver = "(" ( identifier | "?" ) [ "*" ] ExportedName ")" [ FuncBody ] .
func (p *gc_parser) parse_method_decl() (string, *ast.FuncDecl) {
	recv := p.parse_parameters()
	pkg := strip_method_receiver(recv)
	name, _ := p.parse_name()
	typ := p.parse_signature()
	if p.tok == '{' {
		p.parse_func_body()
	}
	return pkg, &ast.FuncDecl{
		Recv: recv,
		Name: ast.NewIdent(name),
		Type: typ,
	}
}

// Decl = [ ImportDecl | ConstDecl | TypeDecl | VarDecl | FuncDecl | MethodDecl ] "\n" .
func (p *gc_parser) parse_decl() (pkg string, decl ast.Decl) {
	switch p.lit {
	case "import":
		p.parse_import_decl()
	case "const":
		pkg, decl = p.parse_const_decl()
	case "type":
		pkg, decl = p.parse_type_decl()
	case "var":
		pkg, decl = p.parse_var_decl()
	case "func":
		p.next()
		if p.tok == '(' {
			pkg, decl = p.parse_method_decl()
		} else {
			pkg, decl = p.parse_func_decl()
		}
	}
	p.expect('\n')
	return
}

// Export = PackageClause { Decl } "$$" .
// PackageClause = "package" identifier [ "safe" ] "\n" .
func (p *gc_parser) parse_export(callback func(string, ast.Decl)) {
	p.expect_keyword("package")
	p.pfc.defalias = p.expect(scanner.Ident)
	if p.tok != '\n' {
		p.expect_keyword("safe")
	}
	p.expect('\n')

	for p.tok != '$' && p.tok != scanner.EOF {
		pkg, decl := p.parse_decl()
		if decl != nil {
			callback(pkg, decl)
		}
	}
}

"""



```