Response:
Let's break down the thought process for answering the request about the `writer_test.go` file.

**1. Understanding the Core Request:**

The primary goal is to understand the *functionality* of the provided Go code snippet. Since the file path is `go/src/archive/tar/writer_test.go`, the immediate assumption is that this code tests the `tar` package's *writer* functionality. This sets the context for the rest of the analysis.

**2. Initial Scan for Keywords and Structure:**

The next step is to quickly scan the code for key terms and the overall structure. I'd look for:

* **`package tar`**: Confirms the package being tested.
* **`import (...)`**: Identifies dependencies, which often hints at the functionality being tested (e.g., `bytes`, `io`, `os`, `testing`).
* **`func Test...`**:  Indicates test functions, which are the core of the file's purpose. I'd notice the prominent `TestWriter`, `TestPax`, etc.
* **Data structures:**  The `vectors` slice of structs is a strong indicator of test cases. I'd look at the fields within those structs (`file`, `tests`, `testHeader`, `testWrite`, etc.) to understand the testing strategy.
* **Helper functions:** `bytediff` suggests a comparison mechanism for byte arrays, likely used to verify the correctness of the tar archive output.
* **Error handling patterns:**  The `wantErr` field in the test structs indicates expectations for error conditions.

**3. Deeper Dive into `TestWriter`:**

The `TestWriter` function appears to be the central test function. Analyzing its structure:

* **`type (...)`**:  The defined types (`testHeader`, `testWrite`, `testReadFrom`, `testClose`) clearly represent different operations that can be performed with a `tar.Writer`. This is a strong clue about the `tar.Writer`'s interface.
* **`vectors := []struct { ... }`**:  This is the core of the test cases. Each element in `vectors` represents a specific scenario. The `file` field suggests testing against pre-generated tar files. The `tests` slice contains a series of actions to perform on a `tar.Writer`.
* **Switch statement within the loop:** This iterates through the `tests` and performs the corresponding action on the `tar.Writer` (`WriteHeader`, `Write`, `ReadFrom`, `Close`). This confirms the main operations being tested.
* **Comparison with `want`:** The code reads expected output from files (if `v.file` is set) and compares it with the output generated by the `tar.Writer`. This is a crucial validation step.

**4. Analyzing Other `Test...` Functions:**

The other test functions (`TestPax`, `TestPaxSymlink`, etc.) focus on specific aspects of the `tar.Writer`:

* **`TestPax`**: Likely tests the PAX format extensions for handling long filenames, etc.
* **`TestPaxSymlink`**: Similar to `TestPax`, but focusing on long link names in symbolic links.
* **`TestPaxNonAscii`**: Tests handling of non-ASCII characters in filenames and metadata, which also often triggers PAX extensions.
* **`TestPaxXattrs`**: Tests the writing and retrieval of extended attributes (xattrs).
* **`TestUSTARLongName`**: Tests handling of long paths specifically with the USTAR format.
* **`TestWriterErrors`**:  Specifically tests various error conditions that might arise when using the `tar.Writer`.

**5. Inferring Functionality and Providing Examples:**

Based on the test structure, the core functionality of the `tar.Writer` is to:

* **Write header information:**  Represented by `WriteHeader`.
* **Write file content:** Represented by `Write`.
* **Handle data from an `io.ReaderFrom`:** Represented by `readFrom`.
* **Close the writer:** Represented by `Close`.
* **Support different tar formats:**  Implied by the various test files and the mention of USTAR, PAX, and GNU formats.
* **Handle edge cases and errors:**  Tested by `TestWriterErrors`.

With this understanding, I could construct the Go code examples demonstrating `WriteHeader` and `Write`.

**6. Identifying Potential Pitfalls:**

By reviewing the test cases and error tests, I could identify common mistakes:

* Writing data before writing a header.
* Writing more data than specified in the header.
* Closing the writer prematurely.

**7. Summarizing the Functionality:**

Finally, I would synthesize the information gathered into a concise summary of the `writer_test.go` file's purpose: to rigorously test the functionality of the `tar.Writer` type, covering various scenarios, formats, and error conditions.

**Self-Correction/Refinement During the Process:**

* **Initial Assumption Check:**  While the file path strongly suggested testing the `tar.Writer`, I needed to confirm this by looking at the code's contents.
* **Understanding `testFnc`:**  Initially, the `testFnc any` might seem a bit opaque. However, looking at how it's used in the `vectors` and the `switch` statement clarifies that it's a type alias for the different test case structs.
* **Connecting Tests to Functionality:** The key was to link the specific test cases (e.g., testing long filenames) to the underlying features of the `tar.Writer` (e.g., PAX extensions).

By following these steps, I could systematically analyze the provided code and generate a comprehensive and accurate response to the request.
这段代码是 Go 语言标准库 `archive/tar` 包中 `writer_test.go` 文件的一部分，其主要功能是**测试 `tar` 包中 `Writer` 类型的各项功能**。

更具体地说，它通过一系列的测试用例来验证 `tar.Writer` 是否能够正确地：

1. **写入 tar 文件头 (Header)：**  测试 `WriteHeader` 方法能否正确地将 `Header` 结构体的信息写入 tar 文件的头部，包括文件名、大小、权限、时间戳等元数据。
2. **写入文件内容 (Data)：** 测试 `Write` 方法能否将数据正确地写入 tar 文件中，并与文件头中指定的大小保持一致。
3. **处理不同类型的条目 (Typeflag)：** 测试 `Writer` 是否能正确处理不同类型的 tar 条目，如普通文件 (TypeReg)、符号链接 (TypeSymlink)、硬链接 (TypeLink)、目录等。
4. **处理不同格式的 tar 文件：** 测试 `Writer` 是否支持并能正确生成不同格式的 tar 文件，例如 USTAR、GNU 和 PAX 格式。
5. **处理特殊情况：**
    * **长文件名和长链接名：** 测试使用 PAX 扩展头来处理超出 USTAR 格式限制的长文件名和长链接名。
    * **非 ASCII 字符：** 测试是否能正确处理包含非 ASCII 字符的文件名、用户名和组名，通常也涉及到 PAX 扩展头。
    * **扩展属性 (Xattrs)：** 测试是否能写入和读取文件的扩展属性。
    * **稀疏文件：** (代码中有被注释掉的部分，表明可能正在开发或测试稀疏文件的支持) 尝试测试稀疏文件的写入。
    * **错误处理：** 测试在各种错误情况下 `Writer` 的行为，例如写入数据前未写入头部、写入数据量超过头部指定大小、在 `Close` 之后写入等。
6. **与预期的 tar 文件进行比较：**  许多测试用例会读取预先生成的 tar 文件（存放在 `testdata` 目录下），并将 `Writer` 生成的 tar 文件与之进行二进制级别的比较，以验证其正确性。

**它是什么 go 语言功能的实现？**

这段代码主要是对 Go 语言标准库中 `archive/tar` 包的 **`Writer` 类型** 的功能进行测试。 `tar.Writer` 实现了将文件和目录等内容打包成 tar 归档的功能。

**go 代码举例说明:**

以下是一个简单的例子，展示了如何使用 `tar.Writer` 将一个文件添加到 tar 归档中：

```go
package main

import (
	"archive/tar"
	"bytes"
	"fmt"
	"io"
	"os"
	"time"
)

func main() {
	var buf bytes.Buffer
	tw := tar.NewWriter(&buf)

	// 创建 tar 文件头
	header := &tar.Header{
		Name:    "hello.txt",
		Size:    int64(len("Hello, world!")),
		Mode:    0600,
		ModTime: time.Now(),
	}
	if err := tw.WriteHeader(header); err != nil {
		fmt.Println(err)
		return
	}

	// 写入文件内容
	if _, err := tw.Write([]byte("Hello, world!")); err != nil {
		fmt.Println(err)
		return
	}

	// 完成 tar 归档
	if err := tw.Close(); err != nil {
		fmt.Println(err)
		return
	}

	// 将生成的 tar 归档写入文件 (可选)
	if err := os.WriteFile("output.tar", buf.Bytes(), 0644); err != nil {
		fmt.Println(err)
		return
	}

	fmt.Println("Tar archive created successfully!")
}
```

**假设的输入与输出 (针对 `TestWriter` 中的一个用例):**

假设我们看 `TestWriter` 中的第一个 `vectors` 中的第一个测试用例：

```go
{
    file: "testdata/writer.tar",
    tests: []testFnc{
        testHeader{Header{
            Typeflag: TypeReg,
            Name:     "small.txt",
            Size:     5,
            Mode:     0640,
            Uid:      73025,
            Gid:      5000,
            Uname:    "dsymonds",
            Gname:    "eng",
            ModTime:  time.Unix(1246508266, 0),
        }, nil},
        testWrite{"Kilts", 5, nil},
        // ... 更多测试用例
    },
},
```

* **假设输入：**  一个空的 `bytes.Buffer` 和一个指向该 buffer 的 `tar.Writer`。
* **执行的 `testFnc`：**
    1. `testHeader`: 调用 `tw.WriteHeader()` 并传入一个描述名为 "small.txt" 的文件的 `Header` 结构体。
    2. `testWrite`: 调用 `tw.Write()` 并传入字符串 "Kilts"。
* **预期输出：** `tar.Writer` 会将 "small.txt" 文件的头部信息和内容 "Kilts" 写入到 `bytes.Buffer` 中。  最终生成的 buffer 的内容应该与 `testdata/writer.tar` 文件中 "small.txt" 条目的内容一致。

**命令行参数的具体处理:**

这段代码本身是测试代码，并不直接处理命令行参数。 `tar` 包本身作为一个库，其功能通常被其他程序调用，这些程序可能会处理命令行参数来决定如何创建 tar 归档。  例如，Go 语言的 `archive/tar` 包会被 Linux 的 `tar` 命令使用，而 `tar` 命令会接收各种命令行参数来控制归档的行为（例如，`-c` 用于创建归档，`-f` 指定归档文件名等）。

**使用者易犯错的点:**

以下是一些使用 `tar.Writer` 时容易犯的错误：

1. **在 `WriteHeader` 之前调用 `Write`：** 必须先写入文件头，才能写入文件内容。
   ```go
   var buf bytes.Buffer
   tw := tar.NewWriter(&buf)
   _, err := tw.Write([]byte("content")) // 错误：在 WriteHeader 之前调用 Write
   if err != nil {
       fmt.Println(err) // 会得到 ErrWriteTooLong 错误
   }
   ```

2. **写入的数据大小与 `Header` 中声明的大小不符：** `tar.Writer` 会检查写入的数据量是否与 `Header.Size` 一致。
   ```go
   var buf bytes.Buffer
   tw := tar.NewWriter(&buf)
   header := &tar.Header{Name: "file.txt", Size: 10}
   tw.WriteHeader(header)
   _, err := tw.Write([]byte("short")) // 错误：写入的数据小于 Header 中声明的大小
   if err != nil {
       fmt.Println(err) // 在 Close 或 Flush 时会报错
   }
   ```

3. **忘记调用 `Close`：**  `Close` 方法会写入 tar 归档的结尾记录，并刷新缓冲区。忘记调用会导致归档不完整。
   ```go
   var buf bytes.Buffer
   tw := tar.NewWriter(&buf)
   // ... 写入文件头和内容
   // 忘记调用 tw.Close()
   ```

4. **在 `Close` 之后调用 `Write` 或 `WriteHeader`：**  `Close` 方法会使 `Writer` 进入已关闭状态，后续的写入操作会报错。
   ```go
   var buf bytes.Buffer
   tw := tar.NewWriter(&buf)
   tw.Close()
   _, err := tw.Write([]byte("content")) // 错误：在 Close 之后调用 Write
   if err != nil {
       fmt.Println(err) // 会得到 ErrWriteAfterClose 错误
   }
   ```

**归纳一下它的功能 (第 1 部分):**

这段代码的主要功能是**全面测试 `archive/tar` 包中 `Writer` 类型的功能，验证其能否正确地创建符合 tar 格式规范的归档文件，并能处理各种边界情况和错误场景。** 它通过定义一系列的测试用例，模拟不同的写入操作和 tar 文件结构，并将生成的输出与预期的结果进行比较，从而确保 `tar.Writer` 的正确性和可靠性。

Prompt: 
```
这是路径为go/src/archive/tar/writer_test.go的go语言实现的一部分， 请列举一下它的功能, 　
如果你能推理出它是什么go语言功能的实现，请用go代码举例说明, 
如果涉及代码推理，需要带上假设的输入与输出，
如果涉及命令行参数的具体处理，请详细介绍一下，
如果有哪些使用者易犯错的点，请举例说明，没有则不必说明，
请用中文回答。
这是第1部分，共2部分，请归纳一下它的功能

"""
// Copyright 2009 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package tar

import (
	"bytes"
	"encoding/hex"
	"errors"
	"io"
	"io/fs"
	"maps"
	"os"
	"path"
	"slices"
	"sort"
	"strings"
	"testing"
	"testing/fstest"
	"testing/iotest"
	"time"
)

func bytediff(a, b []byte) string {
	const (
		uniqueA  = "-  "
		uniqueB  = "+  "
		identity = "   "
	)
	var ss []string
	sa := strings.Split(strings.TrimSpace(hex.Dump(a)), "\n")
	sb := strings.Split(strings.TrimSpace(hex.Dump(b)), "\n")
	for len(sa) > 0 && len(sb) > 0 {
		if sa[0] == sb[0] {
			ss = append(ss, identity+sa[0])
		} else {
			ss = append(ss, uniqueA+sa[0])
			ss = append(ss, uniqueB+sb[0])
		}
		sa, sb = sa[1:], sb[1:]
	}
	for len(sa) > 0 {
		ss = append(ss, uniqueA+sa[0])
		sa = sa[1:]
	}
	for len(sb) > 0 {
		ss = append(ss, uniqueB+sb[0])
		sb = sb[1:]
	}
	return strings.Join(ss, "\n")
}

func TestWriter(t *testing.T) {
	type (
		testHeader struct { // WriteHeader(hdr) == wantErr
			hdr     Header
			wantErr error
		}
		testWrite struct { // Write(str) == (wantCnt, wantErr)
			str     string
			wantCnt int
			wantErr error
		}
		testReadFrom struct { // ReadFrom(testFile{ops}) == (wantCnt, wantErr)
			ops     fileOps
			wantCnt int64
			wantErr error
		}
		testClose struct { // Close() == wantErr
			wantErr error
		}
		testFnc any // testHeader | testWrite | testReadFrom | testClose
	)

	vectors := []struct {
		file  string // Optional filename of expected output
		tests []testFnc
	}{{
		// The writer test file was produced with this command:
		// tar (GNU tar) 1.26
		//   ln -s small.txt link.txt
		//   tar -b 1 --format=ustar -c -f writer.tar small.txt small2.txt link.txt
		file: "testdata/writer.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "small.txt",
				Size:     5,
				Mode:     0640,
				Uid:      73025,
				Gid:      5000,
				Uname:    "dsymonds",
				Gname:    "eng",
				ModTime:  time.Unix(1246508266, 0),
			}, nil},
			testWrite{"Kilts", 5, nil},

			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "small2.txt",
				Size:     11,
				Mode:     0640,
				Uid:      73025,
				Uname:    "dsymonds",
				Gname:    "eng",
				Gid:      5000,
				ModTime:  time.Unix(1245217492, 0),
			}, nil},
			testWrite{"Google.com\n", 11, nil},

			testHeader{Header{
				Typeflag: TypeSymlink,
				Name:     "link.txt",
				Linkname: "small.txt",
				Mode:     0777,
				Uid:      1000,
				Gid:      1000,
				Uname:    "strings",
				Gname:    "strings",
				ModTime:  time.Unix(1314603082, 0),
			}, nil},
			testWrite{"", 0, nil},

			testClose{nil},
		},
	}, {
		// The truncated test file was produced using these commands:
		//   dd if=/dev/zero bs=1048576 count=16384 > /tmp/16gig.txt
		//   tar -b 1 -c -f- /tmp/16gig.txt | dd bs=512 count=8 > writer-big.tar
		file: "testdata/writer-big.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "tmp/16gig.txt",
				Size:     16 << 30,
				Mode:     0640,
				Uid:      73025,
				Gid:      5000,
				Uname:    "dsymonds",
				Gname:    "eng",
				ModTime:  time.Unix(1254699560, 0),
				Format:   FormatGNU,
			}, nil},
		},
	}, {
		// This truncated file was produced using this library.
		// It was verified to work with GNU tar 1.27.1 and BSD tar 3.1.2.
		//  dd if=/dev/zero bs=1G count=16 >> writer-big-long.tar
		//  gnutar -xvf writer-big-long.tar
		//  bsdtar -xvf writer-big-long.tar
		//
		// This file is in PAX format.
		file: "testdata/writer-big-long.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     strings.Repeat("longname/", 15) + "16gig.txt",
				Size:     16 << 30,
				Mode:     0644,
				Uid:      1000,
				Gid:      1000,
				Uname:    "guillaume",
				Gname:    "guillaume",
				ModTime:  time.Unix(1399583047, 0),
			}, nil},
		},
	}, {
		// This file was produced using GNU tar v1.17.
		//	gnutar -b 4 --format=ustar (longname/)*15 + file.txt
		file: "testdata/ustar.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     strings.Repeat("longname/", 15) + "file.txt",
				Size:     6,
				Mode:     0644,
				Uid:      501,
				Gid:      20,
				Uname:    "shane",
				Gname:    "staff",
				ModTime:  time.Unix(1360135598, 0),
			}, nil},
			testWrite{"hello\n", 6, nil},
			testClose{nil},
		},
	}, {
		// This file was produced using GNU tar v1.26:
		//	echo "Slartibartfast" > file.txt
		//	ln file.txt hard.txt
		//	tar -b 1 --format=ustar -c -f hardlink.tar file.txt hard.txt
		file: "testdata/hardlink.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "file.txt",
				Size:     15,
				Mode:     0644,
				Uid:      1000,
				Gid:      100,
				Uname:    "vbatts",
				Gname:    "users",
				ModTime:  time.Unix(1425484303, 0),
			}, nil},
			testWrite{"Slartibartfast\n", 15, nil},

			testHeader{Header{
				Typeflag: TypeLink,
				Name:     "hard.txt",
				Linkname: "file.txt",
				Mode:     0644,
				Uid:      1000,
				Gid:      100,
				Uname:    "vbatts",
				Gname:    "users",
				ModTime:  time.Unix(1425484303, 0),
			}, nil},
			testWrite{"", 0, nil},

			testClose{nil},
		},
	}, {
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "bad-null.txt",
				Xattrs:   map[string]string{"null\x00null\x00": "fizzbuzz"},
			}, headerError{}},
		},
	}, {
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "null\x00.txt",
			}, headerError{}},
		},
	}, {
		file: "testdata/pax-records.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "file",
				Uname:    strings.Repeat("long", 10),
				PAXRecords: map[string]string{
					"path":           "FILE", // Should be ignored
					"GNU.sparse.map": "0,0",  // Should be ignored
					"comment":        "Hello, 世界",
					"GOLANG.pkg":     "tar",
				},
			}, nil},
			testClose{nil},
		},
	}, {
		// Craft a theoretically valid PAX archive with global headers.
		// The GNU and BSD tar tools do not parse these the same way.
		//
		// BSD tar v3.1.2 parses and ignores all global headers;
		// the behavior is verified by researching the source code.
		//
		//	$ bsdtar -tvf pax-global-records.tar
		//	----------  0 0      0           0 Dec 31  1969 file1
		//	----------  0 0      0           0 Dec 31  1969 file2
		//	----------  0 0      0           0 Dec 31  1969 file3
		//	----------  0 0      0           0 May 13  2014 file4
		//
		// GNU tar v1.27.1 applies global headers to subsequent records,
		// but does not do the following properly:
		//	* It does not treat an empty record as deletion.
		//	* It does not use subsequent global headers to update previous ones.
		//
		//	$ gnutar -tvf pax-global-records.tar
		//	---------- 0/0               0 2017-07-13 19:40 global1
		//	---------- 0/0               0 2017-07-13 19:40 file2
		//	gnutar: Substituting `.' for empty member name
		//	---------- 0/0               0 1969-12-31 16:00
		//	gnutar: Substituting `.' for empty member name
		//	---------- 0/0               0 2014-05-13 09:53
		//
		// According to the PAX specification, this should have been the result:
		//	---------- 0/0               0 2017-07-13 19:40 global1
		//	---------- 0/0               0 2017-07-13 19:40 file2
		//	---------- 0/0               0 2017-07-13 19:40 file3
		//	---------- 0/0               0 2014-05-13 09:53 file4
		file: "testdata/pax-global-records.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag:   TypeXGlobalHeader,
				PAXRecords: map[string]string{"path": "global1", "mtime": "1500000000.0"},
			}, nil},
			testHeader{Header{
				Typeflag: TypeReg, Name: "file1",
			}, nil},
			testHeader{Header{
				Typeflag:   TypeReg,
				Name:       "file2",
				PAXRecords: map[string]string{"path": "file2"},
			}, nil},
			testHeader{Header{
				Typeflag:   TypeXGlobalHeader,
				PAXRecords: map[string]string{"path": ""}, // Should delete "path", but keep "mtime"
			}, nil},
			testHeader{Header{
				Typeflag: TypeReg, Name: "file3",
			}, nil},
			testHeader{Header{
				Typeflag:   TypeReg,
				Name:       "file4",
				ModTime:    time.Unix(1400000000, 0),
				PAXRecords: map[string]string{"mtime": "1400000000"},
			}, nil},
			testClose{nil},
		},
	}, {
		file: "testdata/gnu-utf8.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹☺☻☹",
				Mode:     0644,
				Uid:      1000, Gid: 1000,
				Uname:   "☺",
				Gname:   "⚹",
				ModTime: time.Unix(0, 0),
				Format:  FormatGNU,
			}, nil},
			testClose{nil},
		},
	}, {
		file: "testdata/gnu-not-utf8.tar",
		tests: []testFnc{
			testHeader{Header{
				Typeflag: TypeReg,
				Name:     "hi\x80\x81\x82\x83bye",
				Mode:     0644,
				Uid:      1000,
				Gid:      1000,
				Uname:    "rawr",
				Gname:    "dsnet",
				ModTime:  time.Unix(0, 0),
				Format:   FormatGNU,
			}, nil},
			testClose{nil},
		},
		// TODO(dsnet): Re-enable this test when adding sparse support.
		// See https://golang.org/issue/22735
		/*
			}, {
				file: "testdata/gnu-nil-sparse-data.tar",
				tests: []testFnc{
					testHeader{Header{
						Typeflag:    TypeGNUSparse,
						Name:        "sparse.db",
						Size:        1000,
						SparseHoles: []sparseEntry{{Offset: 1000, Length: 0}},
					}, nil},
					testWrite{strings.Repeat("0123456789", 100), 1000, nil},
					testClose{},
				},
			}, {
				file: "testdata/gnu-nil-sparse-hole.tar",
				tests: []testFnc{
					testHeader{Header{
						Typeflag:    TypeGNUSparse,
						Name:        "sparse.db",
						Size:        1000,
						SparseHoles: []sparseEntry{{Offset: 0, Length: 1000}},
					}, nil},
					testWrite{strings.Repeat("\x00", 1000), 1000, nil},
					testClose{},
				},
			}, {
				file: "testdata/pax-nil-sparse-data.tar",
				tests: []testFnc{
					testHeader{Header{
						Typeflag:    TypeReg,
						Name:        "sparse.db",
						Size:        1000,
						SparseHoles: []sparseEntry{{Offset: 1000, Length: 0}},
					}, nil},
					testWrite{strings.Repeat("0123456789", 100), 1000, nil},
					testClose{},
				},
			}, {
				file: "testdata/pax-nil-sparse-hole.tar",
				tests: []testFnc{
					testHeader{Header{
						Typeflag:    TypeReg,
						Name:        "sparse.db",
						Size:        1000,
						SparseHoles: []sparseEntry{{Offset: 0, Length: 1000}},
					}, nil},
					testWrite{strings.Repeat("\x00", 1000), 1000, nil},
					testClose{},
				},
			}, {
				file: "testdata/gnu-sparse-big.tar",
				tests: []testFnc{
					testHeader{Header{
						Typeflag: TypeGNUSparse,
						Name:     "gnu-sparse",
						Size:     6e10,
						SparseHoles: []sparseEntry{
							{Offset: 0e10, Length: 1e10 - 100},
							{Offset: 1e10, Length: 1e10 - 100},
							{Offset: 2e10, Length: 1e10 - 100},
							{Offset: 3e10, Length: 1e10 - 100},
							{Offset: 4e10, Length: 1e10 - 100},
							{Offset: 5e10, Length: 1e10 - 100},
						},
					}, nil},
					testReadFrom{fileOps{
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
					}, 6e10, nil},
					testClose{nil},
				},
			}, {
				file: "testdata/pax-sparse-big.tar",
				tests: []testFnc{
					testHeader{Header{
						Typeflag: TypeReg,
						Name:     "pax-sparse",
						Size:     6e10,
						SparseHoles: []sparseEntry{
							{Offset: 0e10, Length: 1e10 - 100},
							{Offset: 1e10, Length: 1e10 - 100},
							{Offset: 2e10, Length: 1e10 - 100},
							{Offset: 3e10, Length: 1e10 - 100},
							{Offset: 4e10, Length: 1e10 - 100},
							{Offset: 5e10, Length: 1e10 - 100},
						},
					}, nil},
					testReadFrom{fileOps{
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
						int64(1e10 - blockSize),
						strings.Repeat("\x00", blockSize-100) + strings.Repeat("0123456789", 10),
					}, 6e10, nil},
					testClose{nil},
				},
		*/
	}, {
		file: "testdata/trailing-slash.tar",
		tests: []testFnc{
			testHeader{Header{Name: strings.Repeat("123456789/", 30)}, nil},
			testClose{nil},
		},
	}, {
		// Automatically promote zero value of Typeflag depending on the name.
		file: "testdata/file-and-dir.tar",
		tests: []testFnc{
			testHeader{Header{Name: "small.txt", Size: 5}, nil},
			testWrite{"Kilts", 5, nil},
			testHeader{Header{Name: "dir/"}, nil},
			testClose{nil},
		},
	}}

	equalError := func(x, y error) bool {
		_, ok1 := x.(headerError)
		_, ok2 := y.(headerError)
		if ok1 || ok2 {
			return ok1 && ok2
		}
		return x == y
	}
	for _, v := range vectors {
		t.Run(path.Base(v.file), func(t *testing.T) {
			const maxSize = 10 << 10 // 10KiB
			buf := new(bytes.Buffer)
			tw := NewWriter(iotest.TruncateWriter(buf, maxSize))

			for i, tf := range v.tests {
				switch tf := tf.(type) {
				case testHeader:
					err := tw.WriteHeader(&tf.hdr)
					if !equalError(err, tf.wantErr) {
						t.Fatalf("test %d, WriteHeader() = %v, want %v", i, err, tf.wantErr)
					}
				case testWrite:
					got, err := tw.Write([]byte(tf.str))
					if got != tf.wantCnt || !equalError(err, tf.wantErr) {
						t.Fatalf("test %d, Write() = (%d, %v), want (%d, %v)", i, got, err, tf.wantCnt, tf.wantErr)
					}
				case testReadFrom:
					f := &testFile{ops: tf.ops}
					got, err := tw.readFrom(f)
					if _, ok := err.(testError); ok {
						t.Errorf("test %d, ReadFrom(): %v", i, err)
					} else if got != tf.wantCnt || !equalError(err, tf.wantErr) {
						t.Errorf("test %d, ReadFrom() = (%d, %v), want (%d, %v)", i, got, err, tf.wantCnt, tf.wantErr)
					}
					if len(f.ops) > 0 {
						t.Errorf("test %d, expected %d more operations", i, len(f.ops))
					}
				case testClose:
					err := tw.Close()
					if !equalError(err, tf.wantErr) {
						t.Fatalf("test %d, Close() = %v, want %v", i, err, tf.wantErr)
					}
				default:
					t.Fatalf("test %d, unknown test operation: %T", i, tf)
				}
			}

			if v.file != "" {
				want, err := os.ReadFile(v.file)
				if err != nil {
					t.Fatalf("ReadFile() = %v, want nil", err)
				}
				got := buf.Bytes()
				if !bytes.Equal(want, got) {
					t.Fatalf("incorrect result: (-got +want)\n%v", bytediff(got, want))
				}
			}
		})
	}
}

func TestPax(t *testing.T) {
	// Create an archive with a large name
	fileinfo, err := os.Stat("testdata/small.txt")
	if err != nil {
		t.Fatal(err)
	}
	hdr, err := FileInfoHeader(fileinfo, "")
	if err != nil {
		t.Fatalf("os.Stat: %v", err)
	}
	// Force a PAX long name to be written
	longName := strings.Repeat("ab", 100)
	contents := strings.Repeat(" ", int(hdr.Size))
	hdr.Name = longName
	var buf bytes.Buffer
	writer := NewWriter(&buf)
	if err := writer.WriteHeader(hdr); err != nil {
		t.Fatal(err)
	}
	if _, err = writer.Write([]byte(contents)); err != nil {
		t.Fatal(err)
	}
	if err := writer.Close(); err != nil {
		t.Fatal(err)
	}
	// Simple test to make sure PAX extensions are in effect
	if !bytes.Contains(buf.Bytes(), []byte("PaxHeaders.0")) {
		t.Fatal("Expected at least one PAX header to be written.")
	}
	// Test that we can get a long name back out of the archive.
	reader := NewReader(&buf)
	hdr, err = reader.Next()
	if err != nil {
		t.Fatal(err)
	}
	if hdr.Name != longName {
		t.Fatal("Couldn't recover long file name")
	}
}

func TestPaxSymlink(t *testing.T) {
	// Create an archive with a large linkname
	fileinfo, err := os.Stat("testdata/small.txt")
	if err != nil {
		t.Fatal(err)
	}
	hdr, err := FileInfoHeader(fileinfo, "")
	if err != nil {
		t.Fatalf("os.Stat:1 %v", err)
	}
	hdr.Typeflag = TypeSymlink
	// Force a PAX long linkname to be written
	longLinkname := strings.Repeat("1234567890/1234567890", 10)
	hdr.Linkname = longLinkname

	hdr.Size = 0
	var buf bytes.Buffer
	writer := NewWriter(&buf)
	if err := writer.WriteHeader(hdr); err != nil {
		t.Fatal(err)
	}
	if err := writer.Close(); err != nil {
		t.Fatal(err)
	}
	// Simple test to make sure PAX extensions are in effect
	if !bytes.Contains(buf.Bytes(), []byte("PaxHeaders.0")) {
		t.Fatal("Expected at least one PAX header to be written.")
	}
	// Test that we can get a long name back out of the archive.
	reader := NewReader(&buf)
	hdr, err = reader.Next()
	if err != nil {
		t.Fatal(err)
	}
	if hdr.Linkname != longLinkname {
		t.Fatal("Couldn't recover long link name")
	}
}

func TestPaxNonAscii(t *testing.T) {
	// Create an archive with non ascii. These should trigger a pax header
	// because pax headers have a defined utf-8 encoding.
	fileinfo, err := os.Stat("testdata/small.txt")
	if err != nil {
		t.Fatal(err)
	}

	hdr, err := FileInfoHeader(fileinfo, "")
	if err != nil {
		t.Fatalf("os.Stat:1 %v", err)
	}

	// some sample data
	chineseFilename := "文件名"
	chineseGroupname := "組"
	chineseUsername := "用戶名"

	hdr.Name = chineseFilename
	hdr.Gname = chineseGroupname
	hdr.Uname = chineseUsername

	contents := strings.Repeat(" ", int(hdr.Size))

	var buf bytes.Buffer
	writer := NewWriter(&buf)
	if err := writer.WriteHeader(hdr); err != nil {
		t.Fatal(err)
	}
	if _, err = writer.Write([]byte(contents)); err != nil {
		t.Fatal(err)
	}
	if err := writer.Close(); err != nil {
		t.Fatal(err)
	}
	// Simple test to make sure PAX extensions are in effect
	if !bytes.Contains(buf.Bytes(), []byte("PaxHeaders.0")) {
		t.Fatal("Expected at least one PAX header to be written.")
	}
	// Test that we can get a long name back out of the archive.
	reader := NewReader(&buf)
	hdr, err = reader.Next()
	if err != nil {
		t.Fatal(err)
	}
	if hdr.Name != chineseFilename {
		t.Fatal("Couldn't recover unicode name")
	}
	if hdr.Gname != chineseGroupname {
		t.Fatal("Couldn't recover unicode group")
	}
	if hdr.Uname != chineseUsername {
		t.Fatal("Couldn't recover unicode user")
	}
}

func TestPaxXattrs(t *testing.T) {
	xattrs := map[string]string{
		"user.key": "value",
	}

	// Create an archive with an xattr
	fileinfo, err := os.Stat("testdata/small.txt")
	if err != nil {
		t.Fatal(err)
	}
	hdr, err := FileInfoHeader(fileinfo, "")
	if err != nil {
		t.Fatalf("os.Stat: %v", err)
	}
	contents := "Kilts"
	hdr.Xattrs = xattrs
	var buf bytes.Buffer
	writer := NewWriter(&buf)
	if err := writer.WriteHeader(hdr); err != nil {
		t.Fatal(err)
	}
	if _, err = writer.Write([]byte(contents)); err != nil {
		t.Fatal(err)
	}
	if err := writer.Close(); err != nil {
		t.Fatal(err)
	}
	// Test that we can get the xattrs back out of the archive.
	reader := NewReader(&buf)
	hdr, err = reader.Next()
	if err != nil {
		t.Fatal(err)
	}
	if !maps.Equal(hdr.Xattrs, xattrs) {
		t.Fatalf("xattrs did not survive round trip: got %+v, want %+v",
			hdr.Xattrs, xattrs)
	}
}

func TestPaxHeadersSorted(t *testing.T) {
	fileinfo, err := os.Stat("testdata/small.txt")
	if err != nil {
		t.Fatal(err)
	}
	hdr, err := FileInfoHeader(fileinfo, "")
	if err != nil {
		t.Fatalf("os.Stat: %v", err)
	}
	contents := strings.Repeat(" ", int(hdr.Size))

	hdr.Xattrs = map[string]string{
		"foo": "foo",
		"bar": "bar",
		"baz": "baz",
		"qux": "qux",
	}

	var buf bytes.Buffer
	writer := NewWriter(&buf)
	if err := writer.WriteHeader(hdr); err != nil {
		t.Fatal(err)
	}
	if _, err = writer.Write([]byte(contents)); err != nil {
		t.Fatal(err)
	}
	if err := writer.Close(); err != nil {
		t.Fatal(err)
	}
	// Simple test to make sure PAX extensions are in effect
	if !bytes.Contains(buf.Bytes(), []byte("PaxHeaders.0")) {
		t.Fatal("Expected at least one PAX header to be written.")
	}

	// xattr bar should always appear before others
	indices := []int{
		bytes.Index(buf.Bytes(), []byte("bar=bar")),
		bytes.Index(buf.Bytes(), []byte("baz=baz")),
		bytes.Index(buf.Bytes(), []byte("foo=foo")),
		bytes.Index(buf.Bytes(), []byte("qux=qux")),
	}
	if !slices.IsSorted(indices) {
		t.Fatal("PAX headers are not sorted")
	}
}

func TestUSTARLongName(t *testing.T) {
	// Create an archive with a path that failed to split with USTAR extension in previous versions.
	fileinfo, err := os.Stat("testdata/small.txt")
	if err != nil {
		t.Fatal(err)
	}
	hdr, err := FileInfoHeader(fileinfo, "")
	if err != nil {
		t.Fatalf("os.Stat:1 %v", err)
	}
	hdr.Typeflag = TypeDir
	// Force a PAX long name to be written. The name was taken from a practical example
	// that fails and replaced ever char through numbers to anonymize the sample.
	longName := "/0000_0000000/00000-000000000/0000_0000000/00000-0000000000000/0000_0000000/00000-0000000-00000000/0000_0000000/00000000/0000_0000000/000/0000_0000000/00000000v00/0000_0000000/000000/0000_0000000/0000000/0000_0000000/00000y-00/0000/0000/00000000/0x000000/"
	hdr.Name = longName

	hdr.Size = 0
	var buf bytes.Buffer
	writer := NewWriter(&buf)
	if err := writer.WriteHeader(hdr); err != nil {
		t.Fatal(err)
	}
	if err := writer.Close(); err != nil {
		t.Fatal(err)
	}
	// Test that we can get a long name back out of the archive.
	reader := NewReader(&buf)
	hdr, err = reader.Next()
	if err != nil && err != ErrInsecurePath {
		t.Fatal(err)
	}
	if hdr.Name != longName {
		t.Fatal("Couldn't recover long name")
	}
}

func TestValidTypeflagWithPAXHeader(t *testing.T) {
	var buffer bytes.Buffer
	tw := NewWriter(&buffer)

	fileName := strings.Repeat("ab", 100)

	hdr := &Header{
		Name:     fileName,
		Size:     4,
		Typeflag: 0,
	}
	if err := tw.WriteHeader(hdr); err != nil {
		t.Fatalf("Failed to write header: %s", err)
	}
	if _, err := tw.Write([]byte("fooo")); err != nil {
		t.Fatalf("Failed to write the file's data: %s", err)
	}
	tw.Close()

	tr := NewReader(&buffer)

	for {
		header, err := tr.Next()
		if err == io.EOF {
			break
		}
		if err != nil {
			t.Fatalf("Failed to read header: %s", err)
		}
		if header.Typeflag != TypeReg {
			t.Fatalf("Typeflag should've been %d, found %d", TypeReg, header.Typeflag)
		}
	}
}

// failOnceWriter fails exactly once and then always reports success.
type failOnceWriter bool

func (w *failOnceWriter) Write(b []byte) (int, error) {
	if !*w {
		return 0, io.ErrShortWrite
	}
	*w = true
	return len(b), nil
}

func TestWriterErrors(t *testing.T) {
	t.Run("HeaderOnly", func(t *testing.T) {
		tw := NewWriter(new(bytes.Buffer))
		hdr := &Header{Name: "dir/", Typeflag: TypeDir}
		if err := tw.WriteHeader(hdr); err != nil {
			t.Fatalf("WriteHeader() = %v, want nil", err)
		}
		if _, err := tw.Write([]byte{0x00}); err != ErrWriteTooLong {
			t.Fatalf("Write() = %v, want %v", err, ErrWriteTooLong)
		}
	})

	t.Run("NegativeSize", func(t *testing.T) {
		tw := NewWriter(new(bytes.Buffer))
		hdr := &Header{Name: "small.txt", Size: -1}
		if err := tw.WriteHeader(hdr); err == nil {
			t.Fatalf("WriteHeader() = nil, want non-nil error")
		}
	})

	t.Run("BeforeHeader", func(t *testing.T) {
		tw := NewWriter(new(bytes.Buffer))
		if _, err := tw.Write([]byte("Kilts")); err != ErrWriteTooLong {
			t.Fatalf("Write() = %v, want %v", err, ErrWriteTooLong)
		}
	})

	t.Run("AfterClose", func(t *testing.T) {
		tw := NewWriter(new(bytes.Buffer))
		hdr := &Header{Name: "small.txt"}
		if err := tw.WriteHeader(hdr); err != nil {
			t.Fatalf("WriteHeader() = %v, want nil", err)
		}
		if err := tw.Close(); err != nil {
			t.Fatalf("Close() = %v, want nil", err)
		}
		if _, err := tw.Write([]byte("Kilts")); err != ErrWriteAfterClose {
			t.Fatalf("Write() = %v, want %v", err, ErrWriteAfterClose)
		}
		if err := tw.Flush(); err != ErrWriteAfterClose {
			t.Fatalf("Flush() = %v, want %v", err, ErrWriteAfterClose)
		}
		if err := tw.Close(); err != nil {
			t.Fatalf("Close() = %v, want nil", err)
		}
	})

	t.Run("PrematureFlush", func(t *testing.T) {
		tw := NewWriter(new(bytes.Buffer))
		hdr := &Header{Name: "small.txt", Size: 5}
		if err := tw.WriteHeader(hdr); err != nil {
			t.Fatalf("WriteHeader() = %v, want nil", err)
		}
		if err := tw.Flush(); err == nil {
			t.Fatalf("Flush() = %v, want non-nil error", err)
		}
	})

	t.Run("PrematureClose", func(t *testing.T) {
		tw := NewWriter(new(bytes.Buffer))
		hdr := &Header{Name: "small.txt", Size: 5}
		if err := tw.WriteHeader(hdr); err != nil {
			t.Fatalf("WriteHeader() = %v, want nil", err)
		}
		if err := tw.Close(); err == nil {
			t.Fatalf("Close() = %v, want non-nil error", err)
		}
	})

	t.Run("Persistence", func(t *testing.T) {
		tw := NewWriter(new(failOnceWriter))
		if err := tw.WriteHeader(&Header{}); err != io.ErrShortWrite {
			t.Fatalf("WriteHeader() = %v, want %v", err, io.ErrShortWrite)
		}
		if err := tw.WriteHeader(&Header{Name: "small.txt"}); err == nil {
			t.Errorf("WriteHeader() = got %v, want non-nil error", err)
		}
		if _, err := tw.Write(nil); err == nil {
			t.Errorf("Write() = %v, want non-nil error", err)
		}
		if err := tw.Flush(); err == nil {
			t.Errorf("Flush() = %v, want non-nil error", err)
		}
		if err := tw.Close(); err == nil {
			t.Errorf("Close() = %v, want non-nil error", err)
		}
	})
}

func TestSplitUSTARPath(t *testing.T) {
	sr := strings.Repeat

	vectors := []struct {
		input  string // Input path
		prefix string // Expected output prefix
		suffix string // Expected output suffix
		ok     bool   // Split success?
	}{
		{"", "", "", false},
		{"abc", "", "", false},
		{"用戶名", "", "", false},
		{sr("a", nameSize), "", "", false},
		{sr("a", nameSize) + "/", "", "", false},
		{sr("a", nameSize) + "/a", sr("a", nameSize), "a", true},
		{sr("a", prefixSize) + "/", "", "", false},
		{sr("a", prefixSize) + "/a", sr("a", prefixSize), "a", true},
		{sr("a", nameSize+1), "", "", false},
		{sr("/", nameSize+1), sr("/", nameSize-1), "/", true},
		{sr("a", prefixSize) + "/" + sr("b", nameSize),
			sr("a", prefixSize), sr("b", nameSize), true},
		{sr("a", prefixSize) + "//" + sr("b", nameSize), "", "", false},
		{sr("a/", nameSize), sr("a/", 77) + "a", sr("a/", 22), true},
	}

	for _, v := range vectors {
		prefix, suffix, ok := splitUSTARPath(v.input)
		if prefix != v.prefix || suffix != v.suffix || ok != v.ok {
			t.Errorf("splitUSTARPath(%q):\ngot  (%q, %q, %v)\nwant (%q, %q, %v)",
				v.input, prefix, suffix, ok, v.prefix, v.suffix, v.ok)
		}
	}
}

// TestIssue12594 tests that the Writer does not attempt to populate the prefix
// field when encoding a header in the GNU format. The prefix field is valid
// in USTAR and PAX, but not GNU.
func TestIssue12594(t *testing.T) {
	names := []string{
		"0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/20/21/22/23/24/25/26/27/28/29/30/file.txt",
		"0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/20/21/22/23/24/25/26/27/28/29/30/31/32/33/file.txt",
		"0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/20/21/22/23/24/25/26/27/28/29/30/31/32/333/file.txt",
		"0/1/2/3/4/5/6/7/8/9/10/11/12/13/14/15/16/17/18/19/20/21/22/23/24/25/26/27/28/29/30/31/32/33/34/35/36/37/38/39/40/file.txt",
		"0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000/file.txt",
		"/home/support/.openoffice.org/3/user/uno_packages/cache/registry/com.sun.star.comp.deployment.executable.PackageRegistryBackend",
	}

	for i, name := range names {
		var b bytes.Buffer

		tw := NewWriter(&b)
		if err := tw.WriteHeader(&Header{
			Name: name,
			Uid:  1 << 25, // Prevent USTAR format
		}); err != nil {
			t.Errorf("test %d, unexpected WriteHeader error: %v", i, err)
		}
		if err := tw.Close(); err != nil {
			t.Errorf("test %d, unexpected Close error: %v", i, err)
		}

		// The prefix field should never appear in the GNU format.
		var blk block
		copy(blk[:], b.Bytes())
		prefix := string(blk.toUSTAR().prefix())
		prefix, _, _ = strings.Cut(prefix, "\x00") // Truncate at the NUL terminator
		if blk.getFormat() == FormatGNU && len(prefix) > 0 && strings.HasPrefix(name, prefix) {
			t.Errorf("test %d, found prefix in GNU format: %s", i, prefix)
		}

		tr := NewReader(&b)
		hdr, err := tr.Next()
		if err != nil && err != ErrInsecurePath {
			t.Errorf("test %d, unexpected Next error: %v", i, err)
		}
		if hdr.Name != name {
			t.Errorf("test %d, hdr.Name = %s, want %s", i, hdr.Name, name)
		}
	}
}

func TestWriteLongHeader(t *testing.T) {
	for _, test := range []struct {
		name string
		h    *Header
	}{{
		name: "name too long",
		h:    &Header{Name: strings.Repeat("a", maxSpecialFileSize)},
	}, {
		name: "linkname too long",
		h:    &Header{Linkname: strings.Repeat("a", maxSpecialFileSize)},
	}, {
		name: "uname too long",
		h:    &Header{Uname: strings.Repeat("a", maxSpecialFileSize)},
	}, {
		name: "gname too long",
		h:    &Header{Gname: strings.Repeat("a", maxSpecialFileSize)},
	}, {
		name: "PAX header too long",
		h:    &Header{PAXRecords: map[string]string{"GOLANG.x": strings.Repeat("a", maxSpecialFileSize)}},
	}} {
		w := NewWriter(io.Discard)
		if err := w.WriteHeader(test.h); err != ErrFieldTooLong {
			t.Errorf("%v: w.WriteHeader() = %v, want ErrFieldTooLong", test.name, err)
		}
	}
}

// testNonEmptyWriter wraps an io.Writer and ensures that
// Write is never called with an empty buffer.
type testNonEmptyWriter struct{ io.Writer }

func (w testNonEmptyWriter) Write(b []byte) (int, error) {
	if len(b) == 0 {
		return 0, errors.New("unexpected empty Write call")
	}
	return w.Writer.Write(b)
}

func TestFileWriter(t *testing.T) {
	type (
		testWrite struct { // Write(str) == (wantCnt, wantErr)
			str     string
			wantCnt int
			wantErr error
		}
		testReadFrom struct { // ReadFrom(testFile{ops}) == (wantCnt, wantErr)
			ops     fileOps
			wantCnt int64
			wantErr error
		}
		testRemaining struct { // logicalRemaining() == wantLCnt, physicalRemaining() == wantPCnt
			wantLCnt int64
			wantPCnt int64
		}
		testFnc any // testWrite | testReadFrom | testRemaining
	)

	type (
		makeReg struct {
			size    int64
			wantStr string
		}
		makeSparse struct {
			makeReg makeReg
			sph     sparseHoles
			size    int64
		}
		fileMaker any // makeReg | makeSparse
	)

	vectors := []struct {
		maker fileMaker
		tests []testFnc
	}{{
		maker: makeReg{0, ""},
		tests: []testFnc{
			testRemaining{0, 0},
			testWrite{"", 0, nil},
			testWrite{"a", 0, ErrWriteTooLong},
			testReadFrom{fileOps{""}, 0, nil},
			testReadFrom{fileOps{"a"}, 0, ErrWriteTooLong},
			testRemaining{0, 0},
		},
	}, {
		maker: makeReg{1, "a"},
		tests: []testFnc{
			testRemaining{1, 1},
			testWrite{"", 0, nil},
			testWrite{"a", 1, nil},
			testWrite{"bcde", 0, ErrWriteTooLong},
			testWrite{"", 0, nil},
			testReadFrom{fileOps{""}, 0, nil},
			testReadFrom{fileOps{"a"}, 0, ErrWriteTooLong},
			testRemaining{0, 0},
		},
	}, {
		maker: makeReg{5, "hello"},
		tests: []testFnc{
			testRemaining{5, 5},
			testWrite{"hello", 5, nil},
			testRemaining{0, 0},
		},
	}, {
		maker: makeReg{5, "\x00\x00\x00\x00\x00"},
		tests: []testFnc{
			testRemaining{5, 5},
			testReadFrom{fileOps{"\x00\x00\x00\x00\x00"}, 5, nil},
			testRemaining{0, 0},
		},
	}, {
		maker: makeReg{5, "\x00\x00\x00\x00\x00"},
		tests: []testFnc{
			testRemaining{5, 5},
			testReadFrom{fileOps{"\x00\x00\x00\x00\x00extra"}, 5, ErrWriteTooLong},
			testRemaining{0, 0},
		},
	}, {
		maker: makeReg{5, "abc\x00\x00"},
		tests: []testFnc{
			testRemaining{5, 5},
			testWrite{"abc", 3, nil},
			testRemaining{2, 2},
			testReadFrom{fileOps{"\x00\x00"}, 2, nil},
			testRemaining{0, 0},
		},
	}, {
		maker: makeReg{5, "\x00\x00abc"},
		tests: []testFnc{
			testRemaining{5, 5},
			testWrite{"\x00\x00", 2, nil},
			testRemaining{3, 3},
			testWrite{"abc", 3, nil},
			testReadFrom{fileOps{"z"}, 0, ErrWriteTooLong},
			testWrite{"z", 0, ErrWriteTooLong},
			testRemaining{0, 0},
		},
	}, {
		maker: makeSparse{makeReg{5, "abcde"}, sparseHoles{{2, 3}}, 8},
		tests: []testFnc{
			testRemaining{8, 5},
			testWrite{"ab\x00\x00\x00cde", 8, nil},
			testWrite{"a", 0, ErrWriteTooLong},
			testRemaining{0, 0},
		},
	}, {
		maker: makeSparse{makeReg{5, "abcde"}, sparseHoles{{2, 3}}, 8},
		tests: []testFnc{
			testWrite{"ab\x00\x00\x00cdez", 8, ErrWriteTooLong},
			testRemaining{0, 0},
		},
	}, {
		maker: makeSparse{makeReg{5, "abcde"}, sparseHoles{{2, 3}
"""




```