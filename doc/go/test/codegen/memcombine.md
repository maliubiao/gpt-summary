Response: Let's break down the thought process for analyzing the provided Go code.

1. **Understanding the Request:** The core request is to understand the functionality of the `memcombine.go` file, identify what Go feature it exemplifies, provide a code example, explain the code logic, discuss command-line arguments (if any), and highlight potential pitfalls.

2. **Initial Scan and Keywords:**  A quick scan reveals repetitive function names like `load_le`, `load_be`, `store_le`, `store_be`, followed by sizes (64, 32, 16), and variations with `_idx`, `_idx2`, `_inv`. The `binary` package is imported, strongly suggesting byte order manipulation. The `// asmcheck` comment at the beginning is a clue that this code is likely used for testing assembly code generation.

3. **Deduction of Core Functionality:** The naming convention strongly suggests that the code is about loading and storing multi-byte values from byte arrays, considering both little-endian and big-endian byte orders. The `_idx` variants likely indicate reading/writing at a specific index within the byte array. The `_inv` variants might represent the reverse byte order within a specific size (although this turns out not to be the primary purpose of the `_inv` functions, they primarily serve as another pattern for `memcombine` to recognize).

4. **Identifying the Go Feature:** Based on the byte order manipulation, the most relevant Go feature is **handling binary data and endianness**. The `encoding/binary` package is the key player here.

5. **Crafting a Go Example:**  A simple example demonstrating loading and storing both little-endian and big-endian values using functions from the provided code is crucial. This will solidify the understanding of the code's purpose. The example should be concise and illustrative.

6. **Analyzing Code Logic:**  The code consists of numerous functions with similar structures. Each function:
    * Takes a byte slice (and optionally an index) as input.
    * Uses `binary.LittleEndian` or `binary.BigEndian` to interpret the bytes.
    * Returns a numerical value (uint64, uint32, or uint16).
    * Contains `// asmcheck` comments with regular expressions.

7. **The Significance of `// asmcheck` Comments:** These comments are not standard Go comments. They are directives for a testing tool. The regular expressions within these comments describe the expected assembly instructions that should be generated by the Go compiler for that specific function and architecture. This is the core of *why* this code exists – it's for compiler testing and verification, specifically related to how the compiler optimizes memory access. The `-` prefix in the regex likely indicates instructions that should *not* be present.

8. **Explaining Code Logic with Assumptions:** To explain the code logic, we need to make assumptions about the input. A concrete example of a byte slice and the expected output for one `load_le` and one `load_be` function would be helpful.

9. **Command-Line Arguments:** A review of the code reveals no direct interaction with `os.Args` or any command-line flag parsing libraries. Therefore, the conclusion is that this code doesn't process command-line arguments.

10. **Identifying Potential Pitfalls:**  The main pitfall for *users* of a general-purpose binary reading/writing library (not necessarily these specific test functions) is **incorrectly handling endianness**. This is a common source of bugs when dealing with binary data from different systems or file formats. Provide a concrete example of how reading little-endian data as big-endian (or vice versa) leads to incorrect results.

11. **Refining the Explanation:**  After drafting the initial explanation, review it for clarity, accuracy, and completeness. Ensure that the connections between the code, the `encoding/binary` package, and the `// asmcheck` comments are clear. Emphasize that this code is primarily for *compiler testing*, not direct use in typical applications.

12. **Self-Correction/Refinement during the Process:**
    * Initially, I might have focused too much on the `_inv` functions, assuming they were for reversing byte order. However, the `asmcheck` patterns don't particularly emphasize reversal. Realizing they serve as another pattern for the `memcombine` optimization to identify is a refinement.
    *  The crucial insight is understanding the role of the `// asmcheck` comments. This shifts the focus from just being about binary data manipulation to being about *compiler optimization verification*.
    * It's important to differentiate between the *purpose* of this specific test code and the general concepts of binary data and endianness. The pitfalls are relevant to the general concepts, not necessarily to using these specific test functions.

By following these steps, we can arrive at a comprehensive and accurate explanation of the provided Go code.
The Go code snippet you provided is part of the Go standard library's testing infrastructure, specifically for testing the **memory combining optimization** performed by the Go compiler. The file `go/test/codegen/memcombine.go` suggests it's located within the code generation testing suite.

**Functionality Summary:**

The code defines a series of functions designed to load and store integer values of different sizes (16, 32, and 64 bits) from and to byte slices. These functions explicitly handle both **little-endian** (`le`) and **big-endian** (`be`) byte orders. The variations in function names (e.g., `load_le64`, `load_le64_idx`, `load_be64`) indicate different ways of accessing the byte slice:

* **`load_le<size>`/`load_be<size>`:** Loads a `<size>`-bit unsigned integer from the beginning of the byte slice.
* **`load_le<size>_idx`/`load_be<size>_idx`:** Loads a `<size>`-bit unsigned integer from the byte slice starting at a specific index.
* **`load_le_byte<N>_uint<M>`/`load_be_byte<N>_uint<M>`:**  Loads `<M>`-bit unsigned integers by combining `<N>` individual bytes, explicitly defining the byte order.
* **Similar patterns exist for `store` functions.**

**Purpose and Go Feature Implementation:**

This code is **not** an implementation of a general-purpose binary data handling library. Instead, it serves as a **test case generator** for the Go compiler's "memcombine" pass. The `// asmcheck` comments are crucial here. They contain regular expressions that the test infrastructure uses to verify that the compiler generates specific assembly instructions for these functions.

The "memcombine" optimization aims to combine multiple small memory accesses (loads and stores of individual bytes) into fewer, larger memory accesses (e.g., loading a 32-bit word instead of four individual bytes). This can significantly improve performance.

**Go Code Example:**

```go
package main

import (
	"fmt"
	"go/test/codegen" // Note: This import is for demonstration and won't work outside the Go source tree.
)

func main() {
	data := []byte{0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08}

	// Load a little-endian 64-bit integer
	le64 := codegen.Load_le64(data)
	fmt.Printf("Little-Endian 64-bit: 0x%X\n", le64) // Output: 0x0807060504030201

	// Load a big-endian 32-bit integer from index 2
	be32 := codegen.Load_be32_idx(data, 2)
	fmt.Printf("Big-Endian 32-bit from index 2: 0x%X\n", be32) // Output: 0x03040506

	// Create a new byte slice
	storeData := make([]byte, 8)

	// Store a little-endian 32-bit integer
	codegen.Store_le32(storeData, 0xABCDEF01)
	fmt.Printf("After storing LE 32-bit: %X\n", storeData) // Output: [01 ef cd ab 00 00 00 00]

	// Store a big-endian 16-bit integer at index 4
	codegen.Store_be16_idx(storeData, 0x1234, 4)
	fmt.Printf("After storing BE 16-bit at index 4: %X\n", storeData) // Output: [01 ef cd ab 12 34 00 00]
}
```

**Code Logic with Assumptions:**

Let's take the `load_le32` function as an example:

```go
func load_le32(b []byte) uint32 {
	// amd64:`MOVL\s\(.*\),`,-`MOV[BW]`,-`OR`
	// 386:`MOVL\s\(.*\),`,-`MOV[BW]`,-`OR`
	// s390x:`MOVWBR\s\(.*\),`
	// arm64:`MOVWU\s\(R[0-9]+\),`,-`MOV[BH]`
	// loong64:`MOVBU\s\(R[0-9]+\),`
	// ppc64le:`MOVWZ\s`,-`MOV[BH]Z\s`
	// ppc64:`MOVWBR\s`,-`MOV[BH]Z\s`
	return binary.LittleEndian.Uint32(b)
}
```

**Assumptions:**

* **Input:** `b` is a byte slice with at least 4 bytes.
* **Output:** A `uint32` value.

**Logic:**

1. The function takes a byte slice `b` as input.
2. It uses `binary.LittleEndian.Uint32(b)` to interpret the first 4 bytes of the slice `b` as a little-endian unsigned 32-bit integer.
3. It returns the resulting `uint32` value.

**`// asmcheck` Comments:**

The `// asmcheck` lines are architecture-specific directives for the testing tool. For example, `amd64:` indicates a check for the AMD64 architecture. The regular expression `MOVQ\s\(.*\),` expects to find a `MOVQ` (move quadword - 64 bits) instruction loading from memory. The `-` prefix indicates instructions that should *not* be present. So, for `load_le64` on AMD64, the test expects a single `MOVQ` instruction and no individual byte or word moves (`MOV[BWL]`) or bitwise OR operations (`OR`), signifying that the compiler has successfully combined the byte loads.

**Command-Line Argument Processing:**

This specific code snippet does **not** process any command-line arguments. It's a collection of functions designed for internal testing. The broader `go test` command, when used on the `go/test/codegen` directory, will handle test execution, but this individual file doesn't parse command-line input.

**Potential User Errors:**

Since this code is primarily for compiler testing and not intended for direct use in application code, the "users" are the Go compiler developers and contributors. Potential errors they might encounter or test for include:

1. **Incorrect Assembly Generation:** The compiler might fail to combine memory accesses when it should, resulting in the generation of individual byte or word load/store instructions instead of larger ones. The `// asmcheck` directives help catch these regressions.
2. **Incorrect Byte Order Handling:** The compiler might generate incorrect assembly for little-endian or big-endian loads and stores, leading to incorrect values being read or written.
3. **Boundary Conditions:**  The compiler needs to handle cases where the requested data spans across memory boundaries or when the input slice is shorter than expected. The various `_idx` functions and explicit byte manipulation functions help test these scenarios.
4. **Optimization Interference:** Other compiler optimizations might interfere with the memcombine pass, preventing it from working correctly. These tests help identify such interactions.

**Example of a Potential Compiler Error (and what the tests catch):**

Imagine a scenario where the compiler, for some reason, doesn't combine the byte loads in `load_le32` on AMD64. The generated assembly might look like this:

```assembly
MOVBL  0(AX), DI
MOVBL  1(AX), SI
SHLL   $8, SI
ORL    DI, SI
MOVBL  2(AX), DI
SHLL   $16, DI
ORL    SI, DI
MOVBL  3(AX), SI
SHLL   $24, SI
ORL    DI, SI
MOV    SI, CX
```

This assembly performs four separate byte loads and then combines them using shifts and OR operations. The `// asmcheck` comment in `load_le32` would fail because it expects a single `MOVL` instruction and prohibits `MOV[BW]` and `OR`. This failure would alert the developers to a regression in the memcombine optimization.

In summary, this Go code is a crucial part of the Go compiler's testing infrastructure, specifically focused on verifying the correctness and effectiveness of the memory combining optimization. It uses `// asmcheck` directives to ensure that the compiler generates the expected efficient assembly code for various load and store operations with different byte orders and access patterns.

### 提示词
```
这是路径为go/test/codegen/memcombine.go的go语言实现的一部分， 请归纳一下它的功能, 　
如果你能推理出它是什么go语言功能的实现，请用go代码举例说明, 
如果介绍代码逻辑，则建议带上假设的输入与输出，
如果涉及命令行参数的具体处理，请详细介绍一下，
如果有哪些使用者易犯错的点，请举例说明，没有则不必说明，
```

### 源代码
```
// asmcheck

// Copyright 2018 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package codegen

import (
	"encoding/binary"
	"runtime"
)

// ------------- //
//    Loading    //
// ------------- //

func load_le64(b []byte) uint64 {
	// amd64:`MOVQ\s\(.*\),`,-`MOV[BWL]\t[^$]`,-`OR`
	// s390x:`MOVDBR\s\(.*\),`
	// arm64:`MOVD\s\(R[0-9]+\),`,-`MOV[BHW]`
	// loong64:`MOVBU\s\(R[0-9]+\),`
	// ppc64le:`MOVD\s`,-`MOV[BHW]Z`
	// ppc64:`MOVDBR\s`,-`MOV[BHW]Z`
	return binary.LittleEndian.Uint64(b)
}

func load_le64_idx(b []byte, idx int) uint64 {
	// amd64:`MOVQ\s\(.*\)\(.*\*1\),`,-`MOV[BWL]\t[^$]`,-`OR`
	// s390x:`MOVDBR\s\(.*\)\(.*\*1\),`
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+\),`,-`MOV[BHW]`
	// loong64:`MOVBU\s\(R[0-9]+\)\(R[0-9]+\),`
	// ppc64le:`MOVD\s`,-`MOV[BHW]Z\s`
	// ppc64:`MOVDBR\s`,-`MOV[BHW]Z\s`
	return binary.LittleEndian.Uint64(b[idx:])
}

func load_le32(b []byte) uint32 {
	// amd64:`MOVL\s\(.*\),`,-`MOV[BW]`,-`OR`
	// 386:`MOVL\s\(.*\),`,-`MOV[BW]`,-`OR`
	// s390x:`MOVWBR\s\(.*\),`
	// arm64:`MOVWU\s\(R[0-9]+\),`,-`MOV[BH]`
	// loong64:`MOVBU\s\(R[0-9]+\),`
	// ppc64le:`MOVWZ\s`,-`MOV[BH]Z\s`
	// ppc64:`MOVWBR\s`,-`MOV[BH]Z\s`
	return binary.LittleEndian.Uint32(b)
}

func load_le32_idx(b []byte, idx int) uint32 {
	// amd64:`MOVL\s\(.*\)\(.*\*1\),`,-`MOV[BW]`,-`OR`
	// 386:`MOVL\s\(.*\)\(.*\*1\),`,-`MOV[BW]`,-`OR`
	// s390x:`MOVWBR\s\(.*\)\(.*\*1\),`
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+\),`,-`MOV[BH]`
	// loong64:`MOVBU\s\(R[0-9]+\)\(R[0-9]+\),`
	// ppc64le:`MOVWZ\s`,-`MOV[BH]Z\s`
	// ppc64:`MOVWBR\s`,-`MOV[BH]Z\s'
	return binary.LittleEndian.Uint32(b[idx:])
}

func load_le16(b []byte) uint16 {
	// amd64:`MOVWLZX\s\(.*\),`,-`MOVB`,-`OR`
	// ppc64le:`MOVHZ\s`,-`MOVBZ`
	// arm64:`MOVHU\s\(R[0-9]+\),`,-`MOVB`
	// loong64:`MOVBU\s\(R[0-9]+\),`
	// s390x:`MOVHBR\s\(.*\),`
	// ppc64:`MOVHBR\s`,-`MOVBZ`
	return binary.LittleEndian.Uint16(b)
}

func load_le16_idx(b []byte, idx int) uint16 {
	// amd64:`MOVWLZX\s\(.*\),`,-`MOVB`,-`OR`
	// ppc64le:`MOVHZ\s`,-`MOVBZ`
	// ppc64:`MOVHBR\s`,-`MOVBZ`
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+\),`,-`MOVB`
	// loong64:`MOVBU\s\(R[0-9]+\)\(R[0-9]+\),`
	// s390x:`MOVHBR\s\(.*\)\(.*\*1\),`
	return binary.LittleEndian.Uint16(b[idx:])
}

func load_be64(b []byte) uint64 {
	// amd64/v1,amd64/v2:`BSWAPQ`,-`MOV[BWL]\t[^$]`,-`OR`
	// amd64/v3:`MOVBEQ`
	// s390x:`MOVD\s\(.*\),`
	// arm64:`REV`,`MOVD\s\(R[0-9]+\),`,-`MOV[BHW]`,-`REVW`,-`REV16W`
	// ppc64le:`MOVDBR`,-`MOV[BHW]Z`
	// ppc64:`MOVD`,-`MOV[BHW]Z`
	return binary.BigEndian.Uint64(b)
}

func load_be64_idx(b []byte, idx int) uint64 {
	// amd64/v1,amd64/v2:`BSWAPQ`,-`MOV[BWL]\t[^$]`,-`OR`
	// amd64/v3: `MOVBEQ\t\([A-Z]+[0-9]*\)\([A-Z]+[0-9]*\*1\), [A-Z]+[0-9]*`
	// s390x:`MOVD\s\(.*\)\(.*\*1\),`
	// arm64:`REV`,`MOVD\s\(R[0-9]+\)\(R[0-9]+\),`,-`MOV[WHB]`,-`REVW`,-`REV16W`
	// ppc64le:`MOVDBR`,-`MOV[BHW]Z`
	// ppc64:`MOVD`,-`MOV[BHW]Z`
	return binary.BigEndian.Uint64(b[idx:])
}

func load_be32(b []byte) uint32 {
	// amd64/v1,amd64/v2:`BSWAPL`,-`MOV[BW]`,-`OR`
	// amd64/v3: `MOVBEL`
	// s390x:`MOVWZ\s\(.*\),`
	// arm64:`REVW`,`MOVWU\s\(R[0-9]+\),`,-`MOV[BH]`,-`REV16W`
	// ppc64le:`MOVWBR`,-`MOV[BH]Z`
	// ppc64:`MOVWZ`,-MOV[BH]Z`
	return binary.BigEndian.Uint32(b)
}

func load_be32_idx(b []byte, idx int) uint32 {
	// amd64/v1,amd64/v2:`BSWAPL`,-`MOV[BW]`,-`OR`
	// amd64/v3: `MOVBEL\t\([A-Z]+[0-9]*\)\([A-Z]+[0-9]*\*1\), [A-Z]+[0-9]*`
	// s390x:`MOVWZ\s\(.*\)\(.*\*1\),`
	// arm64:`REVW`,`MOVWU\s\(R[0-9]+\)\(R[0-9]+\),`,-`MOV[HB]`,-`REV16W`
	// ppc64le:`MOVWBR`,-`MOV[BH]Z`
	// ppc64:`MOVWZ`,-MOV[BH]Z`
	return binary.BigEndian.Uint32(b[idx:])
}

func load_be16(b []byte) uint16 {
	// amd64:`ROLW\s\$8`,-`MOVB`,-`OR`
	// arm64:`REV16W`,`MOVHU\s\(R[0-9]+\),`,-`MOVB`
	// ppc64le:`MOVHBR`,-`MOVBZ`
	// ppc64:`MOVHZ`,-`MOVBZ`
	// s390x:`MOVHZ\s\(.*\),`,-`OR`,-`ORW`,-`SLD`,-`SLW`
	return binary.BigEndian.Uint16(b)
}

func load_be16_idx(b []byte, idx int) uint16 {
	// amd64:`ROLW\s\$8`,-`MOVB`,-`OR`
	// arm64:`REV16W`,`MOVHU\s\(R[0-9]+\)\(R[0-9]+\),`,-`MOVB`
	// ppc64le:`MOVHBR`,-`MOVBZ`
	// ppc64:`MOVHZ`,-`MOVBZ`
	// s390x:`MOVHZ\s\(.*\)\(.*\*1\),`,-`OR`,-`ORW`,-`SLD`,-`SLW`
	return binary.BigEndian.Uint16(b[idx:])
}

func load_le_byte2_uint16(s []byte) uint16 {
	// arm64:`MOVHU\t\(R[0-9]+\)`,-`ORR`,-`MOVB`
	// 386:`MOVWLZX\s\([A-Z]+\)`,-`MOVB`,-`OR`
	// amd64:`MOVWLZX\s\([A-Z]+\)`,-`MOVB`,-`OR`
	// ppc64le:`MOVHZ\t\(R[0-9]+\)`,-`MOVBZ`
	// ppc64:`MOVHBR`,-`MOVBZ`
	return uint16(s[0]) | uint16(s[1])<<8
}

func load_le_byte2_uint16_inv(s []byte) uint16 {
	// arm64:`MOVHU\t\(R[0-9]+\)`,-`ORR`,-`MOVB`
	// 386:`MOVWLZX\s\([A-Z]+\)`,-`MOVB`,-`OR`
	// amd64:`MOVWLZX\s\([A-Z]+\)`,-`MOVB`,-`OR`
	// ppc64le:`MOVHZ\t\(R[0-9]+\)`,-`MOVBZ`
	// ppc64:`MOVHBR`,-`MOVBZ`
	return uint16(s[1])<<8 | uint16(s[0])
}

func load_le_byte4_uint32(s []byte) uint32 {
	// arm64:`MOVWU\t\(R[0-9]+\)`,-`ORR`,-`MOV[BH]`
	// 386:`MOVL\s\([A-Z]+\)`,-`MOV[BW]`,-`OR`
	// amd64:`MOVL\s\([A-Z]+\)`,-`MOV[BW]`,-`OR`
	// ppc64le:`MOVWZ\t\(R[0-9]+\)`,-`MOV[BH]Z`
	// ppc64:`MOVWBR`,-MOV[BH]Z`
	return uint32(s[0]) | uint32(s[1])<<8 | uint32(s[2])<<16 | uint32(s[3])<<24
}

func load_le_byte4_uint32_inv(s []byte) uint32 {
	// arm64:`MOVWU\t\(R[0-9]+\)`,-`ORR`,-`MOV[BH]`
	// ppc64le:`MOVWZ`,-`MOV[BH]Z`
	// ppc64:`MOVWBR`,-`MOV[BH]Z`
	return uint32(s[3])<<24 | uint32(s[2])<<16 | uint32(s[1])<<8 | uint32(s[0])
}

func load_le_byte8_uint64(s []byte) uint64 {
	// arm64:`MOVD\t\(R[0-9]+\)`,-`ORR`,-`MOV[BHW]`
	// amd64:`MOVQ\s\([A-Z]+\),\s[A-Z]+`,-`MOV[BWL]\t[^$]`,-`OR`
	// ppc64le:`MOVD\t\(R[0-9]+\)`,-`MOV[BHW]Z`
	// ppc64:`MOVDBR`,-`MOVW[WHB]Z`
	return uint64(s[0]) | uint64(s[1])<<8 | uint64(s[2])<<16 | uint64(s[3])<<24 | uint64(s[4])<<32 | uint64(s[5])<<40 | uint64(s[6])<<48 | uint64(s[7])<<56
}

func load_le_byte8_uint64_inv(s []byte) uint64 {
	// arm64:`MOVD\t\(R[0-9]+\)`,-`ORR`,-`MOV[BHW]`
	// ppc64le:`MOVD`,-`MOV[WHB]Z`
	// ppc64:`MOVDBR`,-`MOV[WHB]Z`
	return uint64(s[7])<<56 | uint64(s[6])<<48 | uint64(s[5])<<40 | uint64(s[4])<<32 | uint64(s[3])<<24 | uint64(s[2])<<16 | uint64(s[1])<<8 | uint64(s[0])
}

func load_be_byte2_uint16(s []byte) uint16 {
	// arm64:`MOVHU\t\(R[0-9]+\)`,`REV16W`,-`ORR`,-`MOVB`
	// amd64:`MOVWLZX\s\([A-Z]+\)`,`ROLW`,-`MOVB`,-`OR`
	// ppc64le:`MOVHBR\t\(R[0-9]+\)`,-`MOVBZ`
	// ppc64:`MOVHZ`,-`MOVBZ`
	return uint16(s[0])<<8 | uint16(s[1])
}

func load_be_byte2_uint16_inv(s []byte) uint16 {
	// arm64:`MOVHU\t\(R[0-9]+\)`,`REV16W`,-`ORR`,-`MOVB`
	// amd64:`MOVWLZX\s\([A-Z]+\)`,`ROLW`,-`MOVB`,-`OR`
	// ppc64le:`MOVHBR\t\(R[0-9]+\)`,-`MOVBZ`
	// ppc64:`MOVHZ`,-`MOVBZ`
	return uint16(s[1]) | uint16(s[0])<<8
}

func load_be_byte4_uint32(s []byte) uint32 {
	// arm64:`MOVWU\t\(R[0-9]+\)`,`REVW`,-`ORR`,-`REV16W`,-`MOV[BH]`
	// ppc64le:`MOVWBR`,-`MOV[HB]Z`
	// ppc64:`MOVWZ`,-`MOV[HB]Z`
	return uint32(s[0])<<24 | uint32(s[1])<<16 | uint32(s[2])<<8 | uint32(s[3])
}

func load_be_byte4_uint32_inv(s []byte) uint32 {
	// arm64:`MOVWU\t\(R[0-9]+\)`,`REVW`,-`ORR`,-`REV16W`,-`MOV[BH]`
	// amd64/v1,amd64/v2:`MOVL\s\([A-Z]+\)`,`BSWAPL`,-`MOV[BW]`,-`OR`
	// amd64/v3: `MOVBEL`
	// ppc64le:`MOVWBR`,-`MOV[HB]Z`
	// ppc64:`MOVWZ`,-`MOV[HB]Z`
	return uint32(s[3]) | uint32(s[2])<<8 | uint32(s[1])<<16 | uint32(s[0])<<24
}

func load_be_byte8_uint64(s []byte) uint64 {
	// arm64:`MOVD\t\(R[0-9]+\)`,`REV`,-`ORR`,-`REVW`,-`REV16W`,-`MOV[BHW]`
	// ppc64le:`MOVDBR\t\(R[0-9]+\)`,-`MOV[BHW]Z`
	// ppc64:`MOVD`,-`MOV[WHB]Z`
	return uint64(s[0])<<56 | uint64(s[1])<<48 | uint64(s[2])<<40 | uint64(s[3])<<32 | uint64(s[4])<<24 | uint64(s[5])<<16 | uint64(s[6])<<8 | uint64(s[7])
}

func load_be_byte8_uint64_inv(s []byte) uint64 {
	// arm64:`MOVD\t\(R[0-9]+\)`,`REV`,-`ORR`,-`REVW`,-`REV16W`,-`MOV[BHW]`
	// amd64/v1,amd64/v2:`MOVQ\s\([A-Z]+\),\s[A-Z]+`,`BSWAPQ`,-`MOV[BWL]\t[^$]`,-`OR`
	// amd64/v3: `MOVBEQ`
	// ppc64le:`MOVDBR\t\(R[0-9]+\)`,-`MOV[BHW]Z`
	// ppc64:`MOVD`,-`MOV[BHW]Z`
	return uint64(s[7]) | uint64(s[6])<<8 | uint64(s[5])<<16 | uint64(s[4])<<24 | uint64(s[3])<<32 | uint64(s[2])<<40 | uint64(s[1])<<48 | uint64(s[0])<<56
}

func load_le_byte2_uint16_idx(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+\)`,-`ORR`,-`MOVB`
	// 386:`MOVWLZX\s\([A-Z]+\)\([A-Z]+`,-`ORL`,-`MOVB`
	// amd64:`MOVWLZX\s\([A-Z]+\)\([A-Z]+`,-`MOVB`,-`OR`
	// ppc64le:`MOVHZ`,-`MOVBZ`
	// ppc64:`MOVHBR`,-`MOVBZ`
	return uint16(s[idx]) | uint16(s[idx+1])<<8
}

func load_le_byte2_uint16_idx_inv(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+\)`,-`ORR`,-`MOVB`
	// 386:`MOVWLZX\s\([A-Z]+\)\([A-Z]+`,-`ORL`,-`MOVB`
	// amd64:`MOVWLZX\s\([A-Z]+\)\([A-Z]+`,-`MOVB`,-`OR`
	// ppc64le:`MOVHZ`,-`MOVBZ`
	// ppc64:`MOVHBR`,-`MOVBZ`
	return uint16(s[idx+1])<<8 | uint16(s[idx])
}

func load_le_byte4_uint32_idx(s []byte, idx int) uint32 {
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+\)`,-`ORR`,-`MOV[BH]`
	// amd64:`MOVL\s\([A-Z]+\)\([A-Z]+`,-`MOV[BW]`,-`OR`
	return uint32(s[idx]) | uint32(s[idx+1])<<8 | uint32(s[idx+2])<<16 | uint32(s[idx+3])<<24
}

func load_le_byte4_uint32_idx_inv(s []byte, idx int) uint32 {
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+\)`,-`ORR`,-`MOV[BH]`
	return uint32(s[idx+3])<<24 | uint32(s[idx+2])<<16 | uint32(s[idx+1])<<8 | uint32(s[idx])
}

func load_le_byte8_uint64_idx(s []byte, idx int) uint64 {
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+\)`,-`ORR`,-`MOV[BHW]`
	// amd64:`MOVQ\s\([A-Z]+\)\([A-Z]+`,-`MOV[BWL]`,-`OR`
	return uint64(s[idx]) | uint64(s[idx+1])<<8 | uint64(s[idx+2])<<16 | uint64(s[idx+3])<<24 | uint64(s[idx+4])<<32 | uint64(s[idx+5])<<40 | uint64(s[idx+6])<<48 | uint64(s[idx+7])<<56
}

func load_le_byte8_uint64_idx_inv(s []byte, idx int) uint64 {
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+\)`,-`ORR`,-`MOV[BHW]`
	return uint64(s[idx+7])<<56 | uint64(s[idx+6])<<48 | uint64(s[idx+5])<<40 | uint64(s[idx+4])<<32 | uint64(s[idx+3])<<24 | uint64(s[idx+2])<<16 | uint64(s[idx+1])<<8 | uint64(s[idx])
}

func load_be_byte2_uint16_idx(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+\)`,`REV16W`,-`ORR`,-`MOVB`
	// amd64:`MOVWLZX\s\([A-Z]+\)\([A-Z]+`,-`MOVB`,-`OR`
	return uint16(s[idx])<<8 | uint16(s[idx+1])
}

func load_be_byte2_uint16_idx_inv(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+\)`,`REV16W`,-`ORR`,-`MOVB`
	// amd64:`MOVWLZX\s\([A-Z]+\)\([A-Z]+`,-`MOVB`,-`OR`
	return uint16(s[idx+1]) | uint16(s[idx])<<8
}

func load_be_byte4_uint32_idx(s []byte, idx int) uint32 {
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+\)`,`REVW`,-`ORR`,-`MOV[BH]`,-`REV16W`
	return uint32(s[idx])<<24 | uint32(s[idx+1])<<16 | uint32(s[idx+2])<<8 | uint32(s[idx+3])
}

func load_be_byte8_uint64_idx(s []byte, idx int) uint64 {
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+\)`,`REV`,-`ORR`,-`MOV[BHW]`,-`REVW`,-`REV16W`
	return uint64(s[idx])<<56 | uint64(s[idx+1])<<48 | uint64(s[idx+2])<<40 | uint64(s[idx+3])<<32 | uint64(s[idx+4])<<24 | uint64(s[idx+5])<<16 | uint64(s[idx+6])<<8 | uint64(s[idx+7])
}

func load_le_byte2_uint16_idx2(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+<<1\)`,-`ORR`,-`MOVB`
	return uint16(s[idx<<1]) | uint16(s[(idx<<1)+1])<<8
}

func load_le_byte2_uint16_idx2_inv(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+<<1\)`,-`ORR`,-`MOVB`
	return uint16(s[(idx<<1)+1])<<8 | uint16(s[idx<<1])
}

func load_le_byte4_uint32_idx4(s []byte, idx int) uint32 {
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+<<2\)`,-`ORR`,-`MOV[BH]`
	return uint32(s[idx<<2]) | uint32(s[(idx<<2)+1])<<8 | uint32(s[(idx<<2)+2])<<16 | uint32(s[(idx<<2)+3])<<24
}

func load_le_byte4_uint32_idx4_inv(s []byte, idx int) uint32 {
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+<<2\)`,-`ORR`,-`MOV[BH]`
	return uint32(s[(idx<<2)+3])<<24 | uint32(s[(idx<<2)+2])<<16 | uint32(s[(idx<<2)+1])<<8 | uint32(s[idx<<2])
}

func load_le_byte8_uint64_idx8(s []byte, idx int) uint64 {
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+<<3\)`,-`ORR`,-`MOV[BHW]`
	return uint64(s[idx<<3]) | uint64(s[(idx<<3)+1])<<8 | uint64(s[(idx<<3)+2])<<16 | uint64(s[(idx<<3)+3])<<24 | uint64(s[(idx<<3)+4])<<32 | uint64(s[(idx<<3)+5])<<40 | uint64(s[(idx<<3)+6])<<48 | uint64(s[(idx<<3)+7])<<56
}

func load_le_byte8_uint64_idx8_inv(s []byte, idx int) uint64 {
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+<<3\)`,-`ORR`,-`MOV[BHW]`
	return uint64(s[(idx<<3)+7])<<56 | uint64(s[(idx<<3)+6])<<48 | uint64(s[(idx<<3)+5])<<40 | uint64(s[(idx<<3)+4])<<32 | uint64(s[(idx<<3)+3])<<24 | uint64(s[(idx<<3)+2])<<16 | uint64(s[(idx<<3)+1])<<8 | uint64(s[idx<<3])
}

func load_be_byte2_uint16_idx2(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+<<1\)`,`REV16W`,-`ORR`,-`MOVB`
	return uint16(s[idx<<1])<<8 | uint16(s[(idx<<1)+1])
}

func load_be_byte2_uint16_idx2_inv(s []byte, idx int) uint16 {
	// arm64:`MOVHU\s\(R[0-9]+\)\(R[0-9]+<<1\)`,`REV16W`,-`ORR`,-`MOVB`
	return uint16(s[(idx<<1)+1]) | uint16(s[idx<<1])<<8
}

func load_be_byte4_uint32_idx4(s []byte, idx int) uint32 {
	// arm64:`MOVWU\s\(R[0-9]+\)\(R[0-9]+<<2\)`,`REVW`,-`ORR`,-`MOV[BH]`,-`REV16W`
	return uint32(s[idx<<2])<<24 | uint32(s[(idx<<2)+1])<<16 | uint32(s[(idx<<2)+2])<<8 | uint32(s[(idx<<2)+3])
}

func load_be_byte8_uint64_idx8(s []byte, idx int) uint64 {
	// arm64:`MOVD\s\(R[0-9]+\)\(R[0-9]+<<3\)`,`REV`,-`ORR`,-`MOV[BHW]`,-`REVW`,-`REV16W`
	return uint64(s[idx<<3])<<56 | uint64(s[(idx<<3)+1])<<48 | uint64(s[(idx<<3)+2])<<40 | uint64(s[(idx<<3)+3])<<32 | uint64(s[(idx<<3)+4])<<24 | uint64(s[(idx<<3)+5])<<16 | uint64(s[(idx<<3)+6])<<8 | uint64(s[(idx<<3)+7])
}

// Some tougher cases for the memcombine pass.

func reassoc_load_uint32(b []byte) uint32 {
	// amd64:`MOVL\s\([A-Z]+\)`,-`MOV[BW]`,-`OR`
	return (uint32(b[0]) | uint32(b[1])<<8) | (uint32(b[2])<<16 | uint32(b[3])<<24)
}

func extrashift_load_uint32(b []byte) uint32 {
	// amd64:`MOVL\s\([A-Z]+\)`,`SHLL\s[$]2`,-`MOV[BW]`,-`OR`
	return uint32(b[0])<<2 | uint32(b[1])<<10 | uint32(b[2])<<18 | uint32(b[3])<<26
}

func outoforder_load_uint32(b []byte) uint32 {
	// amd64:`MOVL\s\([A-Z]+\)`,-`MOV[BW]`,-`OR`
	return uint32(b[0]) | uint32(b[2])<<16 | uint32(b[1])<<8 | uint32(b[3])<<24
}

func extraOr_load_uint32(b []byte, x, y uint32) uint32 {
	// amd64:`ORL\s\([A-Z]+\)`,-`MOV[BW]`
	return x | binary.LittleEndian.Uint32(b) | y
	// TODO: Note that
	//   x | uint32(b[0]) | uint32(b[1])<<8 | uint32(b[2])<<16 | uint32(b[3])<<24 | y
	// doesn't work because it associates in a way that memcombine can't detect it.
}

// Check load combining across function calls.

func fcall_byte(a [2]byte) [2]byte {
	return fcall_byte(fcall_byte(a)) // amd64:`MOVW`
}

func fcall_uint16(a [2]uint16) [2]uint16 {
	return fcall_uint16(fcall_uint16(a)) // amd64:`MOVL`
}

func fcall_uint32(a [2]uint32) [2]uint32 {
	return fcall_uint32(fcall_uint32(a)) // amd64:`MOVQ`
}

// We want to merge load+op in the first function, but not in the
// second. See Issue 19595.
func load_op_merge(p, q *int) {
	x := *p // amd64:`ADDQ\t\(`
	*q += x // The combined nilcheck and load would normally have this line number, but we want that combined operation to have the line number of the nil check instead (see #33724).
}
func load_op_no_merge(p, q *int) {
	x := *p
	for i := 0; i < 10; i++ {
		*q += x // amd64:`ADDQ\t[A-Z]`
	}
}

// Make sure offsets are folded into loads and stores.
func offsets_fold(_, a [20]byte) (b [20]byte) {
	// arm64:`MOVD\tcommand-line-arguments\.a\+[0-9]+\(FP\), R[0-9]+`,`MOVD\tR[0-9]+, command-line-arguments\.b\+[0-9]+\(FP\)`
	b = a
	return
}

// Make sure we don't put pointers in SSE registers across safe
// points.

func safe_point(p, q *[2]*int) {
	a, b := p[0], p[1] // amd64:-`MOVUPS`
	runtime.GC()
	q[0], q[1] = a, b // amd64:-`MOVUPS`
}

// ------------- //
//    Storing    //
// ------------- //

func store_le64(b []byte, x uint64) {
	// amd64:`MOVQ\s.*\(.*\)$`,-`SHR.`
	// arm64:`MOVD`,-`MOV[WBH]`
	// ppc64le:`MOVD\s`,-`MOV[BHW]\s`
	// ppc64:`MOVDBR`,-MOVB\s`
	// s390x:`MOVDBR\s.*\(.*\)$`
	binary.LittleEndian.PutUint64(b, x)
}

func store_le64_idx(b []byte, x uint64, idx int) {
	// amd64:`MOVQ\s.*\(.*\)\(.*\*1\)$`,-`SHR.`
	// arm64:`MOVD\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOV[BHW]`
	// ppc64le:`MOVD\s`,-`MOV[BHW]\s`
	// ppc64:`MOVDBR`,-`MOVBZ`
	// s390x:`MOVDBR\s.*\(.*\)\(.*\*1\)$`
	binary.LittleEndian.PutUint64(b[idx:], x)
}

func store_le64_idx2(dst []byte, d, length, offset int) []byte {
	a := dst[d : d+length]
	b := dst[d-offset:]
	// amd64:`MOVQ\s.*\(.*\)\(.*\*1\)$`,-`SHR.`
	binary.LittleEndian.PutUint64(a, binary.LittleEndian.Uint64(b))
	return dst
}

func store_le64_idx_const(b []byte, idx int) {
	// amd64:`MOVQ\s\$123, \(.*\)\(.*\*1\)$`
	binary.LittleEndian.PutUint64(b[idx:], 123)
}

func store_le64_load(b []byte, x *[8]byte) {
	_ = b[8]
	// amd64:-`MOV[BWL]`
	// arm64:-`MOV[BWH]`
	// ppc64le:`MOVD\s`,-`MOV[BWH]Z`
	// ppc64:`MOVDBR`
	// s390x:-`MOVB`,-`MOV[WH]BR`
	binary.LittleEndian.PutUint64(b, binary.LittleEndian.Uint64(x[:]))
}

func store_le32(b []byte, x uint32) {
	// amd64:`MOVL\s`
	// arm64:`MOVW`,-`MOV[BH]`
	// ppc64le:`MOVW\s`
	// ppc64:`MOVWBR`
	// s390x:`MOVWBR\s.*\(.*\)$`
	binary.LittleEndian.PutUint32(b, x)
}

func store_le32_idx(b []byte, x uint32, idx int) {
	// amd64:`MOVL\s`
	// arm64:`MOVW\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOV[BH]`
	// ppc64le:`MOVW\s`
	// ppc64:`MOVWBR`
	// s390x:`MOVWBR\s.*\(.*\)\(.*\*1\)$`
	binary.LittleEndian.PutUint32(b[idx:], x)
}

func store_le32_idx_const(b []byte, idx int) {
	// amd64:`MOVL\s\$123, \(.*\)\(.*\*1\)$`
	// ppc64x:`MOVW\s`,-MOV[HB]`
	binary.LittleEndian.PutUint32(b[idx:], 123)
}

func store_le16(b []byte, x uint16) {
	// amd64:`MOVW\s`
	// arm64:`MOVH`,-`MOVB`
	// ppc64le:`MOVH\s`
	// ppc64:`MOVHBR`
	// s390x:`MOVHBR\s.*\(.*\)$`
	binary.LittleEndian.PutUint16(b, x)
}

func store_le16_idx(b []byte, x uint16, idx int) {
	// amd64:`MOVW\s`
	// arm64:`MOVH\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOVB`
	// ppc64le:`MOVH\s`
	// ppc64:`MOVHBR\s`
	// s390x:`MOVHBR\s.*\(.*\)\(.*\*1\)$`
	binary.LittleEndian.PutUint16(b[idx:], x)
}

func store_le16_idx_const(b []byte, idx int) {
	// amd64:`MOVW\s\$123, \(.*\)\(.*\*1\)$`
	// ppc64x:`MOVH\s`
	binary.LittleEndian.PutUint16(b[idx:], 123)
}

func store_be64(b []byte, x uint64) {
	// amd64/v1,amd64/v2:`BSWAPQ`,-`SHR.`
	// amd64/v3: `MOVBEQ`
	// arm64:`MOVD`,`REV`,-`MOV[WBH]`,-`REVW`,-`REV16W`
	// ppc64le:`MOVDBR`
	// ppc64:`MOVD\s`
	// s390x:`MOVD\s.*\(.*\)$`,-`SRW\s`,-`SRD\s`
	binary.BigEndian.PutUint64(b, x)
}

func store_be64_idx(b []byte, x uint64, idx int) {
	// amd64/v1,amd64/v2:`BSWAPQ`,-`SHR.`
	// amd64/v3:`MOVBEQ\t[A-Z]+[0-9]*, \([A-Z]+[0-9]*\)\([A-Z]+[0-9]*\*1\)`
	// arm64:`REV`,`MOVD\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOV[BHW]`,-`REV16W`,-`REVW`
	// ppc64le:`MOVDBR`
	// ppc64:`MOVD\s`
	// s390x:`MOVD\s.*\(.*\)\(.*\*1\)$`,-`SRW\s`,-`SRD\s`
	binary.BigEndian.PutUint64(b[idx:], x)
}

func store_be32(b []byte, x uint32) {
	// amd64/v1,amd64/v2:`BSWAPL`,-`SHR.`
	// amd64/v3:`MOVBEL`
	// arm64:`MOVW`,`REVW`,-`MOV[BH]`,-`REV16W`
	// ppc64le:`MOVWBR`
	// ppc64:`MOVW\s`
	// s390x:`MOVW\s.*\(.*\)$`,-`SRW\s`,-`SRD\s`
	binary.BigEndian.PutUint32(b, x)
}

func store_be64_load(b, x *[8]byte) {
	// arm64:-`REV`
	// amd64:-`BSWAPQ`
	binary.BigEndian.PutUint64(b[:], binary.BigEndian.Uint64(x[:]))
}

func store_be32_load(b, x *[8]byte) {
	// arm64:-`REVW`
	// amd64:-`BSWAPL`
	binary.BigEndian.PutUint32(b[:], binary.BigEndian.Uint32(x[:]))
}

func store_be32_idx(b []byte, x uint32, idx int) {
	// amd64/v1,amd64/v2:`BSWAPL`,-`SHR.`
	// amd64/v3:`MOVBEL\t[A-Z]+[0-9]*, \([A-Z]+[0-9]*\)\([A-Z]+[0-9]*\*1\)`
	// arm64:`REVW`,`MOVW\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOV[BH]`,-`REV16W`
	// ppc64le:`MOVWBR`
	// ppc64:`MOVW\s`
	// s390x:`MOVW\s.*\(.*\)\(.*\*1\)$`,-`SRW\s`,-`SRD\s`
	binary.BigEndian.PutUint32(b[idx:], x)
}

func store_be16(b []byte, x uint16) {
	// amd64/v1,amd64/v2:`ROLW\s\$8`,-`SHR.`
	// amd64/v3:`MOVBEW`,-`ROLW`
	// arm64:`MOVH`,`REV16W`,-`MOVB`
	// ppc64le:`MOVHBR`
	// ppc64:`MOVH\s`
	// s390x:`MOVH\s.*\(.*\)$`,-`SRW\s`,-`SRD\s`
	binary.BigEndian.PutUint16(b, x)
}

func store_be16_idx(b []byte, x uint16, idx int) {
	// amd64/v1,amd64/v2:`ROLW\s\$8`,-`SHR.`
	// amd64/v3:`MOVBEW\t[A-Z]+[0-9]*, \([A-Z]+[0-9]*\)\([A-Z]+[0-9]*\*1\)`
	// arm64:`MOVH\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,`REV16W`,-`MOVB`
	// ppc64le:`MOVHBR`
	// ppc64:`MOVH\s`
	// s390x:`MOVH\s.*\(.*\)\(.*\*1\)$`,-`SRW\s`,-`SRD\s`
	binary.BigEndian.PutUint16(b[idx:], x)
}

func store_le_byte_2(b []byte, val uint16) {
	_ = b[2]
	// arm64:`MOVH\sR[0-9]+,\s1\(R[0-9]+\)`,-`MOVB`
	// 386:`MOVW\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`
	// amd64:`MOVW\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`
	// ppc64le:`MOVH\s`,-`MOVB`
	// ppc64:`MOVHBR`,-`MOVB`
	b[1], b[2] = byte(val), byte(val>>8)
}

func store_le_byte_2_inv(b []byte, val uint16) {
	_ = b[2]
	// 386:`MOVW\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`
	// amd64:`MOVW\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`
	// ppc64le:`MOVH\s`,-`MOVB`
	// ppc64:`MOVHBR`,-`MOVB`
	b[2], b[1] = byte(val>>8), byte(val)
}

func store_le_byte_4(b []byte, val uint32) {
	_ = b[4]
	// arm64:`MOVW\sR[0-9]+,\s1\(R[0-9]+\)`,-`MOVB`,-`MOVH`
	// 386:`MOVL\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`,-`MOVW`
	// amd64:`MOVL\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`,-`MOVW`
	// ppc64le:`MOVW\s`
	// ppc64:`MOVWBR\s`
	b[1], b[2], b[3], b[4] = byte(val), byte(val>>8), byte(val>>16), byte(val>>24)
}

func store_le_byte_8(b []byte, val uint64) {
	_ = b[8]
	// arm64:`MOVD\sR[0-9]+,\s1\(R[0-9]+\)`,-`MOVB`,-`MOVH`,-`MOVW`
	// amd64:`MOVQ\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`,-`MOVW`,-`MOVL`
	// ppc64le:`MOVD\s`,-`MOVW`
	// ppc64:`MOVDBR\s`
	b[1], b[2], b[3], b[4], b[5], b[6], b[7], b[8] = byte(val), byte(val>>8), byte(val>>16), byte(val>>24), byte(val>>32), byte(val>>40), byte(val>>48), byte(val>>56)
}

func store_be_byte_2(b []byte, val uint16) {
	_ = b[2]
	// arm64:`REV16W`,`MOVH\sR[0-9]+,\s1\(R[0-9]+\)`,-`MOVB`
	// amd64/v1,amd64/v2:`MOVW\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`
	// amd64/v3: `MOVBEW`
	// ppc64le:`MOVHBR`
	// ppc64:`MOVH\s`
	b[1], b[2] = byte(val>>8), byte(val)
}

func store_be_byte_4(b []byte, val uint32) {
	_ = b[4]
	// arm64:`REVW`,`MOVW\sR[0-9]+,\s1\(R[0-9]+\)`,-`MOVB`,-`MOVH`,-`REV16W`
	// amd64/v1,amd64/v2:`MOVL\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`,-`MOVW`
	// amd64/v3:`MOVBEL\s[A-Z]+,\s1\([A-Z]+\)`
	// ppc64le:`MOVWBR`
	// ppc64:`MOVW\s`
	b[1], b[2], b[3], b[4] = byte(val>>24), byte(val>>16), byte(val>>8), byte(val)
}

func store_be_byte_8(b []byte, val uint64) {
	_ = b[8]
	// arm64:`REV`,`MOVD\sR[0-9]+,\s1\(R[0-9]+\)`,-`MOVB`,-`MOVH`,-`MOVW`,-`REV16W`,-`REVW`
	// amd64/v1,amd64/v2:`MOVQ\s[A-Z]+,\s1\([A-Z]+\)`,-`MOVB`,-`MOVW`,-`MOVL`
	// amd64/v3:`MOVBEQ\s[A-Z]+,\s1\([A-Z]+\)`, -`MOVBEL`
	// ppc64le:`MOVDBR`
	// ppc64:`MOVD`
	b[1], b[2], b[3], b[4], b[5], b[6], b[7], b[8] = byte(val>>56), byte(val>>48), byte(val>>40), byte(val>>32), byte(val>>24), byte(val>>16), byte(val>>8), byte(val)
}

func store_le_byte_2_idx(b []byte, idx int, val uint16) {
	_, _ = b[idx+0], b[idx+1]
	// arm64:`MOVH\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOVB`
	// 386:`MOVW\s[A-Z]+,\s\([A-Z]+\)\([A-Z]+`,-`MOVB`
	// ppc64le:`MOVH\s`
	// ppc64:`MOVHBR`
	b[idx+1], b[idx+0] = byte(val>>8), byte(val)
}

func store_le_byte_2_idx_inv(b []byte, idx int, val uint16) {
	_, _ = b[idx+0], b[idx+1]
	// 386:`MOVW\s[A-Z]+,\s\([A-Z]+\)\([A-Z]+`,-`MOVB`
	// ppc64le:`MOVH\s`
	// ppc64:`MOVHBR`
	b[idx+0], b[idx+1] = byte(val), byte(val>>8)
}

func store_le_byte_4_idx(b []byte, idx int, val uint32) {
	_, _, _, _ = b[idx+0], b[idx+1], b[idx+2], b[idx+3]
	// arm64:`MOVW\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOVB`,-`MOVH`
	// ppc64le:`MOVW\s`
	// ppc64:`MOVWBR`
	b[idx+3], b[idx+2], b[idx+1], b[idx+0] = byte(val>>24), byte(val>>16), byte(val>>8), byte(val)
}

func store_be_byte_2_idx(b []byte, idx int, val uint16) {
	_, _ = b[idx+0], b[idx+1]
	// arm64:`REV16W`,`MOVH\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOVB`
	// ppc64le:`MOVHBR`
	// ppc64:`MOVH\s`
	b[idx+0], b[idx+1] = byte(val>>8), byte(val)
}

func store_be_byte_4_idx(b []byte, idx int, val uint32) {
	_, _, _, _ = b[idx+0], b[idx+1], b[idx+2], b[idx+3]
	// arm64:`REVW`,`MOVW\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOVB`,-`MOVH`,-`REV16W`
	// ppc64le:`MOVWBR`
	// ppc64:`MOVW\s`
	b[idx+0], b[idx+1], b[idx+2], b[idx+3] = byte(val>>24), byte(val>>16), byte(val>>8), byte(val)
}

func store_be_byte_2_idx2(b []byte, idx int, val uint16) {
	_, _ = b[(idx<<1)+0], b[(idx<<1)+1]
	// arm64:`REV16W`,`MOVH\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+<<1\)`,-`MOVB`
	// ppc64le:`MOVHBR`
	// ppc64:`MOVH\s`
	b[(idx<<1)+0], b[(idx<<1)+1] = byte(val>>8), byte(val)
}

func store_le_byte_2_idx2(b []byte, idx int, val uint16) {
	_, _ = b[(idx<<1)+0], b[(idx<<1)+1]
	// arm64:`MOVH\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+<<1\)`,-`MOVB`
	// ppc64le:`MOVH\s`
	// ppc64:`MOVHBR`
	b[(idx<<1)+1], b[(idx<<1)+0] = byte(val>>8), byte(val)
}

func store_be_byte_4_idx4(b []byte, idx int, val uint32) {
	_, _, _, _ = b[(idx<<2)+0], b[(idx<<2)+1], b[(idx<<2)+2], b[(idx<<2)+3]
	// arm64:`REVW`,`MOVW\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+<<2\)`,-`MOVB`,-`MOVH`,-`REV16W`
	// ppc64le:`MOVWBR`
	// ppc64:`MOVW\s`
	b[(idx<<2)+0], b[(idx<<2)+1], b[(idx<<2)+2], b[(idx<<2)+3] = byte(val>>24), byte(val>>16), byte(val>>8), byte(val)
}

func store_le_byte_4_idx4_inv(b []byte, idx int, val uint32) {
	_, _, _, _ = b[(idx<<2)+0], b[(idx<<2)+1], b[(idx<<2)+2], b[(idx<<2)+3]
	// arm64:`MOVW\sR[0-9]+,\s\(R[0-9]+\)\(R[0-9]+<<2\)`,-`MOVB`,-`MOVH`
	// ppc64le:`MOVW\s`
	// ppc64:`MOVWBR`
	b[(idx<<2)+3], b[(idx<<2)+2], b[(idx<<2)+1], b[(idx<<2)+0] = byte(val>>24), byte(val>>16), byte(val>>8), byte(val)
}

// ------------- //
//    Zeroing    //
// ------------- //

// Check that zero stores are combined into larger stores

func zero_byte_2(b1, b2 []byte) {
	// bounds checks to guarantee safety of writes below
	_, _ = b1[1], b2[1]
	// arm64:"MOVH\tZR",-"MOVB"
	// amd64:`MOVW\s[$]0,\s\([A-Z]+\)`
	// 386:`MOVW\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVH\s`
	b1[0], b1[1] = 0, 0
	// arm64:"MOVH\tZR",-"MOVB"
	// 386:`MOVW\s[$]0,\s\([A-Z]+\)`
	// amd64:`MOVW\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVH`
	b2[1], b2[0] = 0, 0
}

func zero_byte_4(b1, b2 []byte) {
	_, _ = b1[3], b2[3]
	// arm64:"MOVW\tZR",-"MOVB",-"MOVH"
	// amd64:`MOVL\s[$]0,\s\([A-Z]+\)`
	// 386:`MOVL\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVW\s`
	b1[0], b1[1], b1[2], b1[3] = 0, 0, 0, 0
	// arm64:"MOVW\tZR",-"MOVB",-"MOVH"
	// ppc64x:`MOVW\s`
	b2[2], b2[3], b2[1], b2[0] = 0, 0, 0, 0
}

func zero_byte_8(b []byte) {
	_ = b[7]
	b[0], b[1], b[2], b[3] = 0, 0, 0, 0 // arm64:"MOVD\tZR",-"MOVB",-"MOVH",-"MOVW"
	b[4], b[5], b[6], b[7] = 0, 0, 0, 0
}

func zero_byte_16(b []byte) {
	_ = b[15]
	b[0], b[1], b[2], b[3] = 0, 0, 0, 0 // arm64:"STP",-"MOVB",-"MOVH",-"MOVW"
	b[4], b[5], b[6], b[7] = 0, 0, 0, 0
	b[8], b[9], b[10], b[11] = 0, 0, 0, 0
	b[12], b[13], b[14], b[15] = 0, 0, 0, 0
}

func zero_byte_30(a *[30]byte) {
	*a = [30]byte{} // arm64:"STP",-"MOVB",-"MOVH",-"MOVW"
}

func zero_byte_39(a *[39]byte) {
	*a = [39]byte{} // arm64:"MOVD",-"MOVB",-"MOVH",-"MOVW"
}

func zero_byte_2_idx(b []byte, idx int) {
	_, _ = b[idx+0], b[idx+1]
	// arm64:`MOVH\sZR,\s\(R[0-9]+\)\(R[0-9]+\)`,-`MOVB`
	// ppc64x:`MOVH\s`
	b[idx+0], b[idx+1] = 0, 0
}

func zero_byte_2_idx2(b []byte, idx int) {
	_, _ = b[(idx<<1)+0], b[(idx<<1)+1]
	// arm64:`MOVH\sZR,\s\(R[0-9]+\)\(R[0-9]+<<1\)`,-`MOVB`
	// ppc64x:`MOVH\s`
	b[(idx<<1)+0], b[(idx<<1)+1] = 0, 0
}

func zero_uint16_2(h1, h2 []uint16) {
	_, _ = h1[1], h2[1]
	// arm64:"MOVW\tZR",-"MOVB",-"MOVH"
	// amd64:`MOVL\s[$]0,\s\([A-Z]+\)`
	// 386:`MOVL\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVW\s`
	h1[0], h1[1] = 0, 0
	// arm64:"MOVW\tZR",-"MOVB",-"MOVH"
	// amd64:`MOVL\s[$]0,\s\([A-Z]+\)`
	// 386:`MOVL\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVW`
	h2[1], h2[0] = 0, 0
}

func zero_uint16_4(h1, h2 []uint16) {
	_, _ = h1[3], h2[3]
	// arm64:"MOVD\tZR",-"MOVB",-"MOVH",-"MOVW"
	// amd64:`MOVQ\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVD\s`
	h1[0], h1[1], h1[2], h1[3] = 0, 0, 0, 0
	// arm64:"MOVD\tZR",-"MOVB",-"MOVH",-"MOVW"
	// ppc64x:`MOVD\s`
	h2[2], h2[3], h2[1], h2[0] = 0, 0, 0, 0
}

func zero_uint16_8(h []uint16) {
	_ = h[7]
	h[0], h[1], h[2], h[3] = 0, 0, 0, 0 // arm64:"STP",-"MOVB",-"MOVH"
	h[4], h[5], h[6], h[7] = 0, 0, 0, 0
}

func zero_uint32_2(w1, w2 []uint32) {
	_, _ = w1[1], w2[1]
	// arm64:"MOVD\tZR",-"MOVB",-"MOVH",-"MOVW"
	// amd64:`MOVQ\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVD\s`
	w1[0], w1[1] = 0, 0
	// arm64:"MOVD\tZR",-"MOVB",-"MOVH",-"MOVW"
	// amd64:`MOVQ\s[$]0,\s\([A-Z]+\)`
	// ppc64x:`MOVD\s`
	w2[1], w2[0] = 0, 0
}

func zero_uint32_4(w1, w2 []uint32) {
	_, _ = w1[3], w2[3]
	w1[0], w1[1], w1[2], w1[3] = 0, 0, 0, 0 // arm64:"STP",-"MOVB",-"MOVH"
	w2[2], w2[3], w2[1], w2[0] = 0, 0, 0, 0 // arm64:"STP",-"MOVB",-"MOVH"
}

func zero_uint64_2(d1, d2 []uint64) {
	_, _ = d1[1], d2[1]
	d1[0], d1[1] = 0, 0 // arm64:"STP",-"MOVB",-"MOVH"
	d2[1], d2[0] = 0, 0 // arm64:"STP",-"MOVB",-"MOVH"
}

func loadstore(p, q *[4]uint8) {
	// amd64:"MOVL",-"MOVB"
	// arm64:"MOVWU",-"MOVBU"
	x0, x1, x2, x3 := q[0], q[1], q[2], q[3]
	// amd64:"MOVL",-"MOVB"
	// arm64:"MOVW",-"MOVB"
	p[0], p[1], p[2], p[3] = x0, x1, x2, x3
}

type S1 struct {
	a, b int16
}

func loadstore2(p, q *S1) {
	// amd64:"MOVL",-"MOVWLZX"
	// arm64:"MOVWU",-"MOVH"
	a, b := p.a, p.b
	// amd64:"MOVL",-"MOVW"
	// arm64:"MOVW",-"MOVH"
	q.a, q.b = a, b
}

func wideStore(p *[8]uint64) {
	if p == nil {
		return
	}

	// amd64:"MOVUPS",-"MOVQ"
	// arm64:"STP",-"MOVD"
	p[0] = 0
	// amd64:-"MOVUPS",-"MOVQ"
	// arm64:-"STP",-"MOVD"
	p[1] = 0
}

func wideStore2(p *[8]uint64, x, y uint64) {
	if p == nil {
		return
	}

	// s390x:"STMG"
	p[0] = x
	// s390x:-"STMG",-"MOVD"
	p[1] = y
}

func store32le(p *struct{ a, b uint32 }, x uint64) {
	// amd64:"MOVQ",-"MOVL",-"SHRQ"
	// arm64:"MOVD",-"MOVW",-"LSR"
	// ppc64le:"MOVD",-"MOVW",-"SRD"
	p.a = uint32(x)
	// amd64:-"MOVL",-"SHRQ"
	// arm64:-"MOVW",-"LSR"
	// ppc64le:-"MOVW",-"SRD"
	p.b = uint32(x >> 32)
}
func store32be(p *struct{ a, b uint32 }, x uint64) {
	// ppc64:"MOVD",-"MOVW",-"SRD"
	// s390x:"MOVD",-"MOVW",-"SRD"
	p.a = uint32(x >> 32)
	// ppc64:-"MOVW",-"SRD"
	// s390x:-"MOVW",-"SRD"
	p.b = uint32(x)
}
func store16le(p *struct{ a, b uint16 }, x uint32) {
	// amd64:"MOVL",-"MOVW",-"SHRL"
	// arm64:"MOVW",-"MOVH",-"UBFX"
	// ppc64le:"MOVW",-"MOVH",-"SRW"
	p.a = uint16(x)
	// amd64:-"MOVW",-"SHRL"
	// arm64:-"MOVH",-"UBFX"
	// ppc64le:-"MOVH",-"SRW"
	p.b = uint16(x >> 16)
}
func store16be(p *struct{ a, b uint16 }, x uint32) {
	// ppc64:"MOVW",-"MOVH",-"SRW"
	// s390x:"MOVW",-"MOVH",-"SRW"
	p.a = uint16(x >> 16)
	// ppc64:-"MOVH",-"SRW"
	// s390x:-"MOVH",-"SRW"
	p.b = uint16(x)
}

func storeBoolConst(p *struct{ a, b bool }) {
	// amd64:"MOVW",-"MOVB"
	// arm64:"MOVH",-"MOVB"
	p.a = true
	p.b = true
}
func issue66413(p *struct {
	a byte
	b bool
	c bool
	d int8
}) {
	// amd64:"MOVL",-"MOVB"
	// arm64:"MOVW",-"MOVB"
	p.a = 31
	p.b = false
	p.c = true
	p.d = 12
}

func issue70300(v uint64) (b [8]byte) {
	// amd64:"MOVQ",-"MOVB"
	b[0] = byte(v)
	b[1] = byte(v >> 8)
	b[2] = byte(v >> 16)
	b[3] = byte(v >> 24)
	b[4] = byte(v >> 32)
	b[5] = byte(v >> 40)
	b[6] = byte(v >> 48)
	b[7] = byte(v >> 56)
	return b
}

func issue70300Reverse(v uint64) (b [8]byte) {
	// amd64:"MOVQ",-"MOVB"
	b[7] = byte(v >> 56)
	b[6] = byte(v >> 48)
	b[5] = byte(v >> 40)
	b[4] = byte(v >> 32)
	b[3] = byte(v >> 24)
	b[2] = byte(v >> 16)
	b[1] = byte(v >> 8)
	b[0] = byte(v)
	return b
}
```