Response: Let's break down the thought process for analyzing this C++ code and explaining its functionality and relation to JavaScript.

**1. Initial Understanding and Goal Identification:**

The request asks for:
* A summary of the C++ code's functionality.
* If it relates to JavaScript, provide a JavaScript example.

Therefore, the core goal is to understand what the C++ code does related to string encoding/decoding and how that manifests in JavaScript.

**2. Code Structure and Key Components:**

I'd start by scanning the code for structural elements and keywords that hint at its purpose:

* **Header:** The copyright and includes (`unicode-decoder.h`, `unicode-inl.h`) strongly suggest it deals with Unicode encoding/decoding. The `memcopy.h` inclusion indicates memory manipulation, which is common in string processing.
* **Namespaces:** `v8::internal` suggests this is an internal part of the V8 JavaScript engine.
* **Templates:** The use of templates (`template <class Decoder>`) hints at a generic design, likely to handle different UTF encodings.
* **`DecoderTraits` struct:**  This structure, specialized for different `Decoder` types (like `Utf8Decoder`, `Wtf8Decoder`, `StrictUtf8Decoder`), is a key pattern. It defines specific behaviors for each decoder. Looking at its members (`IsInvalidSurrogatePair`, `kAllowIncompleteSequences`, `DfaDecoder`) gives clues about validation and handling of potentially malformed input.
* **`Utf8DecoderBase` class:** This is the main class. Its constructor and `Decode` method are where the core logic resides.
* **Member variables:** `encoding_`, `non_ascii_start_`, `utf16_length_` suggest the class tracks the encoding, the starting point of non-ASCII characters, and the resulting UTF-16 length.
* **DFA (Deterministic Finite Automaton):**  References to `DfaDecoder` (like `Utf8DfaDecoder`) strongly suggest that a DFA is used to efficiently parse UTF-8 byte sequences.
* **Error Handling:** The checks for invalid surrogate pairs and the handling of incomplete sequences indicate error handling and potentially lenient/strict decoding modes.
* **`DEFINE_UNICODE_DECODER` macro:**  This macro simplifies the instantiation of the `Utf8DecoderBase` template for different character types (`uint8_t`, `uint16_t`).

**3. Deep Dive into the Logic:**

Now, I'd look closely at the core functions:

* **Constructor (`Utf8DecoderBase`):**
    * It determines the `non_ascii_start_`.
    * It iterates through the byte sequence, using the DFA to decode UTF-8 characters.
    * It keeps track of `utf16_length_`, which is important because some UTF-8 characters require two UTF-16 code units (surrogate pairs).
    * It handles invalid UTF-8 sequences based on the `DecoderTraits`.
    * It determines the final encoding (`kAscii`, `kLatin1`, `kUtf16`, `kInvalid`).
* **`Decode` method:**
    * It copies ASCII characters directly.
    * It uses the DFA to decode UTF-8.
    * It handles surrogate pairs when the decoded code point is above the BMP (Basic Multilingual Plane).
    * It manages potentially incomplete sequences.

**4. Identifying the Connection to JavaScript:**

Knowing that this code lives within the V8 engine, which powers Chrome and Node.js, the connection to JavaScript becomes clearer. JavaScript strings are internally represented using UTF-16. When JavaScript code encounters UTF-8 data (e.g., from a network request, file read), V8 needs to convert that data to its internal UTF-16 representation.

The `unicode-decoder.cc` file is very likely involved in this conversion process. It takes raw byte sequences (potentially UTF-8) and decodes them into a format usable by the JavaScript engine.

**5. Crafting the JavaScript Example:**

To illustrate the connection, I would look for common JavaScript scenarios where encoding/decoding is relevant. A few options come to mind:

* **`TextDecoder` API:** This is the most direct way in JavaScript to decode various encodings. Using `TextDecoder('utf-8')` aligns perfectly with the C++ code's purpose.
* **String manipulation:** While JavaScript handles string encoding largely internally, understanding the underlying encoding helps explain the length and character access behaviors. However, `TextDecoder` provides a more explicit link to the C++ code's function.

I'd choose `TextDecoder` for its clarity. The example should:

* Have a UTF-8 encoded string (represented as a `Uint8Array`).
* Use `TextDecoder` to decode it.
* Show the resulting JavaScript string.
* Optionally, highlight cases with multi-byte characters or invalid sequences to demonstrate the C++ code's error handling.

**6. Refining the Explanation:**

Finally, I'd structure the explanation clearly:

* **Summarize the core functionality:** Focus on decoding UTF-8 to UTF-16.
* **Explain the key components:** Briefly describe the roles of `DecoderTraits`, `Utf8DecoderBase`, and the DFA.
* **Highlight the connection to JavaScript:** Emphasize that this code is part of V8 and handles the conversion needed for JavaScript strings.
* **Provide the JavaScript example:**  Use `TextDecoder` and explain how it relates to the C++ code.
* **Discuss potential implications:** Mention performance and security aspects related to efficient and correct decoding.

**Self-Correction/Refinement during the process:**

* **Initial thought:** Maybe this just handles basic UTF-8 decoding.
* **Correction:** The presence of different `Decoder` types (like `StrictUtf8Decoder`) suggests more nuanced handling, including error tolerance. The DFA further reinforces the idea of optimized decoding.
* **Initial example idea:**  Focus on string length in JavaScript.
* **Refinement:** `TextDecoder` is a more direct and illustrative example of the C++ code's function.

By following this thought process, combining code analysis with knowledge of JavaScript and V8 internals, a comprehensive and accurate explanation can be constructed.
è¿™ä¸ª C++ ä»£ç æ–‡ä»¶ `unicode-decoder.cc` çš„ä¸»è¦åŠŸèƒ½æ˜¯ **å°† UTF-8 ç¼–ç çš„å­—èŠ‚åºåˆ—è§£ç æˆ UTF-16 ç¼–ç çš„å­—ç¬¦åºåˆ—**ã€‚å®ƒæ˜¯ V8 JavaScript å¼•æ“ä¸­å¤„ç†å­—ç¬¦ä¸²ç¼–ç è½¬æ¢çš„å…³é”®éƒ¨åˆ†ã€‚

æ›´å…·ä½“åœ°è¯´ï¼Œå®ƒçš„åŠŸèƒ½å¯ä»¥å½’çº³ä¸ºï¼š

1. **æ”¯æŒå¤šç§ UTF-8 è§£ç å™¨ï¼š**  ä»£ç ä½¿ç”¨äº†æ¨¡æ¿ `Utf8DecoderBase` å’Œ `DecoderTraits` æ¥æ”¯æŒä¸åŒçš„ UTF-8 è§£ç ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
    * `Utf8Decoder`:  ä¸€ä¸ªæ ‡å‡†çš„ UTF-8 è§£ç å™¨ã€‚
    * `Wtf8Decoder` (å¦‚æœ `V8_ENABLE_WEBASSEMBLY` å®å®šä¹‰å¯ç”¨)ï¼š  å¯èƒ½ç”¨äºå¤„ç† WebAssembly ä¸­ä½¿ç”¨çš„ç‰¹å®š UTF-8 å˜ä½“ï¼ˆWTF-8ï¼‰ã€‚
    * `StrictUtf8Decoder` (å¦‚æœ `V8_ENABLE_WEBASSEMBLY` å®å®šä¹‰å¯ç”¨)ï¼š ä¸€ä¸ªä¸¥æ ¼çš„ UTF-8 è§£ç å™¨ï¼Œå¯èƒ½å¯¹è¾“å…¥æœ‰æ›´ä¸¥æ ¼çš„æ ¡éªŒã€‚

2. **é«˜æ•ˆçš„è§£ç è¿‡ç¨‹ï¼š** ä»£ç ä½¿ç”¨äº†ç¡®å®šæ€§æœ‰é™è‡ªåŠ¨æœº (DFA, Deterministic Finite Automaton)  (`Utf8DfaDecoder` æˆ– `GeneralizedUtf8DfaDecoder`) æ¥å®ç°é«˜æ•ˆçš„ UTF-8 è§£æã€‚DFA èƒ½å¤Ÿå¿«é€Ÿåˆ¤æ–­å­—èŠ‚åºåˆ—æ˜¯å¦æ„æˆæœ‰æ•ˆçš„ UTF-8 å­—ç¬¦ä»¥åŠå­—ç¬¦çš„é•¿åº¦ã€‚

3. **å¤„ç†é ASCII å­—ç¬¦ï¼š** ä»£ç é¦–å…ˆå¿«é€Ÿè·³è¿‡ ASCII å­—ç¬¦ï¼Œåªå¯¹å¯èƒ½åŒ…å«å¤šå­—èŠ‚ UTF-8 å­—ç¬¦çš„éƒ¨åˆ†è¿›è¡Œè§£ç ã€‚è¿™æé«˜äº†å¤„ç†åŒ…å«å¤§é‡ ASCII å­—ç¬¦çš„å­—ç¬¦ä¸²çš„æ•ˆç‡ã€‚

4. **å¤„ç†ä¸å®Œæ•´çš„ UTF-8 åºåˆ—ï¼š**  é€šè¿‡ `kAllowIncompleteSequences` æ¨¡æ¿å‚æ•°ï¼Œè§£ç å™¨å¯ä»¥é€‰æ‹©æ˜¯å¦å…è®¸æˆ–å¦‚ä½•å¤„ç†ä¸å®Œæ•´çš„ UTF-8 åºåˆ—ã€‚å¯¹äºå…è®¸ä¸å®Œæ•´åºåˆ—çš„æƒ…å†µï¼Œé‡åˆ°ä¸å®Œæ•´çš„åºåˆ—å¯èƒ½ä¼šç”¨ä¸€ä¸ªç‰¹æ®Šçš„æ— æ•ˆå­—ç¬¦ (`unibrow::Utf8::kBadChar`) æ›¿æ¢ã€‚

5. **å¤„ç†ä»£ç†å¯¹ (Surrogate Pairs)ï¼š**  UTF-8 å¯ä»¥ç¼–ç è¶…å‡ºåŸºæœ¬å¤šæ–‡ç§å¹³é¢ (BMP) çš„ Unicode å­—ç¬¦ï¼Œè¿™äº›å­—ç¬¦åœ¨ UTF-16 ä¸­éœ€è¦ç”¨ä»£ç†å¯¹è¡¨ç¤ºã€‚è§£ç å™¨è´Ÿè´£å°†è¿™äº› UTF-8 åºåˆ—æ­£ç¡®åœ°è½¬æ¢ä¸º UTF-16 ä»£ç†å¯¹ã€‚

6. **ç¡®å®šå­—ç¬¦ä¸²çš„æœ€ç»ˆç¼–ç ï¼š**  è§£ç å™¨ä¼šåˆ¤æ–­è§£ç åçš„å­—ç¬¦ä¸²æ˜¯çº¯ ASCIIã€Latin-1 è¿˜æ˜¯åŒ…å«éœ€è¦ UTF-16 ç¼–ç çš„å­—ç¬¦ã€‚

**ä¸ JavaScript çš„å…³ç³»ä»¥åŠ JavaScript ç¤ºä¾‹ï¼š**

è¿™ä¸ª `unicode-decoder.cc` æ–‡ä»¶æ˜¯ V8 å¼•æ“å†…éƒ¨å®ç°çš„ä¸€éƒ¨åˆ†ï¼Œå®ƒç›´æ¥å½±å“ç€ JavaScript ä¸­å­—ç¬¦ä¸²çš„å¤„ç†æ–¹å¼ã€‚å½“ JavaScript ä»£ç å¤„ç†å­—ç¬¦ä¸²æ—¶ï¼ŒV8 éœ€è¦èƒ½å¤Ÿç†è§£å’Œæ“ä½œä¸åŒç¼–ç çš„å­—ç¬¦ä¸²ã€‚

ä¾‹å¦‚ï¼Œå½“ JavaScript ä»£ç ä»ç½‘ç»œè¯·æ±‚ã€æ–‡ä»¶è¯»å–æˆ–å…¶ä»–æ¥æºè·å–åˆ° UTF-8 ç¼–ç çš„æ–‡æœ¬æ•°æ®æ—¶ï¼ŒV8 å¼•æ“å°±ä¼šä½¿ç”¨ç±»ä¼¼çš„è§£ç å™¨å°†è¿™äº›æ•°æ®è½¬æ¢ä¸º JavaScript å†…éƒ¨ä½¿ç”¨çš„ UTF-16 å­—ç¬¦ä¸²è¡¨ç¤ºã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ª JavaScript ç¤ºä¾‹ï¼Œå±•ç¤ºäº† JavaScript å¦‚ä½•å¤„ç† UTF-8 ç¼–ç çš„æ•°æ®ï¼Œè€Œ V8 å¼•æ“å†…éƒ¨å¯èƒ½å°±ä½¿ç”¨äº†ç±»ä¼¼ `unicode-decoder.cc` ä¸­çš„æœºåˆ¶ï¼š

```javascript
// ä¸€ä¸ª UTF-8 ç¼–ç çš„å­—èŠ‚æ•°ç»„ï¼Œè¡¨ç¤ºå­—ç¬¦ä¸² "ä½ å¥½"
const utf8Bytes = new Uint8Array([228, 189, 160, 229, 165, 189]);

// ä½¿ç”¨ TextDecoder API å°† UTF-8 å­—èŠ‚æ•°ç»„è§£ç ä¸º JavaScript å­—ç¬¦ä¸²
const decoder = new TextDecoder('utf-8');
const decodedString = decoder.decode(utf8Bytes);

console.log(decodedString); // è¾“å‡º: ä½ å¥½
console.log(decodedString.length); // è¾“å‡º: 2 (å› ä¸º "ä½ " å’Œ "å¥½" å„å ä¸€ä¸ª UTF-16 ç å…ƒ)

// å¦‚æœ UTF-8 åºåˆ—åŒ…å«éœ€è¦ä»£ç†å¯¹çš„å­—ç¬¦ï¼Œè§£ç å™¨ä¹Ÿä¼šæ­£ç¡®å¤„ç†
const utf8BytesSurrogate = new Uint8Array([240, 159, 144, 141]); // UTF-8 for U+1F42D (Koala)
const decodedStringSurrogate = decoder.decode(utf8BytesSurrogate);
console.log(decodedStringSurrogate); // è¾“å‡º: ğŸ¨
console.log(decodedStringSurrogate.length); // è¾“å‡º: 1 (ä½†åœ¨ UTF-16 ä¸­å®é™…å ç”¨ä¸¤ä¸ªç å…ƒ)

// å°è¯•è§£ç ä¸å®Œæ•´çš„ UTF-8 åºåˆ— (å–å†³äºè§£ç å™¨çš„å®¹é”™æ€§ï¼ŒV8 å¯èƒ½ä¼šå¤„ç†æˆ–æŠ¥é”™)
const incompleteUtf8Bytes = new Uint8Array([228, 189]); // "ä½ " çš„å‰ä¸¤ä¸ªå­—èŠ‚
const decodedIncompleteString = decoder.decode(incompleteUtf8Bytes);
console.log(decodedIncompleteString); // è¾“å‡ºå¯èƒ½æ˜¯ä¸€ä¸ªéƒ¨åˆ†å­—ç¬¦æˆ–è€…ä¸€ä¸ªé”™è¯¯æŒ‡ç¤ºç¬¦

// JavaScript å­—ç¬¦ä¸²å†…éƒ¨ä½¿ç”¨ UTF-16 ç¼–ç 
const jsString = "ä½ å¥½";
console.log(jsString.charCodeAt(0).toString(16)); // è¾“å‡º "4f60" ("ä½ " çš„ Unicode ç ç‚¹)
console.log(jsString.charCodeAt(1).toString(16)); // è¾“å‡º "597d" ("å¥½" çš„ Unicode ç ç‚¹)
```

**æ€»ç»“:**

`v8/src/strings/unicode-decoder.cc` æ–‡ä»¶æ˜¯ V8 å¼•æ“ä¸­è´Ÿè´£å°† UTF-8 ç¼–ç çš„å­—èŠ‚æµè½¬æ¢ä¸º JavaScript å¯ä»¥ä½¿ç”¨çš„ UTF-16 å­—ç¬¦ä¸²çš„å…³é”®ç»„ä»¶ã€‚å®ƒä½¿ç”¨äº†é«˜æ•ˆçš„ DFA å’Œæ¨¡æ¿æŠ€æœ¯æ¥æ”¯æŒä¸åŒçš„è§£ç ç­–ç•¥ï¼Œå¹¶å¤„ç†å„ç§ UTF-8 ç¼–ç åœºæ™¯ï¼ŒåŒ…æ‹¬å¤šå­—èŠ‚å­—ç¬¦ã€ä»£ç†å¯¹ä»¥åŠå¯èƒ½å­˜åœ¨çš„ä¸å®Œæ•´åºåˆ—ã€‚  JavaScript çš„ `TextDecoder` API æä¾›äº†åœ¨ JavaScript ä»£ç ä¸­æ‰§è¡Œç±»ä¼¼è§£ç æ“ä½œçš„èƒ½åŠ›ï¼Œè€Œå…¶åº•å±‚å®ç°å¾ˆå¯èƒ½å°±ä¾èµ–äºåƒ `unicode-decoder.cc` è¿™æ ·çš„ C++ ä»£ç ã€‚

### æç¤ºè¯
```
è¿™æ˜¯ç›®å½•ä¸ºv8/src/strings/unicode-decoder.ccçš„ä¸€ä¸ªc++æºä»£ç æ–‡ä»¶ï¼Œ è¯·å½’çº³ä¸€ä¸‹å®ƒçš„åŠŸèƒ½, å¦‚æœå®ƒä¸javascriptçš„åŠŸèƒ½æœ‰å…³ç³»ï¼Œè¯·ç”¨javascriptä¸¾ä¾‹è¯´æ˜
```

### æºä»£ç 
```
// Copyright 2014 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#include "src/strings/unicode-decoder.h"

#include "src/strings/unicode-inl.h"
#include "src/utils/memcopy.h"

#if V8_ENABLE_WEBASSEMBLY
#include "src/third_party/utf8-decoder/generalized-utf8-decoder.h"
#endif

namespace v8 {
namespace internal {

namespace {
template <class Decoder>
struct DecoderTraits;

template <>
struct DecoderTraits<Utf8Decoder> {
  static bool IsInvalidSurrogatePair(uint32_t lead, uint32_t trail) {
    // The DfaDecoder will only ever decode Unicode scalar values, and all
    // sequences of USVs are valid.
    DCHECK(!unibrow::Utf16::IsLeadSurrogate(trail));
    DCHECK(!unibrow::Utf16::IsTrailSurrogate(trail));
    return false;
  }
  static const bool kAllowIncompleteSequences = true;
  using DfaDecoder = Utf8DfaDecoder;
};

#if V8_ENABLE_WEBASSEMBLY
template <>
struct DecoderTraits<Wtf8Decoder> {
  static bool IsInvalidSurrogatePair(uint32_t lead, uint32_t trail) {
    return unibrow::Utf16::IsSurrogatePair(lead, trail);
  }
  static const bool kAllowIncompleteSequences = false;
  using DfaDecoder = GeneralizedUtf8DfaDecoder;
};

template <>
struct DecoderTraits<StrictUtf8Decoder> {
  static bool IsInvalidSurrogatePair(uint32_t lead, uint32_t trail) {
    // The DfaDecoder will only ever decode Unicode scalar values, and all
    // sequences of USVs are valid.
    DCHECK(!unibrow::Utf16::IsLeadSurrogate(trail));
    DCHECK(!unibrow::Utf16::IsTrailSurrogate(trail));
    return false;
  }
  static const bool kAllowIncompleteSequences = false;
  using DfaDecoder = Utf8DfaDecoder;
};
#endif  // V8_ENABLE_WEBASSEMBLY
}  // namespace

template <class Decoder>
Utf8DecoderBase<Decoder>::Utf8DecoderBase(base::Vector<const uint8_t> data)
    : encoding_(Encoding::kAscii),
      non_ascii_start_(NonAsciiStart(data.begin(), data.length())),
      utf16_length_(non_ascii_start_) {
  using Traits = DecoderTraits<Decoder>;
  if (non_ascii_start_ == data.length()) return;

  bool is_one_byte = true;
  auto state = Traits::DfaDecoder::kAccept;
  uint32_t current = 0;
  uint32_t previous = 0;
  const uint8_t* cursor = data.begin() + non_ascii_start_;
  const uint8_t* end = data.begin() + data.length();

  while (cursor < end) {
    if (V8_LIKELY(*cursor <= unibrow::Utf8::kMaxOneByteChar &&
                  state == Traits::DfaDecoder::kAccept)) {
      DCHECK_EQ(0u, current);
      DCHECK(!Traits::IsInvalidSurrogatePair(previous, *cursor));
      previous = *cursor;
      utf16_length_++;
      cursor++;
      continue;
    }

    auto previous_state = state;
    Traits::DfaDecoder::Decode(*cursor, &state, &current);
    if (state < Traits::DfaDecoder::kAccept) {
      DCHECK_EQ(state, Traits::DfaDecoder::kReject);
      if (Traits::kAllowIncompleteSequences) {
        state = Traits::DfaDecoder::kAccept;
        static_assert(unibrow::Utf8::kBadChar > unibrow::Latin1::kMaxChar);
        is_one_byte = false;
        utf16_length_++;
        previous = unibrow::Utf8::kBadChar;
        current = 0;
        // If we were trying to continue a multibyte sequence, try this byte
        // again.
        if (previous_state != Traits::DfaDecoder::kAccept) continue;
      } else {
        encoding_ = Encoding::kInvalid;
        return;
      }
    } else if (state == Traits::DfaDecoder::kAccept) {
      if (Traits::IsInvalidSurrogatePair(previous, current)) {
        encoding_ = Encoding::kInvalid;
        return;
      }
      is_one_byte = is_one_byte && current <= unibrow::Latin1::kMaxChar;
      utf16_length_++;
      if (current > unibrow::Utf16::kMaxNonSurrogateCharCode) utf16_length_++;
      previous = current;
      current = 0;
    }
    cursor++;
  }

  if (state == Traits::DfaDecoder::kAccept) {
    encoding_ = is_one_byte ? Encoding::kLatin1 : Encoding::kUtf16;
  } else if (Traits::kAllowIncompleteSequences) {
    static_assert(unibrow::Utf8::kBadChar > unibrow::Latin1::kMaxChar);
    encoding_ = Encoding::kUtf16;
    utf16_length_++;
  } else {
    encoding_ = Encoding::kInvalid;
  }
}

template <class Decoder>
template <typename Char>
void Utf8DecoderBase<Decoder>::Decode(Char* out,
                                      base::Vector<const uint8_t> data) {
  using Traits = DecoderTraits<Decoder>;
  DCHECK(!is_invalid());
  CopyChars(out, data.begin(), non_ascii_start_);

  out += non_ascii_start_;

  auto state = Traits::DfaDecoder::kAccept;
  uint32_t current = 0;
  const uint8_t* cursor = data.begin() + non_ascii_start_;
  const uint8_t* end = data.begin() + data.length();

  while (cursor < end) {
    if (V8_LIKELY(*cursor <= unibrow::Utf8::kMaxOneByteChar &&
                  state == Traits::DfaDecoder::kAccept)) {
      DCHECK_EQ(0u, current);
      *(out++) = static_cast<Char>(*cursor);
      cursor++;
      continue;
    }

    auto previous_state = state;
    Traits::DfaDecoder::Decode(*cursor, &state, &current);
    if (Traits::kAllowIncompleteSequences &&
        state < Traits::DfaDecoder::kAccept) {
      state = Traits::DfaDecoder::kAccept;
      *(out++) = static_cast<Char>(unibrow::Utf8::kBadChar);
      current = 0;
      // If we were trying to continue a multibyte sequence, try this byte
      // again.
      if (previous_state != Traits::DfaDecoder::kAccept) continue;
    } else if (state == Traits::DfaDecoder::kAccept) {
      if (sizeof(Char) == 1 ||
          current <= unibrow::Utf16::kMaxNonSurrogateCharCode) {
        *(out++) = static_cast<Char>(current);
      } else {
        *(out++) = unibrow::Utf16::LeadSurrogate(current);
        *(out++) = unibrow::Utf16::TrailSurrogate(current);
      }
      current = 0;
    }
    cursor++;
  }

  if (Traits::kAllowIncompleteSequences &&
      state != Traits::DfaDecoder::kAccept) {
    *out = static_cast<Char>(unibrow::Utf8::kBadChar);
  } else {
    DCHECK_EQ(state, Traits::DfaDecoder::kAccept);
  }
}

#define DEFINE_UNICODE_DECODER(Decoder)                                 \
  template V8_EXPORT_PRIVATE Utf8DecoderBase<Decoder>::Utf8DecoderBase( \
      base::Vector<const uint8_t> data);                                \
  template V8_EXPORT_PRIVATE void Utf8DecoderBase<Decoder>::Decode(     \
      uint8_t* out, base::Vector<const uint8_t> data);                  \
  template V8_EXPORT_PRIVATE void Utf8DecoderBase<Decoder>::Decode(     \
      uint16_t* out, base::Vector<const uint8_t> data)

DEFINE_UNICODE_DECODER(Utf8Decoder);

#if V8_ENABLE_WEBASSEMBLY
DEFINE_UNICODE_DECODER(Wtf8Decoder);
DEFINE_UNICODE_DECODER(StrictUtf8Decoder);
#endif  // V8_ENABLE_WEBASSEMBLY

#undef DEFINE_UNICODE_DECODER

}  // namespace internal
}  // namespace v8
```