Response: Let's break down the thought process for analyzing this C++ code and relating it to JavaScript.

1. **Initial Understanding of the File Path and Namespace:** The file path `v8/src/inspector/v8-string-conversions.cc` and the namespace `v8_inspector` immediately suggest this code is part of the V8 JavaScript engine's inspector functionality. Inspectors deal with debugging and profiling, which often involve handling string data transferred between the engine and the debugging tools. The name "string-conversions" is a strong indicator of the core functionality.

2. **Scanning for Key Data Structures and Functions:**  A quick scan of the code reveals several important elements:
    * `UChar` (char16_t) and `UChar32` (uint32_t):  These suggest the code is dealing with different Unicode encodings, particularly UTF-16 (common in JavaScript) and potentially UTF-32.
    * `convertUTF16ToUTF8` and `convertUTF8ToUTF16`: These function names are explicit and point to the main purpose of the file: converting between UTF-16 and UTF-8.
    * Helper functions like `inlineUTF8SequenceLength`, `isLegalUTF8`, `readUTF8Sequence`: These indicate the code handles the complexities of UTF-8 encoding and validation.
    * `replacementCharacter`:  This suggests error handling for invalid or unrepresentable characters during conversion.
    * `UTF16ToUTF8` and `UTF8ToUTF16`: These are the higher-level functions likely used by other parts of the inspector.

3. **Analyzing the Conversion Logic (Focus on `convertUTF16ToUTF8` and `convertUTF8ToUTF16`):**
    * **`convertUTF16ToUTF8`:**  The code iterates through UTF-16 code units. It handles surrogate pairs correctly to represent code points above U+FFFF. It determines the number of bytes needed in UTF-8 and writes the corresponding byte sequence. It also handles potential errors like running out of space in the target buffer or encountering unpaired surrogates (if `strict` is true).
    * **`convertUTF8ToUTF16`:**  The code reads UTF-8 sequences, determines the corresponding Unicode code point, and then writes the appropriate UTF-16 representation (potentially as a surrogate pair if the code point is above U+FFFF). It also performs validation of the UTF-8 sequence and handles potential errors.

4. **Identifying Connections to JavaScript:**  The use of UTF-16 is the most direct link to JavaScript. JavaScript internally represents strings using UTF-16. The inspector needs to convert these JavaScript strings to UTF-8 for transmission or storage (UTF-8 is a more common encoding for data exchange). Conversely, when receiving data (e.g., from a debugging client), the inspector might need to convert UTF-8 back to UTF-16 to represent it as a JavaScript string.

5. **Formulating the Summary of Functionality:** Based on the analysis, the core function is clearly UTF-16 to UTF-8 and UTF-8 to UTF-16 conversion. The code handles the nuances of these encodings, including surrogate pairs, multi-byte UTF-8 sequences, and error conditions.

6. **Developing JavaScript Examples:**  To illustrate the connection, consider scenarios where string conversion is relevant in the context of the V8 inspector:
    * **Sending data to the debugger:** When the inspector sends information about a JavaScript object or variable (including strings) to the debugging tools, it likely needs to convert the UTF-16 JavaScript strings to UTF-8 for easier transmission and compatibility. The example `console.log("ä½ å¥½");` demonstrates a simple JavaScript string that would be converted.
    * **Receiving data from the debugger:**  If the debugger sends commands or data containing strings back to the JavaScript engine, those strings might be in UTF-8 and need to be converted back to UTF-16. An example could be a breakpoint condition involving a string. Although not directly demonstrated by user-level JavaScript, this conversion happens internally within the V8 inspector.
    * **Handling special characters:**  Demonstrating the handling of characters outside the basic ASCII range and surrogate pairs helps illustrate the robustness of the conversion functions. Examples like emojis (`'ğŸ˜€'`) or characters requiring surrogate pairs are good for this.

7. **Refining the Explanation:**  Review and refine the explanation to ensure clarity and accuracy. Emphasize the "why" â€“ why these conversions are necessary in the context of the inspector and JavaScript's string representation. Structure the explanation logically, starting with the main function and then providing specific examples. Use clear and concise language, avoiding excessive technical jargon where possible.

**Self-Correction/Refinement during the process:**

* **Initial thought:** Maybe the file deals with all kinds of string conversions.
* **Correction:** The file name and function names clearly point to UTF-8 and UTF-16 specifically. The focus should be on these two encodings and their relevance to JavaScript.
* **Initial thought:** The JavaScript examples should be complex debugging scenarios.
* **Correction:**  Simple and direct examples are better for illustrating the core concept of string conversion. The `console.log` example is very direct and easy to understand. Later examples can introduce more nuanced scenarios like emojis.
* **Initial thought:**  Focus solely on the C++ code logic.
* **Correction:**  The prompt specifically asks about the relationship to JavaScript. The explanation needs to explicitly connect the C++ code to JavaScript's string representation and the role of the inspector.

By following this thought process, combining code analysis with an understanding of the V8 inspector's purpose and JavaScript string handling, a comprehensive and accurate explanation can be constructed.
è¿™ä¸ª C++ æºä»£ç æ–‡ä»¶ `v8-string-conversions.cc` çš„ä¸»è¦åŠŸèƒ½æ˜¯**åœ¨ UTF-8 å’Œ UTF-16 ä¸¤ç§å­—ç¬¦ç¼–ç æ ¼å¼ä¹‹é—´è¿›è¡Œç›¸äº’è½¬æ¢**ã€‚ç”±äº JavaScript å†…éƒ¨ä½¿ç”¨ UTF-16 ç¼–ç æ¥è¡¨ç¤ºå­—ç¬¦ä¸²ï¼Œè€Œ UTF-8 æ˜¯ä¸€ç§åœ¨ç½‘ç»œä¼ è¾“å’Œæ–‡ä»¶å­˜å‚¨ä¸­æ›´å¸¸ç”¨çš„ç¼–ç ï¼Œå› æ­¤è¿™ä¸ªæ–‡ä»¶å¯¹äº V8 å¼•æ“çš„ Inspectorï¼ˆè°ƒè¯•å™¨ï¼‰ç»„ä»¶æ¥è¯´è‡³å…³é‡è¦ã€‚

ä»¥ä¸‹æ˜¯è¯¥æ–‡ä»¶åŠŸèƒ½çš„è¯¦ç»†å½’çº³ï¼š

**æ ¸å¿ƒåŠŸèƒ½ï¼š**

* **`convertUTF16ToUTF8(const UChar** sourceStart, const UChar* sourceEnd, char** targetStart, char* targetEnd, bool strict)`:**  å°† UTF-16 ç¼–ç çš„å­—ç¬¦ä¸²è½¬æ¢ä¸º UTF-8 ç¼–ç ã€‚
    * `sourceStart`, `sourceEnd`: æŒ‡å‘ UTF-16 å­—ç¬¦ä¸²çš„èµ·å§‹å’Œç»“æŸä½ç½®ã€‚
    * `targetStart`, `targetEnd`: æŒ‡å‘ç”¨äºå­˜å‚¨è½¬æ¢å UTF-8 å­—ç¬¦ä¸²çš„ç¼“å†²åŒºçš„èµ·å§‹å’Œç»“æŸä½ç½®ã€‚
    * `strict`:  ä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºæ˜¯å¦è¿›è¡Œä¸¥æ ¼çš„è½¬æ¢ã€‚å¦‚æœä¸º `true`ï¼Œé‡åˆ°æ— æ•ˆçš„ UTF-16 åºåˆ—ï¼ˆå¦‚æœªé…å¯¹çš„ä»£ç†é¡¹ï¼‰å°†è¿”å›é”™è¯¯ï¼›å¦‚æœä¸º `false`ï¼Œåˆ™ä¼šæ›¿æ¢ä¸ºæ›¿æ¢å­—ç¬¦ (U+FFFD)ã€‚
* **`convertUTF8ToUTF16(const char** sourceStart, const char* sourceEnd, UChar** targetStart, UChar* targetEnd, bool* sourceAllASCII, bool strict)`:** å°† UTF-8 ç¼–ç çš„å­—ç¬¦ä¸²è½¬æ¢ä¸º UTF-16 ç¼–ç ã€‚
    * `sourceStart`, `sourceEnd`: æŒ‡å‘ UTF-8 å­—ç¬¦ä¸²çš„èµ·å§‹å’Œç»“æŸä½ç½®ã€‚
    * `targetStart`, `targetEnd`: æŒ‡å‘ç”¨äºå­˜å‚¨è½¬æ¢å UTF-16 å­—ç¬¦ä¸²çš„ç¼“å†²åŒºçš„èµ·å§‹å’Œç»“æŸä½ç½®ã€‚
    * `sourceAllASCII`: ä¸€ä¸ªå¯é€‰çš„è¾“å‡ºå‚æ•°ï¼Œå¦‚æœæ‰€æœ‰è½¬æ¢çš„å­—ç¬¦éƒ½æ˜¯ ASCII å­—ç¬¦ï¼Œåˆ™è®¾ç½®ä¸º `true`ã€‚
    * `strict`: ä¸€ä¸ªå¸ƒå°”å€¼ï¼ŒæŒ‡ç¤ºæ˜¯å¦è¿›è¡Œä¸¥æ ¼çš„è½¬æ¢ã€‚å¦‚æœä¸º `true`ï¼Œé‡åˆ°æ— æ•ˆçš„ UTF-8 åºåˆ—å°†è¿”å›é”™è¯¯ï¼›å¦‚æœä¸º `false`ï¼Œåˆ™ä¼šæ›¿æ¢ä¸ºæ›¿æ¢å­—ç¬¦ (U+FFFD)ã€‚

**è¾…åŠ©åŠŸèƒ½ï¼š**

* **`isASCII(UChar c)`:** æ£€æŸ¥ä¸€ä¸ª UTF-16 å­—ç¬¦æ˜¯å¦æ˜¯ ASCII å­—ç¬¦ã€‚
* **`inlineUTF8SequenceLength(char b0)`:**  æ ¹æ® UTF-8 åºåˆ—çš„ç¬¬ä¸€ä¸ªå­—èŠ‚ï¼Œå¿«é€Ÿç¡®å®šè¯¥åºåˆ—çš„å­—èŠ‚é•¿åº¦ã€‚
* **`isLegalUTF8(const unsigned char* source, int length)`:** æ£€æŸ¥ä¸€ä¸ª UTF-8 åºåˆ—æ˜¯å¦åˆæ³•ã€‚
* **`readUTF8Sequence(const char*& sequence, size_t length)`:** ä» UTF-8 åºåˆ—ä¸­è¯»å–å¹¶è¿”å›å¯¹åº”çš„ Unicode ç ç‚¹ã€‚
* **`UTF16ToUTF8(const UChar* stringStart, size_t length)`:** æä¾›ä¸€ä¸ªæ›´æ–¹ä¾¿çš„æ¥å£ï¼Œå°† UTF-16 å­—ç¬¦ä¸²è½¬æ¢ä¸º `std::string` ç±»å‹çš„ UTF-8 å­—ç¬¦ä¸²ã€‚
* **`UTF8ToUTF16(const char* stringStart, size_t length)`:** æä¾›ä¸€ä¸ªæ›´æ–¹ä¾¿çš„æ¥å£ï¼Œå°† UTF-8 å­—ç¬¦ä¸²è½¬æ¢ä¸º `std::basic_string<UChar>` ç±»å‹çš„ UTF-16 å­—ç¬¦ä¸²ã€‚

**ä¸ JavaScript çš„å…³ç³»ï¼ˆä¸¾ä¾‹è¯´æ˜ï¼‰ï¼š**

ç”±äº JavaScript å†…éƒ¨ä½¿ç”¨ UTF-16 ç¼–ç ï¼Œå½“ V8 å¼•æ“çš„ Inspector éœ€è¦ä¸å¤–éƒ¨å·¥å…·ï¼ˆä¾‹å¦‚ Chrome DevToolsï¼‰è¿›è¡Œé€šä¿¡æ—¶ï¼Œé€šå¸¸éœ€è¦å°† JavaScript å­—ç¬¦ä¸²è½¬æ¢ä¸º UTF-8 ç¼–ç è¿›è¡Œä¼ è¾“ï¼Œå› ä¸º UTF-8 åœ¨ç½‘ç»œä¼ è¾“ä¸­æ›´å¸¸è§ä¸”æ›´èŠ‚çœç©ºé—´ã€‚åä¹‹ï¼Œä»å¤–éƒ¨æ¥æ”¶åˆ°çš„å­—ç¬¦ä¸²ï¼ˆé€šå¸¸æ˜¯ UTF-8 ç¼–ç ï¼‰éœ€è¦è½¬æ¢å› UTF-16 æ‰èƒ½åœ¨ JavaScript ä¸­ä½¿ç”¨ã€‚

**JavaScript ç¤ºä¾‹ï¼š**

å‡è®¾ä½ åœ¨ Chrome DevTools çš„æ§åˆ¶å°ä¸­æ‰§è¡Œä»¥ä¸‹ JavaScript ä»£ç ï¼š

```javascript
let message = "ä½ å¥½ï¼Œä¸–ç•Œï¼ğŸŒ";
console.log(message);
```

å½“ Inspector éœ€è¦å°†è¿™ä¸ª `message` å˜é‡çš„å€¼å‘é€åˆ° DevTools å‰ç«¯æ—¶ï¼Œ`v8-string-conversions.cc` ä¸­çš„ `UTF16ToUTF8` å‡½æ•°ä¼šè¢«è°ƒç”¨ï¼Œå°† UTF-16 ç¼–ç çš„ `"ä½ å¥½ï¼Œä¸–ç•Œï¼ğŸŒ"` è½¬æ¢ä¸º UTF-8 ç¼–ç çš„å­—èŠ‚åºåˆ—ã€‚

åŒæ ·ï¼Œå¦‚æœ DevTools å‰ç«¯å‘ V8 å‘é€ä¸€ä¸ªåŒ…å«å­—ç¬¦ä¸²çš„å‘½ä»¤ï¼Œä¾‹å¦‚è®¾ç½®ä¸€ä¸ªåŒ…å«é ASCII å­—ç¬¦çš„æ–­ç‚¹ï¼š

```
// å‡è®¾ DevTools å‘é€çš„æ–­ç‚¹æ¡ä»¶å­—ç¬¦ä¸²æ˜¯ UTF-8 ç¼–ç çš„ "å˜é‡ === 'æµ‹è¯•'"
```

é‚£ä¹ˆ `v8-string-conversions.cc` ä¸­çš„ `UTF8ToUTF16` å‡½æ•°ä¼šè¢«è°ƒç”¨ï¼Œå°† UTF-8 ç¼–ç çš„ `"å˜é‡ === 'æµ‹è¯•'"` è½¬æ¢å› UTF-16 ç¼–ç ï¼Œä»¥ä¾¿ V8 å¼•æ“å¯ä»¥ç†è§£å’Œä½¿ç”¨è¿™ä¸ªæ–­ç‚¹æ¡ä»¶ã€‚

**æ€»ç»“:**

`v8-string-conversions.cc` æ–‡ä»¶åœ¨ V8 å¼•æ“çš„ Inspector ç»„ä»¶ä¸­æ‰®æ¼”ç€å…³é”®çš„è§’è‰²ï¼Œå®ƒæä¾›äº†é«˜æ•ˆä¸”å¯é çš„ UTF-8 å’Œ UTF-16 ä¹‹é—´çš„è½¬æ¢åŠŸèƒ½ï¼Œä½¿å¾— Inspector èƒ½å¤Ÿæ­£ç¡®åœ°å¤„ç†å’Œä¼ è¾“åŒ…å«å„ç§å­—ç¬¦çš„å­—ç¬¦ä¸²æ•°æ®ï¼Œä»è€Œå®ç° JavaScript ä»£ç çš„è°ƒè¯•å’Œåˆ†æã€‚

### æç¤ºè¯
```
è¿™æ˜¯ç›®å½•ä¸ºv8/src/inspector/v8-string-conversions.ccçš„ä¸€ä¸ªc++æºä»£ç æ–‡ä»¶ï¼Œ è¯·å½’çº³ä¸€ä¸‹å®ƒçš„åŠŸèƒ½, å¦‚æœå®ƒä¸javascriptçš„åŠŸèƒ½æœ‰å…³ç³»ï¼Œè¯·ç”¨javascriptä¸¾ä¾‹è¯´æ˜
```

### æºä»£ç 
```
// Copyright 2019 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#include "src/inspector/v8-string-conversions.h"

#include <limits>
#include <vector>

#include "src/base/logging.h"

namespace v8_inspector {
namespace {
using UChar = char16_t;
using UChar32 = uint32_t;

bool isASCII(UChar c) { return !(c & ~0x7F); }

const UChar replacementCharacter = 0xFFFD;

inline int inlineUTF8SequenceLengthNonASCII(char b0) {
  if ((b0 & 0xC0) != 0xC0) return 0;
  if ((b0 & 0xE0) == 0xC0) return 2;
  if ((b0 & 0xF0) == 0xE0) return 3;
  if ((b0 & 0xF8) == 0xF0) return 4;
  return 0;
}

inline int inlineUTF8SequenceLength(char b0) {
  return isASCII(b0) ? 1 : inlineUTF8SequenceLengthNonASCII(b0);
}

// Once the bits are split out into bytes of UTF-8, this is a mask OR-ed
// into the first byte, depending on how many bytes follow.  There are
// as many entries in this table as there are UTF-8 sequence types.
// (I.e., one byte sequence, two byte... etc.). Remember that sequences
// for *legal* UTF-8 will be 4 or fewer bytes total.
static const unsigned char firstByteMark[7] = {0x00, 0x00, 0xC0, 0xE0,
                                               0xF0, 0xF8, 0xFC};

enum ConversionResult {
  conversionOK,     // conversion successful
  sourceExhausted,  // partial character in source, but hit end
  targetExhausted,  // insuff. room in target for conversion
  sourceIllegal     // source sequence is illegal/malformed
};

ConversionResult convertUTF16ToUTF8(const UChar** sourceStart,
                                    const UChar* sourceEnd, char** targetStart,
                                    char* targetEnd, bool strict) {
  ConversionResult result = conversionOK;
  const UChar* source = *sourceStart;
  char* target = *targetStart;
  while (source < sourceEnd) {
    UChar32 ch;
    uint32_t bytesToWrite = 0;
    const UChar32 byteMask = 0xBF;
    const UChar32 byteMark = 0x80;
    const UChar* oldSource =
        source;  // In case we have to back up because of target overflow.
    ch = static_cast<uint16_t>(*source++);
    // If we have a surrogate pair, convert to UChar32 first.
    if (ch >= 0xD800 && ch <= 0xDBFF) {
      // If the 16 bits following the high surrogate are in the source buffer...
      if (source < sourceEnd) {
        UChar32 ch2 = static_cast<uint16_t>(*source);
        // If it's a low surrogate, convert to UChar32.
        if (ch2 >= 0xDC00 && ch2 <= 0xDFFF) {
          ch = ((ch - 0xD800) << 10) + (ch2 - 0xDC00) + 0x0010000;
          ++source;
        } else if (strict) {  // it's an unpaired high surrogate
          --source;           // return to the illegal value itself
          result = sourceIllegal;
          break;
        }
      } else {     // We don't have the 16 bits following the high surrogate.
        --source;  // return to the high surrogate
        result = sourceExhausted;
        break;
      }
    } else if (strict) {
      // UTF-16 surrogate values are illegal in UTF-32
      if (ch >= 0xDC00 && ch <= 0xDFFF) {
        --source;  // return to the illegal value itself
        result = sourceIllegal;
        break;
      }
    }
    // Figure out how many bytes the result will require
    if (ch < static_cast<UChar32>(0x80)) {
      bytesToWrite = 1;
    } else if (ch < static_cast<UChar32>(0x800)) {
      bytesToWrite = 2;
    } else if (ch < static_cast<UChar32>(0x10000)) {
      bytesToWrite = 3;
    } else if (ch < static_cast<UChar32>(0x110000)) {
      bytesToWrite = 4;
    } else {
      bytesToWrite = 3;
      ch = replacementCharacter;
    }

    target += bytesToWrite;
    if (target > targetEnd) {
      source = oldSource;  // Back up source pointer!
      target -= bytesToWrite;
      result = targetExhausted;
      break;
    }
    switch (bytesToWrite) {
      case 4:
        *--target = static_cast<char>((ch | byteMark) & byteMask);
        ch >>= 6;
        [[fallthrough]];
      case 3:
        *--target = static_cast<char>((ch | byteMark) & byteMask);
        ch >>= 6;
        [[fallthrough]];
      case 2:
        *--target = static_cast<char>((ch | byteMark) & byteMask);
        ch >>= 6;
        [[fallthrough]];
      case 1:
        *--target = static_cast<char>(ch | firstByteMark[bytesToWrite]);
    }
    target += bytesToWrite;
  }
  *sourceStart = source;
  *targetStart = target;
  return result;
}

/**
 * Is this code point a BMP code point (U+0000..U+ffff)?
 * @param c 32-bit code point
 * @return TRUE or FALSE
 * @stable ICU 2.8
 */
#define U_IS_BMP(c) ((uint32_t)(c) <= 0xFFFF)

/**
 * Is this code point a supplementary code point (U+010000..U+10FFFF)?
 * @param c 32-bit code point
 * @return TRUE or FALSE
 * @stable ICU 2.8
 */
#define U_IS_SUPPLEMENTARY(c) ((uint32_t)((c)-0x010000) <= 0xFFFFF)

/**
 * Is this code point a surrogate (U+d800..U+dfff)?
 * @param c 32-bit code point
 * @return TRUE or FALSE
 * @stable ICU 2.4
 */
#define U_IS_SURROGATE(c) (((c)&0xFFFFF800) == 0xD800)

/**
 * Get the lead surrogate (0xD800..0xDBFF) for a
 * supplementary code point (0x010000..0x10FFFF).
 * @param supplementary 32-bit code point (U+010000..U+10FFFF)
 * @return lead surrogate (U+D800..U+DBFF) for supplementary
 * @stable ICU 2.4
 */
#define U16_LEAD(supplementary) (UChar)(((supplementary) >> 10) + 0xD7C0)

/**
 * Get the trail surrogate (0xDC00..0xDFFF) for a
 * supplementary code point (0x010000..0x10FFFF).
 * @param supplementary 32-bit code point (U+010000..U+10FFFF)
 * @return trail surrogate (U+DC00..U+DFFF) for supplementary
 * @stable ICU 2.4
 */
#define U16_TRAIL(supplementary) (UChar)(((supplementary)&0x3FF) | 0xDC00)

// This must be called with the length pre-determined by the first byte.
// If presented with a length > 4, this returns false.  The Unicode
// definition of UTF-8 goes up to 4-byte sequences.
static bool isLegalUTF8(const unsigned char* source, int length) {
  unsigned char a;
  const unsigned char* srcptr = source + length;
  switch (length) {
    default:
      return false;
    // Everything else falls through when "true"...
    case 4:
      if ((a = (*--srcptr)) < 0x80 || a > 0xBF) return false;
      [[fallthrough]];
    case 3:
      if ((a = (*--srcptr)) < 0x80 || a > 0xBF) return false;
      [[fallthrough]];
    case 2:
      if ((a = (*--srcptr)) > 0xBF) return false;

      // no fall-through in this inner switch
      switch (*source) {
        case 0xE0:
          if (a < 0xA0) return false;
          break;
        case 0xED:
          if (a > 0x9F) return false;
          break;
        case 0xF0:
          if (a < 0x90) return false;
          break;
        case 0xF4:
          if (a > 0x8F) return false;
          break;
        default:
          if (a < 0x80) return false;
      }
      [[fallthrough]];

    case 1:
      if (*source >= 0x80 && *source < 0xC2) return false;
  }
  if (*source > 0xF4) return false;
  return true;
}

// Magic values subtracted from a buffer value during UTF8 conversion.
// This table contains as many values as there might be trailing bytes
// in a UTF-8 sequence.
static const UChar32 offsetsFromUTF8[6] = {0x00000000UL,
                                           0x00003080UL,
                                           0x000E2080UL,
                                           0x03C82080UL,
                                           static_cast<UChar32>(0xFA082080UL),
                                           static_cast<UChar32>(0x82082080UL)};

static inline UChar32 readUTF8Sequence(const char*& sequence, size_t length) {
  UChar32 character = 0;

  // The cases all fall through.
  switch (length) {
    case 6:
      character += static_cast<unsigned char>(*sequence++);
      character <<= 6;
      [[fallthrough]];
    case 5:
      character += static_cast<unsigned char>(*sequence++);
      character <<= 6;
      [[fallthrough]];
    case 4:
      character += static_cast<unsigned char>(*sequence++);
      character <<= 6;
      [[fallthrough]];
    case 3:
      character += static_cast<unsigned char>(*sequence++);
      character <<= 6;
      [[fallthrough]];
    case 2:
      character += static_cast<unsigned char>(*sequence++);
      character <<= 6;
      [[fallthrough]];
    case 1:
      character += static_cast<unsigned char>(*sequence++);
  }

  return character - offsetsFromUTF8[length - 1];
}

ConversionResult convertUTF8ToUTF16(const char** sourceStart,
                                    const char* sourceEnd, UChar** targetStart,
                                    UChar* targetEnd, bool* sourceAllASCII,
                                    bool strict) {
  ConversionResult result = conversionOK;
  const char* source = *sourceStart;
  UChar* target = *targetStart;
  UChar orAllData = 0;
  while (source < sourceEnd) {
    int utf8SequenceLength = inlineUTF8SequenceLength(*source);
    if (sourceEnd - source < utf8SequenceLength) {
      result = sourceExhausted;
      break;
    }
    // Do this check whether lenient or strict
    if (!isLegalUTF8(reinterpret_cast<const unsigned char*>(source),
                     utf8SequenceLength)) {
      result = sourceIllegal;
      break;
    }

    UChar32 character = readUTF8Sequence(source, utf8SequenceLength);

    if (target >= targetEnd) {
      source -= utf8SequenceLength;  // Back up source pointer!
      result = targetExhausted;
      break;
    }

    if (U_IS_BMP(character)) {
      // UTF-16 surrogate values are illegal in UTF-32
      if (U_IS_SURROGATE(character)) {
        if (strict) {
          source -= utf8SequenceLength;  // return to the illegal value itself
          result = sourceIllegal;
          break;
        }
        *target++ = replacementCharacter;
        orAllData |= replacementCharacter;
      } else {
        *target++ = static_cast<UChar>(character);  // normal case
        orAllData |= character;
      }
    } else if (U_IS_SUPPLEMENTARY(character)) {
      // target is a character in range 0xFFFF - 0x10FFFF
      if (target + 1 >= targetEnd) {
        source -= utf8SequenceLength;  // Back up source pointer!
        result = targetExhausted;
        break;
      }
      *target++ = U16_LEAD(character);
      *target++ = U16_TRAIL(character);
      orAllData = 0xFFFF;
    } else {
      if (strict) {
        source -= utf8SequenceLength;  // return to the start
        result = sourceIllegal;
        break;  // Bail out; shouldn't continue
      } else {
        *target++ = replacementCharacter;
        orAllData |= replacementCharacter;
      }
    }
  }
  *sourceStart = source;
  *targetStart = target;

  if (sourceAllASCII) *sourceAllASCII = !(orAllData & ~0x7F);

  return result;
}

// Helper to write a three-byte UTF-8 code point to the buffer, caller must
// check room is available.
static inline void putUTF8Triple(char*& buffer, UChar ch) {
  *buffer++ = static_cast<char>(((ch >> 12) & 0x0F) | 0xE0);
  *buffer++ = static_cast<char>(((ch >> 6) & 0x3F) | 0x80);
  *buffer++ = static_cast<char>((ch & 0x3F) | 0x80);
}
}  // namespace

std::string UTF16ToUTF8(const UChar* stringStart, size_t length) {
  if (!stringStart || !length) return std::string();

  // Allocate a buffer big enough to hold all the characters
  // (an individual UTF-16 UChar can only expand to 3 UTF-8 bytes).
  // Optimization ideas, if we find this function is hot:
  //  * We could speculatively create a CStringBuffer to contain 'length'
  //    characters, and resize if necessary (i.e. if the buffer contains
  //    non-ascii characters). (Alternatively, scan the buffer first for
  //    ascii characters, so we know this will be sufficient).
  //  * We could allocate a CStringBuffer with an appropriate size to
  //    have a good chance of being able to write the string into the
  //    buffer without reallocing (say, 1.5 x length).
  if (length > std::numeric_limits<unsigned>::max() / 3) return std::string();

  std::string output(length * 3, '\0');
  const UChar* characters = stringStart;
  const UChar* characters_end = characters + length;
  char* buffer = &*output.begin();
  char* buffer_end = &*output.end();
  while (characters < characters_end) {
    // Use strict conversion to detect unpaired surrogates.
    ConversionResult result = convertUTF16ToUTF8(
        &characters, characters_end, &buffer, buffer_end, /* strict= */ true);
    DCHECK_NE(result, targetExhausted);
    // Conversion fails when there is an unpaired surrogate.  Put
    // replacement character (U+FFFD) instead of the unpaired
    // surrogate.
    if (result != conversionOK) {
      DCHECK_LE(0xD800, *characters);
      DCHECK_LE(*characters, 0xDFFF);
      // There should be room left, since one UChar hasn't been
      // converted.
      DCHECK_LE(buffer + 3, buffer_end);
      putUTF8Triple(buffer, replacementCharacter);
      ++characters;
    }
  }

  output.resize(buffer - output.data());
  return output;
}

std::basic_string<UChar> UTF8ToUTF16(const char* stringStart, size_t length) {
  if (!stringStart || !length) return std::basic_string<UChar>();
  std::vector<UChar> buffer(length);
  UChar* bufferStart = buffer.data();

  UChar* bufferCurrent = bufferStart;
  const char* stringCurrent = reinterpret_cast<const char*>(stringStart);
  if (convertUTF8ToUTF16(&stringCurrent,
                         reinterpret_cast<const char*>(stringStart + length),
                         &bufferCurrent, bufferCurrent + buffer.size(), nullptr,
                         true) != conversionOK)
    return std::basic_string<UChar>();
  size_t utf16Length = bufferCurrent - bufferStart;
  return std::basic_string<UChar>(bufferStart, bufferStart + utf16Length);
}

}  // namespace v8_inspector
```