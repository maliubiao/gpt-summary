Response:
The user is asking for a summary of the functionalities provided by the C++ header file `v8/src/codegen/arm64/macro-assembler-arm64.h`. This file defines the `MacroAssembler` class for the ARM64 architecture in V8. It provides a high-level interface for generating machine code.

Here's a breakdown of the thought process to generate the summary:

1. **Identify the core purpose:** The file is a header defining the `MacroAssembler` for ARM64. This class is used for generating machine code.

2. **Categorize functionalities:** Scan the provided code snippets and group related functions together. Look for patterns in the function names and the operations they perform. Common categories include:
    * **Memory Access:** Loading and storing data (registers, immediates, constants, roots).
    * **Arithmetic and Logical Operations:**  Basic arithmetic, bitwise operations, comparisons.
    * **Control Flow:** Jumps, calls, branches, returns.
    * **Stack Manipulation:** Pushing and popping registers.
    * **Function Calls:** Calling C functions, built-ins, JS functions, WASM code.
    * **Floating-Point Operations:**  Arithmetic, conversions, comparisons.
    * **Vector (NEON) Instructions:** Operations on SIMD registers.
    * **Atomic Operations:**  Thread-safe memory access.
    * **Pointer Compression:** Handling compressed pointers.
    * **Debugging/Assertions:**  Checks and assertions for development.
    * **System Registers:** Accessing system registers.

3. **Elaborate on each category:**  For each category, provide a brief description of the kinds of operations offered. Use descriptive terms.

4. **Address specific constraints:** The prompt asks about:
    * **`.tq` extension:**  The provided snippet is `.h`, not `.tq`, so it's not Torque.
    * **Relationship to JavaScript:**  Since it's about generating machine code for V8, it's directly related to executing JavaScript. Examples are in function calls and object manipulation.
    * **Code logic inference:**  The `Switch` statement is a good example of conditional logic.
    * **Common programming errors:**  Stack alignment is a classic issue.
    * **"Part 2 of 4"**: This indicates a cumulative summary is needed, building upon the previous part (which we don't have). Focus on the functionalities present in *this* snippet.

5. **Provide examples:** Where appropriate, provide simple JavaScript examples to illustrate how the underlying machine code generated by these functions might be used.

6. **Illustrate code logic inference:** Describe the input and output of the `Switch` function as an example of logic.

7. **Give an example of a common error:** Explain the importance of stack alignment with `Push` and `Pop`.

8. **Structure the summary:** Organize the information clearly with headings and bullet points for readability.

9. **Review and refine:**  Read through the summary to ensure accuracy, completeness (within the scope of the provided snippet), and clarity. Make sure to address all parts of the prompt. For example, initially, I might have missed the significance of the `NOOP_UNLESS_DEBUG_CODE` macro, which is important for understanding the purpose of `AssertPositiveOrZero`. Re-reading the code helps catch such details.

10. **Address the "Part 2" aspect:**  Since this is part 2, emphasize that this summary focuses on the *new* functionalities presented in this section. If the earlier parts were available, the summary would ideally integrate those as well. Since they are not, a disclaimer about focusing on the current snippet is appropriate.
Based on the provided code snippet from `v8/src/codegen/arm64/macro-assembler-arm64.h`, here's a summary of its functionalities, focusing on the new elements introduced in this section:

**Core Functionality:**

This section of the `MacroAssembler` class definition for the ARM64 architecture in V8 continues to define methods for generating specific ARM64 assembly instructions. These methods provide an abstraction layer over raw assembly, making it easier to generate correct and efficient machine code within the V8 JavaScript engine.

**Specific Functionalities Introduced in this Section:**

* **Memory Access (Loads and Stores):**
    * `st Register& rd, const Register& rn, const Operand& operand);`:  A generic store instruction.
    * Several overloaded `Push` and `Pop` methods for pushing and popping multiple registers (up to 8 in some cases) to/from the stack. These methods handle stack alignment and optional link register signing/authentication for control flow integrity.
    * `MoveObjectAndSlot`:  Atomically moves an object and calculates the address of a slot within it, handling potential register overlaps.
    * `PushCPURegList`, `PopCPURegList`: Push and pop a list of CPU registers based on a `CPURegList`.
    * `LoadMap`, `LoadCompressedMap`: Load the map (object type information) from an object.
    * Vector (NEON) store instructions like `St1`.
    * Atomic memory operations like `Lda`, `Stl`, `Cas`, `Ld`, `St`, `Swp`.
    * `LoadRoot`, `LoadTaggedRoot`, `PushRoot`: Load values from the V8 root table.
    * `LoadTaggedField`, `LoadTaggedFieldWithoutDecompressing`, `LoadTaggedSignedField`, `SmiUntagField`:  Methods for loading tagged values (representing JavaScript objects and values) from memory, handling potential pointer compression.
    * `StoreTaggedField`, `StoreTwoTaggedFields`: Methods for storing tagged values to memory, handling potential pointer compression.
    * `AtomicStoreTaggedField`: Atomically stores a tagged field.
    * `DecompressTaggedSigned`, `DecompressTagged`, `DecompressProtected`: Decompress tagged pointers.
    * `AtomicDecompressTaggedSigned`, `AtomicDecompressTagged`:  Atomically decompress tagged pointers.

* **Control Flow:**
    * `Switch`:  Generates code for a switch statement based on an integer value.
    * `CompareAndBranch`, `CompareTaggedAndBranch`: Compare a register with an operand and branch based on the result.
    * `TestAndBranchIfAnySet`, `TestAndBranchIfAllClear`: Test bits in a register and branch based on the result.
    * `Brk`:  Generate a breakpoint instruction.
    * `JumpIfSmi`: Jump if a register holds a Small Integer (Smi).
    * `JumpIf`, `JumpIfEqual`, `JumpIfLessThan`, `JumpIfUnsignedLessThan`: Conditional jumps based on comparisons with immediate values.
    * `JumpIfMarking`, `JumpIfNotMarking`: Jump based on the state of the garbage collector's marking flag.
    * `Jump`, `Call`, `IndirectCall`:  Unconditional and conditional jumps and calls to different targets (addresses, code objects, external references).
    * `LoadEntryFromBuiltinIndex`, `LoadEntryFromBuiltin`, `CallBuiltinByIndex`, `CallBuiltin`, `TailCallBuiltin`:  Methods for calling V8 built-in functions.
    * `LoadCodeInstructionStart`, `CallCodeObject`, `JumpCodeObject`: Methods for calling and jumping to code objects.
    * `CallJSFunction`, `JumpJSFunction`:  Convenience methods for calling/jumping to JavaScript functions.
    * `ResolveWasmCodePointer`, `CallWasmCodePointer`, `LoadWasmCodePointer`: Methods for interacting with WebAssembly code.
    * `StoreReturnAddressAndCall`:  Stores the return address on the stack before a call.
    * `BailoutIfDeoptimized`, `CallForDeoptimization`:  Handles deoptimization scenarios.
    * `Ret`: Return from a function.

* **Arithmetic and Logical Operations:**
    * `Mul`: Multiplication.
    * Floating-point conversions: `Fcvtzs`, `Fjcvtzs`, `Fcvtzu`.
    * `Madd`, `Mneg`, `Sdiv`, `Udiv`, `Msub`:  More arithmetic operations.
    * Bitwise shifts and rotations: `Lsl`, `Lsr`, `Ror`.
    * Bitfield manipulation: `Ubfiz`, `Sbfiz`, `Ubfx`, `Sbfx`, `Bfi`.
    * `Cmn`: Compare Negative (affects flags).
    * Floating-point arithmetic: `Fadd`, `Fcmp`, `Fabs`, `Fmul`, `Fsub`, `Fdiv`, `Fmax`, `Fmin`.
    * `Rbit`, `Rev`: Bit reversal and byte reversal.
    * `Adc`: Add with Carry.
    * Conditional comparisons: `Ccmp`, `CcmpTagged`, `Ccmn`.
    * `Clz`: Count Leading Zeros.
    * Floating-point conversions with rounding modes: `Scvtf`, `Ucvtf`.
    * `CanonicalizeNaN`: Convert a NaN to its canonical form.
    * Conditional moves and sets: `CmovX`, `Cset`, `Csetm`, `Csinc`.
    * `Fcvt`: Floating-point conversion.
    * `Neg`, `Negs`: Negation.
    * `Abs`: Absolute value calculation.
    * `Cls`: Count Leading Sign bits.
    * `Cneg`: Conditional negation.
    * More floating-point conversions with different rounding modes: `Fcvtns`, `Fcvtnu`, `Fcvtms`, `Fcvtmu`, `Fcvtas`, `Fcvtau`.

* **Immediate Value Handling:**
    * `MoveImmediateForShiftedOp`:  Moves an immediate value into a register, potentially applying a shift that can be undone later.

* **Stack Management:**
    * `RequiredStackSizeForCallerSaved`: Calculates the stack space needed for saving caller-saved registers.
    * `PushCallerSaved`, `PopCallerSaved`: Pushes and pops caller-saved registers.
    * `Poke`, `Peek`, `PokePair`:  Directly write and read values from the stack at specific offsets.

* **Function Calling Conventions:**
    * `CallCFunction`:  Calls a C function, handling argument setup and return.
    * `TruncateDoubleToI`:  Converts a double to an integer according to JavaScript semantics.

* **Vector (NEON) Operations:**
    * `Fmov`: Move data between vector registers, and between scalar and vector registers.
    * `Movi`: Move immediate values into vector registers.
    * `Ins`: Insert elements into vector registers.
    * `Dup`: Duplicate elements or scalar values into vector registers.
    * `St1`: Store vector register contents to memory.
    * Several macro-defined functions for NEON shift operations (e.g., `Rshrn`, `Shl`).
    * `Umov`, `Smov`: Move elements from vector registers to scalar registers.
    * `Tbl`, `Ext`:  Table lookup and extract operations on vector registers.
    * Vector comparison operations: `Cmgt`, `Cmge`, `Cmeq`, `Cmlt`, `Cmle`.

* **Pointer Compression Support:**
    * Functions like `LoadTaggedField`, `StoreTaggedField`, `DecompressTagged`, etc., are crucial for handling V8's pointer compression mechanism, which saves memory by using 32-bit pointers in the heap and decompressing them when needed.

* **Debugging and Assertions:**
    * `AssertPositiveOrZero`: Asserts that a register contains a positive or zero integer (enabled in debug builds).
    * `AssertFPCRState`: Asserts the state of the Floating-Point Control Register (FPCR).

* **System Registers:**
    * `Mrs`, `Msr`:  Read from and write to system registers.

* **Prologue and Epilogue:**
    * `Prologue`: Generates standard function prologue code.

* **Code Object Information:**
    * `ComputeCodeStartAddress`:  Calculates the starting address of the generated code.

**Relationship to JavaScript:**

This header file is fundamental to V8's ability to execute JavaScript. The `MacroAssembler` is used by V8's compilers (TurboFan, Crankshaft, and the interpreter's bytecode handlers) to generate the native machine code that directly executes JavaScript. For example:

```javascript
function add(a, b) {
  return a + b;
}
```

When V8 compiles this JavaScript function, the `MacroAssembler` (and specifically the ARM64 version defined here) would be used to generate ARM64 instructions to:

1. Load the values of `a` and `b` from their locations (registers or stack). (`Ldr`, potentially with address calculations using `Add`)
2. Perform the addition operation. (`Add`)
3. Store the result. (`Str`)
4. Return from the function. (`Ret`)

The `CallJSFunction` method would be used when calling this JavaScript function from other parts of the V8 engine. The pointer compression related functions are used extensively when loading and storing JavaScript objects and values in memory.

**Code Logic Inference (Example with `Switch`):**

**Assumption:** You have a JavaScript `switch` statement like this:

```javascript
function handleCase(value) {
  switch (value) {
    case 10:
      // ... code for case 10 ...
      break;
    case 20:
      // ... code for case 20 ...
      break;
    default:
      // ... default code ...
  }
}
```

**Hypothetical Input:**

* `value` is in register `r0`.
* `case_value_base` is 10 (the starting value of the cases).
* `labels` is an array of labels pointing to the code for each case (case 10, case 20, and default).
* `num_labels` is 3.

**Output:**

The `Switch` method would generate ARM64 assembly code that:

1. Subtracts `case_value_base` (10) from the input `value` in `r0`.
2. Checks if the result is within the bounds of the `labels` array (0 to `num_labels - 2`).
3. If within bounds, it uses the result as an index into the `labels` array to jump to the corresponding case label.
4. If out of bounds, it jumps to the default case label (the last label in the array).

**Common Programming Errors:**

* **Incorrect Stack Alignment:**  The `Push` and `Pop` methods emphasize that the stack pointer must be 16-byte aligned. Failing to maintain this alignment can lead to crashes or unpredictable behavior, especially when dealing with floating-point or vector operations.

   **Example:** Manually manipulating the stack pointer without ensuring 16-byte alignment before calling a function that relies on it.

   ```c++
   // Incorrect manual stack manipulation (example of what NOT to do)
   sub(sp, sp, 8); // Allocate 8 bytes (wrong alignment)
   // ... some operations ...
   add(sp, sp, 8);
   CallBuiltin(Builtin::kSomeFunction); // Might crash if kSomeFunction expects 16-byte alignment
   ```

* **Register Allocation Errors:** Incorrectly managing which registers hold which values can lead to data corruption. For instance, using a register that's expected to hold a specific value for another purpose. The `MaybeSaveRegisters` and `MaybeRestoreRegisters` methods help manage this but developers still need to be careful.

**Summary of Functionality (Part 2):**

This second part of the `macro-assembler-arm64.h` definition significantly expands the instruction generation capabilities, particularly in areas like:

* **More complex stack manipulation:** Efficiently pushing and popping multiple registers with control over link register handling.
* **Advanced control flow:** Providing a `Switch` statement implementation and more granular conditional branching.
* **Extensive arithmetic and logical operations:** Covering a wider range of ARM64 instructions.
* **Comprehensive floating-point support:** Including various conversion, arithmetic, and comparison operations.
* **Introduction of vector (NEON) instructions:** Enabling SIMD processing for performance optimization.
* **Atomic memory operations:** Supporting thread-safe access to memory.
* **Mechanisms for handling V8's internal object representation:**  Including functions for loading and storing tagged pointers and dealing with pointer compression.

In essence, this section builds upon the foundational elements of the `MacroAssembler` to provide the tools needed to implement more sophisticated logic within the V8 engine's code generation pipelines.

### 提示词
```
这是目录为v8/src/codegen/arm64/macro-assembler-arm64.h的一个v8源代码， 请列举一下它的功能, 
如果v8/src/codegen/arm64/macro-assembler-arm64.h以.tq结尾，那它是个v8 torque源代码，
如果它与javascript的功能有关系，请用javascript举例说明,
如果有代码逻辑推理，请给出假设输入与输出，
如果涉及用户常见的编程错误，请举例说明
这是第2部分，共4部分，请归纳一下它的功能
```

### 源代码
```c
st Register& rd, const Register& rn,
                  const Operand& operand);

  // Abort execution if argument is not a positive or zero integer, enabled via
  // --debug-code.
  void AssertPositiveOrZero(Register value) NOOP_UNLESS_DEBUG_CODE;

#define DECLARE_FUNCTION(FN, REGTYPE, REG, OP) \
  inline void FN(const REGTYPE REG, const MemOperand& addr);
      LS_MACRO_LIST(DECLARE_FUNCTION)
#undef DECLARE_FUNCTION

  // Caution: if {value} is a 32-bit negative int, it should be sign-extended
  // to 64-bit before calling this function.
  void Switch(Register scratch, Register value, int case_value_base,
              Label** labels, int num_labels);

  // Push or pop up to 4 registers of the same width to or from the stack.
  //
  // If an argument register is 'NoReg', all further arguments are also assumed
  // to be 'NoReg', and are thus not pushed or popped.
  //
  // Arguments are ordered such that "Push(a, b);" is functionally equivalent
  // to "Push(a); Push(b);".
  //
  // It is valid to push the same register more than once, and there is no
  // restriction on the order in which registers are specified.
  //
  // It is not valid to pop into the same register more than once in one
  // operation, not even into the zero register.
  //
  // The stack pointer must be aligned to 16 bytes on entry and the total size
  // of the specified registers must also be a multiple of 16 bytes.
  //
  // Other than the registers passed into Pop, the stack pointer, (possibly)
  // the system stack pointer and (possibly) the link register, these methods
  // do not modify any other registers.
  //
  // Some of the methods take an optional LoadLRMode or StoreLRMode template
  // argument, which specifies whether we need to sign the link register at the
  // start of the operation, or authenticate it at the end of the operation,
  // when control flow integrity measures are enabled.
  // When the mode is kDontLoadLR or kDontStoreLR, LR must not be passed as an
  // argument to the operation.
  enum LoadLRMode { kAuthLR, kDontLoadLR };
  enum StoreLRMode { kSignLR, kDontStoreLR };
  template <StoreLRMode lr_mode = kDontStoreLR>
  void Push(const CPURegister& src0, const CPURegister& src1 = NoReg,
            const CPURegister& src2 = NoReg, const CPURegister& src3 = NoReg);
  void Push(const CPURegister& src0, const CPURegister& src1,
            const CPURegister& src2, const CPURegister& src3,
            const CPURegister& src4, const CPURegister& src5 = NoReg,
            const CPURegister& src6 = NoReg, const CPURegister& src7 = NoReg);
  template <LoadLRMode lr_mode = kDontLoadLR>
  void Pop(const CPURegister& dst0, const CPURegister& dst1 = NoReg,
           const CPURegister& dst2 = NoReg, const CPURegister& dst3 = NoReg);
  void Pop(const CPURegister& dst0, const CPURegister& dst1,
           const CPURegister& dst2, const CPURegister& dst3,
           const CPURegister& dst4, const CPURegister& dst5 = NoReg,
           const CPURegister& dst6 = NoReg, const CPURegister& dst7 = NoReg);
  template <StoreLRMode lr_mode = kDontStoreLR>
  void Push(const Register& src0, const VRegister& src1);

  void MaybeSaveRegisters(RegList registers);
  void MaybeRestoreRegisters(RegList registers);

  void CallEphemeronKeyBarrier(Register object, Operand offset,
                               SaveFPRegsMode fp_mode);

  void CallIndirectPointerBarrier(Register object, Operand offset,
                                  SaveFPRegsMode fp_mode,
                                  IndirectPointerTag tag);

  void CallRecordWriteStubSaveRegisters(
      Register object, Operand offset, SaveFPRegsMode fp_mode,
      StubCallMode mode = StubCallMode::kCallBuiltinPointer);
  void CallRecordWriteStub(
      Register object, Register slot_address, SaveFPRegsMode fp_mode,
      StubCallMode mode = StubCallMode::kCallBuiltinPointer);

  // For a given |object| and |offset|:
  //   - Move |object| to |dst_object|.
  //   - Compute the address of the slot pointed to by |offset| in |object| and
  //     write it to |dst_slot|.
  // This method makes sure |object| and |offset| are allowed to overlap with
  // the destination registers.
  void MoveObjectAndSlot(Register dst_object, Register dst_slot,
                         Register object, Operand offset);

  // Alternative forms of Push and Pop, taking a RegList or CPURegList that
  // specifies the registers that are to be pushed or popped. Higher-numbered
  // registers are associated with higher memory addresses (as in the A32 push
  // and pop instructions).
  //
  // (Push|Pop)SizeRegList allow you to specify the register size as a
  // parameter. Only kXRegSizeInBits, kWRegSizeInBits, kDRegSizeInBits and
  // kSRegSizeInBits are supported.
  //
  // Otherwise, (Push|Pop)(CPU|X|W|D|S)RegList is preferred.
  void PushCPURegList(CPURegList registers);
  void PopCPURegList(CPURegList registers);

  // Calculate how much stack space (in bytes) are required to store caller
  // registers excluding those specified in the arguments.
  int RequiredStackSizeForCallerSaved(SaveFPRegsMode fp_mode,
                                      Register exclusion) const;

  // Push caller saved registers on the stack, and return the number of bytes
  // stack pointer is adjusted.
  int PushCallerSaved(SaveFPRegsMode fp_mode, Register exclusion = no_reg);

  // Restore caller saved registers from the stack, and return the number of
  // bytes stack pointer is adjusted.
  int PopCallerSaved(SaveFPRegsMode fp_mode, Register exclusion = no_reg);

  // Move an immediate into register dst, and return an Operand object for use
  // with a subsequent instruction that accepts a shift. The value moved into
  // dst is not necessarily equal to imm; it may have had a shifting operation
  // applied to it that will be subsequently undone by the shift applied in the
  // Operand.
  Operand MoveImmediateForShiftedOp(const Register& dst, int64_t imm,
                                    PreShiftImmMode mode);

  void CheckPageFlag(const Register& object, int mask, Condition cc,
                     Label* condition_met);

  void CheckPageFlag(const Register& object, Register scratch, int mask,
                     Condition cc, Label* condition_met) {
    CheckPageFlag(object, mask, cc, condition_met);
  }

  // Compare a register with an operand, and branch to label depending on the
  // condition. May corrupt the status flags.
  inline void CompareAndBranch(const Register& lhs, const Operand& rhs,
                               Condition cond, Label* label);
  inline void CompareTaggedAndBranch(const Register& lhs, const Operand& rhs,
                                     Condition cond, Label* label);

  // Test the bits of register defined by bit_pattern, and branch if ANY of
  // those bits are set. May corrupt the status flags.
  inline void TestAndBranchIfAnySet(const Register& reg,
                                    const uint64_t bit_pattern, Label* label);

  // Test the bits of register defined by bit_pattern, and branch if ALL of
  // those bits are clear (ie. not set.) May corrupt the status flags.
  inline void TestAndBranchIfAllClear(const Register& reg,
                                      const uint64_t bit_pattern, Label* label);

  inline void Brk(int code);

  inline void JumpIfSmi(Register value, Label* smi_label,
                        Label* not_smi_label = nullptr);

  inline void JumpIf(Condition cond, Register x, int32_t y, Label* dest);
  inline void JumpIfEqual(Register x, int32_t y, Label* dest);
  inline void JumpIfLessThan(Register x, int32_t y, Label* dest);
  inline void JumpIfUnsignedLessThan(Register x, int32_t y, Label* dest);

  void JumpIfMarking(Label* is_marking,
                     Label::Distance condition_met_distance = Label::kFar);
  void JumpIfNotMarking(Label* not_marking,
                        Label::Distance condition_met_distance = Label::kFar);

  void LoadMap(Register dst, Register object);
  void LoadCompressedMap(Register dst, Register object);

  void LoadFeedbackVector(Register dst, Register closure, Register scratch,
                          Label* fbv_undef);

  inline void Fmov(VRegister fd, VRegister fn);
  inline void Fmov(VRegister fd, Register rn);
  // Provide explicit double and float interfaces for FP immediate moves, rather
  // than relying on implicit C++ casts. This allows signalling NaNs to be
  // preserved when the immediate matches the format of fd. Most systems convert
  // signalling NaNs to quiet NaNs when converting between float and double.
  inline void Fmov(VRegister fd, double imm);
  inline void Fmov(VRegister fd, float imm);
  // Provide a template to allow other types to be converted automatically.
  template <typename T>
  void Fmov(VRegister fd, T imm) {
    DCHECK(allow_macro_instructions());
    Fmov(fd, static_cast<double>(imm));
  }
  inline void Fmov(Register rd, VRegister fn);

  void Movi(const VRegister& vd, uint64_t imm, Shift shift = LSL,
            int shift_amount = 0);
  void Movi(const VRegister& vd, uint64_t hi, uint64_t lo);

  void LoadFromConstantsTable(Register destination, int constant_index) final;
  void LoadRootRegisterOffset(Register destination, intptr_t offset) final;
  void LoadRootRelative(Register destination, int32_t offset) final;
  void StoreRootRelative(int32_t offset, Register value) final;

  // Operand pointing to an external reference.
  // May emit code to set up the scratch register. The operand is
  // only guaranteed to be correct as long as the scratch register
  // isn't changed.
  // If the operand is used more than once, use a scratch register
  // that is guaranteed not to be clobbered.
  MemOperand ExternalReferenceAsOperand(ExternalReference reference,
                                        Register scratch);
  MemOperand ExternalReferenceAsOperand(IsolateFieldId id) {
    return ExternalReferenceAsOperand(ExternalReference::Create(id), no_reg);
  }

  void Jump(Register target, Condition cond = al);
  void Jump(Address target, RelocInfo::Mode rmode, Condition cond = al);
  void Jump(Handle<Code> code, RelocInfo::Mode rmode, Condition cond = al);
  void Jump(const ExternalReference& reference);

  void Call(Register target);
  void Call(Address target, RelocInfo::Mode rmode);
  void Call(Handle<Code> code, RelocInfo::Mode rmode = RelocInfo::CODE_TARGET);
  void Call(ExternalReference target);

  // Generate an indirect call (for when a direct call's range is not adequate).
  void IndirectCall(Address target, RelocInfo::Mode rmode);

  // Load the builtin given by the Smi in |builtin| into |target|.
  void LoadEntryFromBuiltinIndex(Register builtin, Register target);
  void LoadEntryFromBuiltin(Builtin builtin, Register destination);
  MemOperand EntryFromBuiltinAsOperand(Builtin builtin);
  void CallBuiltinByIndex(Register builtin, Register target);
  void CallBuiltin(Builtin builtin);
  void TailCallBuiltin(Builtin builtin, Condition cond = al);

  // Load code entry point from the Code object.
  void LoadCodeInstructionStart(Register destination, Register code_object,
                                CodeEntrypointTag tag);
  void CallCodeObject(Register code_object, CodeEntrypointTag tag);
  void JumpCodeObject(Register code_object, CodeEntrypointTag tag,
                      JumpMode jump_mode = JumpMode::kJump);

  // Convenience functions to call/jmp to the code of a JSFunction object.
  // TODO(42204201): These don't work properly with leaptiering as we need to
  // validate the parameter count at runtime. Instead, we should replace them
  // with CallJSDispatchEntry that generates a call to a given (compile-time
  // constant) JSDispatchHandle.
  void CallJSFunction(Register function_object, uint16_t argument_count);
  void JumpJSFunction(Register function_object,
                      JumpMode jump_mode = JumpMode::kJump);
  void ResolveWasmCodePointer(Register target);
  void CallWasmCodePointer(Register target,
                           CallJumpMode call_jump_mode = CallJumpMode::kCall);
  void LoadWasmCodePointer(Register dst, MemOperand src);

  // Generates an instruction sequence s.t. the return address points to the
  // instruction following the call.
  // The return address on the stack is used by frame iteration.
  void StoreReturnAddressAndCall(Register target);

  void BailoutIfDeoptimized();
  void CallForDeoptimization(Builtin target, int deopt_id, Label* exit,
                             DeoptimizeKind kind, Label* ret,
                             Label* jump_deoptimization_entry_label);

  // Calls a C function and cleans up the space for arguments allocated
  // by PrepareCallCFunction. The called function is not allowed to trigger a
  // garbage collection, since that might move the code and invalidate the
  // return address (unless this is somehow accounted for by the called
  // function).
  int CallCFunction(
      ExternalReference function, int num_reg_arguments,
      SetIsolateDataSlots set_isolate_data_slots = SetIsolateDataSlots::kYes,
      Label* return_location = nullptr);
  int CallCFunction(
      ExternalReference function, int num_reg_arguments,
      int num_double_arguments,
      SetIsolateDataSlots set_isolate_data_slots = SetIsolateDataSlots::kYes,
      Label* return_location = nullptr);
  int CallCFunction(
      Register function, int num_reg_arguments, int num_double_arguments,
      SetIsolateDataSlots set_isolate_data_slots = SetIsolateDataSlots::kYes,
      Label* return_location = nullptr);

  // Performs a truncating conversion of a floating point number as used by
  // the JS bitwise operations. See ECMA-262 9.5: ToInt32.
  // Exits with 'result' holding the answer.
  void TruncateDoubleToI(Isolate* isolate, Zone* zone, Register result,
                         DoubleRegister double_input, StubCallMode stub_mode,
                         LinkRegisterStatus lr_status);

  inline void Mul(const Register& rd, const Register& rn, const Register& rm);

  inline void Fcvtzs(const Register& rd, const VRegister& fn);
  void Fcvtzs(const VRegister& vd, const VRegister& vn, int fbits = 0) {
    DCHECK(allow_macro_instructions());
    fcvtzs(vd, vn, fbits);
  }

  void Fjcvtzs(const Register& rd, const VRegister& vn) {
    DCHECK(allow_macro_instructions());
    DCHECK(!rd.IsZero());
    fjcvtzs(rd, vn);
  }

  inline void Fcvtzu(const Register& rd, const VRegister& fn);
  void Fcvtzu(const VRegister& vd, const VRegister& vn, int fbits = 0) {
    DCHECK(allow_macro_instructions());
    fcvtzu(vd, vn, fbits);
  }

  inline void Madd(const Register& rd, const Register& rn, const Register& rm,
                   const Register& ra);
  inline void Mneg(const Register& rd, const Register& rn, const Register& rm);
  inline void Sdiv(const Register& rd, const Register& rn, const Register& rm);
  inline void Udiv(const Register& rd, const Register& rn, const Register& rm);
  inline void Msub(const Register& rd, const Register& rn, const Register& rm,
                   const Register& ra);

  inline void Lsl(const Register& rd, const Register& rn, unsigned shift);
  inline void Lsl(const Register& rd, const Register& rn, const Register& rm);
  inline void Umull(const Register& rd, const Register& rn, const Register& rm);
  inline void Umulh(const Register& rd, const Register& rn, const Register& rm);
  inline void Smull(const Register& rd, const Register& rn, const Register& rm);
  inline void Smulh(const Register& rd, const Register& rn, const Register& rm);

  inline void Sxtb(const Register& rd, const Register& rn);
  inline void Sxth(const Register& rd, const Register& rn);
  inline void Sxtw(const Register& rd, const Register& rn);
  inline void Ubfiz(const Register& rd, const Register& rn, unsigned lsb,
                    unsigned width);
  inline void Sbfiz(const Register& rd, const Register& rn, unsigned lsb,
                    unsigned width);
  inline void Ubfx(const Register& rd, const Register& rn, unsigned lsb,
                   unsigned width);
  inline void Lsr(const Register& rd, const Register& rn, unsigned shift);
  inline void Lsr(const Register& rd, const Register& rn, const Register& rm);
  inline void Ror(const Register& rd, const Register& rs, unsigned shift);
  inline void Ror(const Register& rd, const Register& rn, const Register& rm);
  inline void Cmn(const Register& rn, const Operand& operand);
  inline void Fadd(const VRegister& fd, const VRegister& fn,
                   const VRegister& fm);
  inline void Fcmp(const VRegister& fn, const VRegister& fm);
  inline void Fcmp(const VRegister& fn, double value);
  inline void Fabs(const VRegister& fd, const VRegister& fn);
  inline void Fmul(const VRegister& fd, const VRegister& fn,
                   const VRegister& fm);
  inline void Fsub(const VRegister& fd, const VRegister& fn,
                   const VRegister& fm);
  inline void Fdiv(const VRegister& fd, const VRegister& fn,
                   const VRegister& fm);
  inline void Fmax(const VRegister& fd, const VRegister& fn,
                   const VRegister& fm);
  inline void Fmin(const VRegister& fd, const VRegister& fn,
                   const VRegister& fm);
  inline void Rbit(const Register& rd, const Register& rn);
  inline void Rev(const Register& rd, const Register& rn);

  enum AdrHint {
    // The target must be within the immediate range of adr.
    kAdrNear,
    // The target may be outside of the immediate range of adr. Additional
    // instructions may be emitted.
    kAdrFar
  };
  void Adr(const Register& rd, Label* label, AdrHint = kAdrNear);

  // Add/sub with carry macros.
  inline void Adc(const Register& rd, const Register& rn,
                  const Operand& operand);

  // Conditional macros.
  inline void Ccmp(const Register& rn, const Operand& operand, StatusFlags nzcv,
                   Condition cond);
  inline void CcmpTagged(const Register& rn, const Operand& operand,
                         StatusFlags nzcv, Condition cond);
  inline void Ccmn(const Register& rn, const Operand& operand, StatusFlags nzcv,
                   Condition cond);

  inline void Clz(const Register& rd, const Register& rn);

  // Poke 'src' onto the stack. The offset is in bytes. The stack pointer must
  // be 16 byte aligned.
  // When the optional template argument is kSignLR and control flow integrity
  // measures are enabled, we sign the link register before poking it onto the
  // stack. 'src' must be lr in this case.
  template <StoreLRMode lr_mode = kDontStoreLR>
  void Poke(const CPURegister& src, const Operand& offset);

  // Peek at a value on the stack, and put it in 'dst'. The offset is in bytes.
  // The stack pointer must be aligned to 16 bytes.
  // When the optional template argument is kAuthLR and control flow integrity
  // measures are enabled, we authenticate the link register after peeking the
  // value. 'dst' must be lr in this case.
  template <LoadLRMode lr_mode = kDontLoadLR>
  void Peek(const CPURegister& dst, const Operand& offset);

  // Poke 'src1' and 'src2' onto the stack. The values written will be adjacent
  // with 'src2' at a higher address than 'src1'. The offset is in bytes. The
  // stack pointer must be 16 byte aligned.
  void PokePair(const CPURegister& src1, const CPURegister& src2, int offset);

  inline void Sbfx(const Register& rd, const Register& rn, unsigned lsb,
                   unsigned width);

  inline void Bfi(const Register& rd, const Register& rn, unsigned lsb,
                  unsigned width);

  inline void Scvtf(const VRegister& fd, const Register& rn,
                    unsigned fbits = 0);
  void Scvtf(const VRegister& vd, const VRegister& vn, int fbits = 0) {
    DCHECK(allow_macro_instructions());
    scvtf(vd, vn, fbits);
  }
  inline void Ucvtf(const VRegister& fd, const Register& rn,
                    unsigned fbits = 0);
  void Ucvtf(const VRegister& vd, const VRegister& vn, int fbits = 0) {
    DCHECK(allow_macro_instructions());
    ucvtf(vd, vn, fbits);
  }

  void AssertFPCRState(Register fpcr = NoReg) NOOP_UNLESS_DEBUG_CODE;
  void CanonicalizeNaN(const VRegister& dst, const VRegister& src);
  void CanonicalizeNaN(const VRegister& reg) { CanonicalizeNaN(reg, reg); }

  inline void CmovX(const Register& rd, const Register& rn, Condition cond);
  inline void Cset(const Register& rd, Condition cond);
  inline void Csetm(const Register& rd, Condition cond);
  inline void Fccmp(const VRegister& fn, const VRegister& fm, StatusFlags nzcv,
                    Condition cond);
  inline void Fccmp(const VRegister& fn, const double value, StatusFlags nzcv,
                    Condition cond);
  inline void Csinc(const Register& rd, const Register& rn, const Register& rm,
                    Condition cond);

  inline void Fcvt(const VRegister& fd, const VRegister& fn);

  int ActivationFrameAlignment();

  void Ins(const VRegister& vd, int vd_index, const VRegister& vn,
           int vn_index) {
    DCHECK(allow_macro_instructions());
    ins(vd, vd_index, vn, vn_index);
  }
  void Ins(const VRegister& vd, int vd_index, const Register& rn) {
    DCHECK(allow_macro_instructions());
    ins(vd, vd_index, rn);
  }

  inline void Bl(Label* label);
  inline void Br(const Register& xn);

  inline void Uxtb(const Register& rd, const Register& rn);
  inline void Uxth(const Register& rd, const Register& rn);
  inline void Uxtw(const Register& rd, const Register& rn);

  void Dup(const VRegister& vd, const VRegister& vn, int index) {
    DCHECK(allow_macro_instructions());
    dup(vd, vn, index);
  }
  void Dup(const VRegister& vd, const Register& rn) {
    DCHECK(allow_macro_instructions());
    dup(vd, rn);
  }

#define DECLARE_FUNCTION(FN, REGTYPE, REG, REG2, OP) \
  inline void FN(const REGTYPE REG, const REGTYPE REG2, const MemOperand& addr);
  LSPAIR_MACRO_LIST(DECLARE_FUNCTION)
#undef DECLARE_FUNCTION

  void St1(const VRegister& vt, const MemOperand& dst) {
    DCHECK(allow_macro_instructions());
    st1(vt, dst);
  }
  void St1(const VRegister& vt, const VRegister& vt2, const MemOperand& dst) {
    DCHECK(allow_macro_instructions());
    st1(vt, vt2, dst);
  }
  void St1(const VRegister& vt, const VRegister& vt2, const VRegister& vt3,
           const MemOperand& dst) {
    DCHECK(allow_macro_instructions());
    st1(vt, vt2, vt3, dst);
  }
  void St1(const VRegister& vt, const VRegister& vt2, const VRegister& vt3,
           const VRegister& vt4, const MemOperand& dst) {
    DCHECK(allow_macro_instructions());
    st1(vt, vt2, vt3, vt4, dst);
  }
  void St1(const VRegister& vt, int lane, const MemOperand& dst) {
    DCHECK(allow_macro_instructions());
    st1(vt, lane, dst);
  }

#define NEON_2VREG_SHIFT_MACRO_LIST(V) \
  V(rshrn, Rshrn)                      \
  V(rshrn2, Rshrn2)                    \
  V(shl, Shl)                          \
  V(shll, Shll)                        \
  V(shll2, Shll2)                      \
  V(shrn, Shrn)                        \
  V(shrn2, Shrn2)                      \
  V(sli, Sli)                          \
  V(sqrshrn, Sqrshrn)                  \
  V(sqrshrn2, Sqrshrn2)                \
  V(sqrshrun, Sqrshrun)                \
  V(sqrshrun2, Sqrshrun2)              \
  V(sqshl, Sqshl)                      \
  V(sqshlu, Sqshlu)                    \
  V(sqshrn, Sqshrn)                    \
  V(sqshrn2, Sqshrn2)                  \
  V(sqshrun, Sqshrun)                  \
  V(sqshrun2, Sqshrun2)                \
  V(sri, Sri)                          \
  V(srshr, Srshr)                      \
  V(srsra, Srsra)                      \
  V(sshll, Sshll)                      \
  V(sshll2, Sshll2)                    \
  V(sshr, Sshr)                        \
  V(ssra, Ssra)                        \
  V(uqrshrn, Uqrshrn)                  \
  V(uqrshrn2, Uqrshrn2)                \
  V(uqshl, Uqshl)                      \
  V(uqshrn, Uqshrn)                    \
  V(uqshrn2, Uqshrn2)                  \
  V(urshr, Urshr)                      \
  V(ursra, Ursra)                      \
  V(ushll, Ushll)                      \
  V(ushll2, Ushll2)                    \
  V(ushr, Ushr)                        \
  V(usra, Usra)

#define DEFINE_MACRO_ASM_FUNC(ASM, MASM)                           \
  void MASM(const VRegister& vd, const VRegister& vn, int shift) { \
    DCHECK(allow_macro_instructions());                            \
    ASM(vd, vn, shift);                                            \
  }
  NEON_2VREG_SHIFT_MACRO_LIST(DEFINE_MACRO_ASM_FUNC)
#undef DEFINE_MACRO_ASM_FUNC

  void Umov(const Register& rd, const VRegister& vn, int vn_index) {
    DCHECK(allow_macro_instructions());
    umov(rd, vn, vn_index);
  }
  void Tbl(const VRegister& vd, const VRegister& vn, const VRegister& vm) {
    DCHECK(allow_macro_instructions());
    tbl(vd, vn, vm);
  }
  void Tbl(const VRegister& vd, const VRegister& vn, const VRegister& vn2,
           const VRegister& vm) {
    DCHECK(allow_macro_instructions());
    tbl(vd, vn, vn2, vm);
  }
  void Tbl(const VRegister& vd, const VRegister& vn, const VRegister& vn2,
           const VRegister& vn3, const VRegister& vm) {
    DCHECK(allow_macro_instructions());
    tbl(vd, vn, vn2, vn3, vm);
  }
  void Tbl(const VRegister& vd, const VRegister& vn, const VRegister& vn2,
           const VRegister& vn3, const VRegister& vn4, const VRegister& vm) {
    DCHECK(allow_macro_instructions());
    tbl(vd, vn, vn2, vn3, vn4, vm);
  }
  void Ext(const VRegister& vd, const VRegister& vn, const VRegister& vm,
           int index) {
    DCHECK(allow_macro_instructions());
    ext(vd, vn, vm, index);
  }

  void Smov(const Register& rd, const VRegister& vn, int vn_index) {
    DCHECK(allow_macro_instructions());
    smov(rd, vn, vn_index);
  }

// Load-acquire/store-release macros.
#define DECLARE_FUNCTION(FN, OP) \
  inline void FN(const Register& rt, const Register& rn);
  LDA_STL_MACRO_LIST(DECLARE_FUNCTION)
#undef DECLARE_FUNCTION

#define DECLARE_FUNCTION(FN, OP) \
  inline void FN(const Register& rs, const Register& rt, const MemOperand& src);
  CAS_SINGLE_MACRO_LIST(DECLARE_FUNCTION)
#undef DECLARE_FUNCTION

#define DECLARE_FUNCTION(FN, OP)                                              \
  inline void FN(const Register& rs, const Register& rs2, const Register& rt, \
                 const Register& rt2, const MemOperand& src);
  CAS_PAIR_MACRO_LIST(DECLARE_FUNCTION)
#undef DECLARE_FUNCTION

#define DECLARE_LOAD_FUNCTION(FN, OP) \
  inline void FN(const Register& rs, const Register& rt, const MemOperand& src);
#define DECLARE_STORE_FUNCTION(FN, OP) \
  inline void FN(const Register& rs, const MemOperand& src);

  ATOMIC_MEMORY_SIMPLE_MACRO_LIST(ATOMIC_MEMORY_LOAD_MACRO_MODES,
                                  DECLARE_LOAD_FUNCTION, Ld, ld)
  ATOMIC_MEMORY_SIMPLE_MACRO_LIST(ATOMIC_MEMORY_STORE_MACRO_MODES,
                                  DECLARE_STORE_FUNCTION, St, st)

#define DECLARE_SWP_FUNCTION(FN, OP) \
  inline void FN(const Register& rs, const Register& rt, const MemOperand& src);

  ATOMIC_MEMORY_LOAD_MACRO_MODES(DECLARE_SWP_FUNCTION, Swp, swp)

#undef DECLARE_LOAD_FUNCTION
#undef DECLARE_STORE_FUNCTION
#undef DECLARE_SWP_FUNCTION

  // Load an object from the root table.
  void LoadRoot(Register destination, RootIndex index) final;
  void LoadTaggedRoot(Register destination, RootIndex index);
  void PushRoot(RootIndex index);

  inline void Ret(const Register& xn = lr);

  // Perform a conversion from a double to a signed int64. If the input fits in
  // range of the 64-bit result, execution branches to done. Otherwise,
  // execution falls through, and the sign of the result can be used to
  // determine if overflow was towards positive or negative infinity.
  //
  // On successful conversion, the least significant 32 bits of the result are
  // equivalent to the ECMA-262 operation "ToInt32".
  void TryConvertDoubleToInt64(Register result, DoubleRegister input,
                               Label* done);

  inline void Mrs(const Register& rt, SystemRegister sysreg);
  inline void Msr(SystemRegister sysreg, const Register& rt);

  // Prologue claims an extra slot due to arm64's alignement constraints.
  static constexpr int kExtraSlotClaimedByPrologue = 1;
  // Generates function prologue code.
  void Prologue();

  void Cmgt(const VRegister& vd, const VRegister& vn, int imm) {
    DCHECK(allow_macro_instructions());
    cmgt(vd, vn, imm);
  }
  void Cmge(const VRegister& vd, const VRegister& vn, int imm) {
    DCHECK(allow_macro_instructions());
    cmge(vd, vn, imm);
  }
  void Cmeq(const VRegister& vd, const VRegister& vn, int imm) {
    DCHECK(allow_macro_instructions());
    cmeq(vd, vn, imm);
  }
  void Cmlt(const VRegister& vd, const VRegister& vn, int imm) {
    DCHECK(allow_macro_instructions());
    cmlt(vd, vn, imm);
  }
  void Cmle(const VRegister& vd, const VRegister& vn, int imm) {
    DCHECK(allow_macro_instructions());
    cmle(vd, vn, imm);
  }

  inline void Neg(const Register& rd, const Operand& operand);
  inline void Negs(const Register& rd, const Operand& operand);

  // Compute rd = abs(rm).
  // This function clobbers the condition flags. On output the overflow flag is
  // set iff the negation overflowed.
  //
  // If rm is the minimum representable value, the result is not representable.
  // Handlers for each case can be specified using the relevant labels.
  void Abs(const Register& rd, const Register& rm,
           Label* is_not_representable = nullptr,
           Label* is_representable = nullptr);

  inline void Cls(const Register& rd, const Register& rn);
  inline void Cneg(const Register& rd, const Register& rn, Condition cond);
  inline void Rev16(const Register& rd, const Register& rn);
  inline void Rev32(const Register& rd, const Register& rn);
  inline void Fcvtns(const Register& rd, const VRegister& fn);
  inline void Fcvtnu(const Register& rd, const VRegister& fn);
  inline void Fcvtms(const Register& rd, const VRegister& fn);
  inline void Fcvtmu(const Register& rd, const VRegister& fn);
  inline void Fcvtas(const Register& rd, const VRegister& fn);
  inline void Fcvtau(const Register& rd, const VRegister& fn);

  // Compute the start of the generated instruction stream from the current PC.
  // This is an alternative to embedding the {CodeObject} handle as a reference.
  void ComputeCodeStartAddress(const Register& rd);

  // ---------------------------------------------------------------------------
  // Pointer compression Support

  // Loads a field containing any tagged value and decompresses it if necessary.
  void LoadTaggedField(const Register& destination,
                       const MemOperand& field_operand);

  // Loads a field containing any tagged value but never decompresses it.
  void LoadTaggedFieldWithoutDecompressing(const Register& destination,
                                           const MemOperand& field_operand);

  // Loads a field containing a tagged signed value and decompresses it if
  // necessary.
  void LoadTaggedSignedField(const Register& destination,
                             const MemOperand& field_operand);

  // Loads a field containing smi value and untags it.
  void SmiUntagField(Register dst, const MemOperand& src);

  // Compresses and stores tagged value to given on-heap location.
  void StoreTaggedField(const Register& value,
                        const MemOperand& dst_field_operand);
  void StoreTwoTaggedFields(const Register& value,
                            const MemOperand& dst_field_operand);

  // For compatibility with platform-independent code.
  void StoreTaggedField(const MemOperand& dst_field_operand,
                        const Register& value) {
    StoreTaggedField(value, dst_field_operand);
  }

  void AtomicStoreTaggedField(const Register& value, const Register& dst_base,
                              const Register& dst_index, const Register& temp);

  void DecompressTaggedSigned(const Register& destination,
                              const MemOperand& field_operand);
  void DecompressTagged(const Register& destination,
                        const MemOperand& field_operand);
  void DecompressTagged(const Register& destination, const Register& source);
  void DecompressTagged(const Register& destination, Tagged_t immediate);
  void DecompressProtected(const Register& destination,
                           const MemOperand& field_operand);

  void AtomicDecompressTaggedSigned(const Register& destination,
                                    const Register& base, const Register& index,
                                    const Register& temp);
  void AtomicDecompressTagged(const Register& destination, const Register& base,
                              const Register& index, c
```