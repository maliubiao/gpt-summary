Response:
The user wants a summary of the provided C++ code snippet, which is part of the V8 JavaScript engine. I need to identify the key functionalities of this code. The prompt also includes specific instructions related to `.tq` files, JavaScript examples, logic reasoning with inputs/outputs, and common programming errors. However, since this is the first part of a larger code file, the focus should be on summarizing the functionalities present in *this* specific part.

Here's a breakdown of what this code snippet seems to handle:

1. **Maglev IR (Intermediate Representation):** The file name and the presence of classes like `Phi`, `BasicBlock`, and nodes like `Call`, `Construct`, `LoadField` suggest that this code defines the structure and operations of an intermediate representation used within the Maglev compiler.

2. **Node Definitions:**  It defines various node types (`Phi`, `InitialValue`, `RootConstant`, `Call`, etc.) representing different operations or values within the IR. Each node likely has properties like opcode, inputs, and output.

3. **Graph Structure:**  The presence of `BasicBlock` and connections between nodes suggests that the IR is represented as a graph.

4. **Data Flow and Types:** The code includes logic for managing data flow, including value representations (`ValueRepresentation`), and checks for input types.

5. **Deoptimization:**  The presence of `DeoptInfo` and related structures indicates support for deoptimization, a process of reverting from optimized code to interpreted bytecode.

6. **Constant Handling:**  The code has specific node types and logic for handling constants.

7. **Debugging and Printing:**  There are functions for printing the IR graph, which is helpful for debugging.

8. **Virtual Objects:** The `VirtualObject` class and related logic suggest support for representing objects that haven't been fully allocated in memory yet.

9. **Register Allocation Hints:** The code mentions setting hints for register allocation.

Based on this analysis, I can now formulate a concise summary of the functionality in this first part.
è¿™æ˜¯ä¸€ä¸ªV8æºä»£ç æ–‡ä»¶ `v8/src/maglev/maglev-ir.cc` çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå®ƒå®šä¹‰äº† **Maglevç¼–è¯‘å™¨çš„ä¸­é—´è¡¨ç¤º (IR)** çš„æ ¸å¿ƒç»“æ„å’ŒåŠŸèƒ½ã€‚

ä»¥ä¸‹æ˜¯è¿™ä¸ªæ–‡ä»¶ç‰‡æ®µçš„ä¸»è¦åŠŸèƒ½å½’çº³ï¼š

1. **å®šä¹‰äº† Maglev IR çš„åŸºæœ¬å…ƒç´ :**
   - åŒ…å«äº†å„ç§ **èŠ‚ç‚¹ (Node)** çš„å®šä¹‰ï¼Œä¾‹å¦‚ `Phi` (ç”¨äºåˆå¹¶æ§åˆ¶æµ)ã€`Call` (å‡½æ•°è°ƒç”¨)ã€`Construct` (å¯¹è±¡æ„é€ )ã€`LoadField` (åŠ è½½å­—æ®µ) ç­‰ã€‚è¿™äº›èŠ‚ç‚¹ä»£è¡¨äº† Maglev ç¼–è¯‘å™¨åœ¨ä¼˜åŒ– JavaScript ä»£ç æ—¶ä½¿ç”¨çš„æ“ä½œã€‚
   - å®šä¹‰äº† **åŸºæœ¬å— (BasicBlock)**ï¼Œå®ƒæ˜¯ IR å›¾ä¸­çš„ä¸€ä¸ªæ‰§è¡Œå•å…ƒï¼ŒåŒ…å«ä¸€ç³»åˆ—é¡ºåºæ‰§è¡Œçš„èŠ‚ç‚¹ã€‚
   - å®šä¹‰äº† **è¾“å…¥ (Input)**ï¼Œç”¨äºè¿æ¥èŠ‚ç‚¹ï¼Œè¡¨ç¤ºæ•°æ®ä¾èµ–å…³ç³»ã€‚
   - å®šä¹‰äº† **å€¼è¡¨ç¤º (ValueRepresentation)**ï¼Œç”¨äºè¡¨ç¤ºä¸åŒç±»å‹çš„å€¼åœ¨ IR ä¸­çš„è¡¨ç¤ºå½¢å¼ï¼Œä¾‹å¦‚ `Tagged` (V8 å¯¹è±¡), `Int32`, `Float64` ç­‰ã€‚

2. **æä¾›äº†æ“ä½œç  (Opcode) çš„å®šä¹‰å’Œå­—ç¬¦ä¸²è¡¨ç¤º:**
   - ä½¿ç”¨ `enum class Opcode` å®šä¹‰äº†å„ç§ IR èŠ‚ç‚¹çš„æ“ä½œç ã€‚
   - `OpcodeToString` å‡½æ•°å¯ä»¥å°†æ“ä½œç è½¬æ¢ä¸ºå¯è¯»çš„å­—ç¬¦ä¸²ï¼Œç”¨äºè°ƒè¯•å’Œæ—¥å¿—è¾“å‡ºã€‚

3. **å®ç°äº† `Phi` èŠ‚ç‚¹çš„ç‰¹æ®ŠåŠŸèƒ½:**
   - `Phi` èŠ‚ç‚¹ç”¨äºåœ¨æ§åˆ¶æµåˆå¹¶ç‚¹æ±‡èšæ¥è‡ªä¸åŒè·¯å¾„çš„å€¼ã€‚
   - åŒ…å«äº†åˆ¤æ–­æ˜¯å¦ä¸ºå¾ªç¯ `Phi` èŠ‚ç‚¹ (`is_loop_phi`) å’Œæœªåˆå¹¶å¾ªç¯ `Phi` èŠ‚ç‚¹ (`is_unmerged_loop_phi`) çš„æ–¹æ³•ã€‚
   - å®ç°äº†è®°å½• `Phi` èŠ‚ç‚¹ä½¿ç”¨è¡¨ç¤ºæç¤º (`RecordUseReprHint`) å’Œéœ€è¦ 31 ä½å€¼ (`SetUseRequires31BitValue`) çš„åŠŸèƒ½ï¼Œè¿™ä¸ä¼˜åŒ–å’Œç±»å‹æ¨æ–­æœ‰å…³ã€‚

4. **å®šä¹‰äº†å¸¸é‡çš„è¡¨ç¤º:**
   - åŒ…å«äº†å„ç§å¸¸é‡èŠ‚ç‚¹ç±»å‹ï¼Œå¦‚ `SmiConstant` (å°æ•´æ•°å¸¸é‡)ã€`Int32Constant`ã€`Float64Constant`ã€`RootConstant` (æŒ‡å‘ V8 æ ¹å¯¹è±¡çš„å¸¸é‡) ç­‰ã€‚
   - æä¾›äº†å°†å¸¸é‡èŠ‚ç‚¹ç‰©åŒ–çš„æ–¹æ³• `Reify`ï¼Œå¯ä»¥å°† IR ä¸­çš„å¸¸é‡è¡¨ç¤ºè½¬æ¢ä¸º V8 çš„ `Handle<Object>`ã€‚

5. **æ”¯æŒåä¼˜åŒ– (Deoptimization):**
   - å®šä¹‰äº† `DeoptInfo` å’Œ `LazyDeoptInfo`ï¼Œç”¨äºå­˜å‚¨åä¼˜åŒ–æ‰€éœ€çš„ä¿¡æ¯ï¼Œä¾‹å¦‚åä¼˜åŒ–æ—¶çš„å¸§çŠ¶æ€ã€‚
   - å®šä¹‰äº† `InterpretedDeoptFrame`ï¼Œç”¨äºæè¿°è§£é‡Šå™¨å¸§çš„åä¼˜åŒ–çŠ¶æ€ã€‚
   - åŒ…å«äº†è®¡ç®—è¿”å›åç§»é‡ (`ComputeReturnOffset`) ç­‰ä¸åä¼˜åŒ–ç›¸å…³çš„åŠŸèƒ½ã€‚

6. **å®ç°äº†èŠ‚ç‚¹çš„æ‰“å°åŠŸèƒ½:**
   - æä¾›äº† `Print` æ–¹æ³•ï¼Œå¯ä»¥å°† IR èŠ‚ç‚¹çš„ä¿¡æ¯æ‰“å°å‡ºæ¥ï¼ŒåŒ…æ‹¬æ“ä½œç ã€è¾“å…¥ã€è¾“å‡ºå’Œç›®æ ‡å—ç­‰ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œç†è§£ IR ç»“æ„ã€‚

7. **å®ç°äº†è¾“å…¥éªŒè¯:**
   - æä¾›äº† `VerifyInputs` æ–¹æ³•ï¼Œç”¨äºåœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ£€æŸ¥èŠ‚ç‚¹çš„è¾“å…¥æ˜¯å¦ç¬¦åˆé¢„æœŸçš„æ•°æ®ç±»å‹æˆ–æ“ä½œç ï¼Œæœ‰åŠ©äºå‘ç° IR æ„å»ºè¿‡ç¨‹ä¸­çš„é”™è¯¯ã€‚

8. **å®šä¹‰äº†è™šæ‹Ÿå¯¹è±¡ (VirtualObject):**
   - `VirtualObject` ç”¨äºè¡¨ç¤ºåœ¨ä»£ç ç”Ÿæˆé˜¶æ®µå°šæœªå®Œå…¨åˆ†é…å†…å­˜çš„å¯¹è±¡ï¼Œè¿™æ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ã€‚
   - æä¾›äº†è®¡ç®—è™šæ‹Ÿå¯¹è±¡æ‰€éœ€è¾“å…¥ä½ç½®å¤§å° (`InputLocationSizeNeeded`) ç­‰åŠŸèƒ½ã€‚

**å…³äºæ‚¨æå‡ºçš„å…¶ä»–é—®é¢˜ï¼š**

* **`.tq` ç»“å°¾ï¼š**  æ­£å¦‚æ‚¨æ‰€è¯´ï¼Œå¦‚æœ `v8/src/maglev/maglev-ir.cc` ä»¥ `.tq` ç»“å°¾ï¼Œé‚£å®ƒå°†æ˜¯ä¸€ä¸ª V8 Torque æºä»£ç ã€‚ä½†ç›®å‰çš„æ–‡ä»¶åæ˜¯ `.cc`ï¼Œæ‰€ä»¥å®ƒæ˜¯ **C++ æºä»£ç **ã€‚

* **ä¸ JavaScript åŠŸèƒ½çš„å…³ç³»ï¼š**  `maglev-ir.cc` ä¸­å®šä¹‰çš„ IR èŠ‚ç‚¹ç›´æ¥å¯¹åº”ç€ JavaScript ä»£ç ä¸­çš„å„ç§æ“ä½œå’Œç»“æ„ã€‚ä¾‹å¦‚ï¼š
   ```javascript
   function add(a, b) {
     return a + b;
   }
   ```
   è¿™æ®µç®€å•çš„ JavaScript ä»£ç åœ¨ Maglev ç¼–è¯‘å™¨ä¸­å¯èƒ½ä¼šè¢«è¡¨ç¤ºä¸ºåŒ…å« `LoadLocalVariable` èŠ‚ç‚¹ï¼ˆåŠ è½½ `a` å’Œ `b`ï¼‰ï¼Œ`Add` èŠ‚ç‚¹ï¼ˆæ‰§è¡ŒåŠ æ³•ï¼‰ï¼Œå’Œ `Return` èŠ‚ç‚¹çš„ IR å›¾ã€‚ `Call` å’Œ `Construct` èŠ‚ç‚¹åˆ™åˆ†åˆ«å¯¹åº” JavaScript ä¸­çš„å‡½æ•°è°ƒç”¨å’Œ `new` æ“ä½œã€‚

* **ä»£ç é€»è¾‘æ¨ç† (å‡è®¾è¾“å…¥ä¸è¾“å‡º):**
   ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ª `Add` èŠ‚ç‚¹ï¼š
   - **å‡è®¾è¾“å…¥ï¼š** ä¸¤ä¸ª `Int32Constant` èŠ‚ç‚¹ï¼Œåˆ†åˆ«è¡¨ç¤ºæ•´æ•° 5 å’Œ 10ã€‚
   - **è¾“å‡ºï¼š** ä¸€ä¸ªæ–°çš„ `Int32Constant` èŠ‚ç‚¹ï¼Œè¡¨ç¤ºæ•´æ•° 15ã€‚
   æ›´å¤æ‚çš„é€»è¾‘æ¨ç†ä¼šæ¶‰åŠåˆ°æ§åˆ¶æµå’Œ `Phi` èŠ‚ç‚¹ï¼Œä¾‹å¦‚åœ¨ `if-else` è¯­å¥ä¸­ï¼Œ`Phi` èŠ‚ç‚¹ä¼šæ ¹æ®æ¡ä»¶é€‰æ‹©ä¸åŒçš„è¾“å…¥å€¼ã€‚

* **ç”¨æˆ·å¸¸è§çš„ç¼–ç¨‹é”™è¯¯ï¼š**
   è™½ç„¶è¿™ä¸ª C++ æ–‡ä»¶æœ¬èº«ä¸ç›´æ¥æ¶‰åŠç”¨æˆ·ç¼–å†™çš„ JavaScript ä»£ç ï¼Œä½†å®ƒåœ¨å†…éƒ¨å¤„ç† JavaScript ä»£ç çš„è¡¨ç¤ºå’Œä¼˜åŒ–ã€‚  å¦‚æœ Maglev ç¼–è¯‘å™¨åœ¨æ„å»º IR æ—¶å‡ºç°é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œå‡è®¾äº†é”™è¯¯çš„ç±»å‹ä¿¡æ¯ï¼‰ï¼Œè¿™å¯èƒ½æºäº V8 å¼•æ“æœ¬èº«å¯¹æŸäº› JavaScript æ¨¡å¼çš„å¤„ç†ä¸å½“ï¼Œæˆ–è€…ç”¨æˆ·ç¼–å†™äº†å¯¼è‡´ç±»å‹æ¨æ–­å›°éš¾çš„ JavaScript ä»£ç ã€‚ ä¾‹å¦‚ï¼Œè¿‡åº¦ä½¿ç”¨åŠ¨æ€ç±»å‹å¯èƒ½ä¼šä½¿ç¼–è¯‘å™¨éš¾ä»¥è¿›è¡Œæœ‰æ•ˆçš„ä¼˜åŒ–ã€‚

**æ€»ç»“ä¸€ä¸‹ï¼Œ`v8/src/maglev/maglev-ir.cc` çš„ç¬¬ä¸€éƒ¨åˆ†ä¸º Maglev ç¼–è¯‘å™¨çš„ä¸­é—´è¡¨ç¤ºæä¾›äº†åŸºç¡€çš„å®šä¹‰å’ŒåŠŸèƒ½ï¼Œå®ƒæ˜¯ Maglev ç¼–è¯‘å™¨ç†è§£å’Œä¼˜åŒ– JavaScript ä»£ç çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚**

### æç¤ºè¯
```
è¿™æ˜¯ç›®å½•ä¸ºv8/src/maglev/maglev-ir.ccçš„ä¸€ä¸ªv8æºä»£ç ï¼Œ è¯·åˆ—ä¸¾ä¸€ä¸‹å®ƒçš„åŠŸèƒ½, 
å¦‚æœv8/src/maglev/maglev-ir.ccä»¥.tqç»“å°¾ï¼Œé‚£å®ƒæ˜¯ä¸ªv8 torqueæºä»£ç ï¼Œ
å¦‚æœå®ƒä¸javascriptçš„åŠŸèƒ½æœ‰å…³ç³»ï¼Œè¯·ç”¨javascriptä¸¾ä¾‹è¯´æ˜,
å¦‚æœæœ‰ä»£ç é€»è¾‘æ¨ç†ï¼Œè¯·ç»™å‡ºå‡è®¾è¾“å…¥ä¸è¾“å‡ºï¼Œ
å¦‚æœæ¶‰åŠç”¨æˆ·å¸¸è§çš„ç¼–ç¨‹é”™è¯¯ï¼Œè¯·ä¸¾ä¾‹è¯´æ˜
è¿™æ˜¯ç¬¬1éƒ¨åˆ†ï¼Œå…±9éƒ¨åˆ†ï¼Œè¯·å½’çº³ä¸€ä¸‹å®ƒçš„åŠŸèƒ½
```

### æºä»£ç 
```cpp
// Copyright 2022 the V8 project authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#include "src/maglev/maglev-ir.h"

#include <cmath>
#include <limits>
#include <optional>

#include "src/base/bounds.h"
#include "src/base/logging.h"
#include "src/builtins/builtins-constructor.h"
#include "src/codegen/code-factory.h"
#include "src/codegen/interface-descriptors-inl.h"
#include "src/codegen/interface-descriptors.h"
#include "src/common/globals.h"
#include "src/compiler/compilation-dependencies.h"
#include "src/compiler/fast-api-calls.h"
#include "src/compiler/heap-refs.h"
#include "src/deoptimizer/deoptimize-reason.h"
#include "src/execution/isolate-inl.h"
#include "src/heap/local-heap.h"
#include "src/heap/parked-scope.h"
#include "src/interpreter/bytecode-flags-and-tokens.h"
#include "src/objects/fixed-array.h"
#include "src/objects/instance-type.h"
#include "src/objects/js-array.h"
#include "src/objects/js-generator.h"
#include "src/objects/property-cell.h"
#include "src/roots/static-roots.h"
#ifdef V8_ENABLE_MAGLEV
#include "src/maglev/maglev-assembler-inl.h"
#include "src/maglev/maglev-assembler.h"
#include "src/maglev/maglev-code-gen-state.h"
#endif
#include "src/maglev/maglev-compilation-unit.h"
#include "src/maglev/maglev-graph-labeller.h"
#include "src/maglev/maglev-graph-processor.h"
#include "src/maglev/maglev-ir-inl.h"
#include "src/roots/roots.h"

namespace v8 {
namespace internal {
namespace maglev {

#define __ masm->

const char* OpcodeToString(Opcode opcode) {
#define DEF_NAME(Name) #Name,
  static constexpr const char* const names[] = {NODE_BASE_LIST(DEF_NAME)};
#undef DEF_NAME
  return names[static_cast<int>(opcode)];
}

BasicBlock* Phi::predecessor_at(int i) {
  return merge_state_->predecessor_at(i);
}

namespace {

// Prevent people from accidentally using kScratchRegister here and having their
// code break in arm64.
[[maybe_unused]] struct Do_not_use_kScratchRegister_in_arch_independent_code {
} kScratchRegister;
[[maybe_unused]] struct
    Do_not_use_kScratchDoubleRegister_in_arch_independent_code {
} kScratchDoubleRegister;
static_assert(!std::is_same_v<decltype(kScratchRegister), Register>);
static_assert(
    !std::is_same_v<decltype(kScratchDoubleRegister), DoubleRegister>);

}  // namespace

#ifdef DEBUG
namespace {

template <size_t InputCount, typename Base, typename Derived>
int StaticInputCount(FixedInputNodeTMixin<InputCount, Base, Derived>*) {
  return InputCount;
}

int StaticInputCount(NodeBase*) { UNREACHABLE(); }

}  // namespace

void NodeBase::CheckCanOverwriteWith(Opcode new_opcode,
                                     OpProperties new_properties) {
  if (new_opcode == Opcode::kDead) return;

  DCHECK_IMPLIES(new_properties.can_eager_deopt(),
                 properties().can_eager_deopt());
  DCHECK_IMPLIES(new_properties.can_lazy_deopt(),
                 properties().can_lazy_deopt());
  DCHECK_IMPLIES(new_properties.needs_register_snapshot(),
                 properties().needs_register_snapshot());

  int old_input_count = input_count();
  size_t old_sizeof = -1;
  switch (opcode()) {
#define CASE(op)             \
  case Opcode::k##op:        \
    old_sizeof = sizeof(op); \
    break;
    NODE_BASE_LIST(CASE);
#undef CASE
  }

  switch (new_opcode) {
#define CASE(op)                                                          \
  case Opcode::k##op: {                                                   \
    DCHECK_EQ(old_input_count, StaticInputCount(static_cast<op*>(this))); \
    DCHECK_EQ(sizeof(op), old_sizeof);                                    \
    break;                                                                \
  }
    NODE_BASE_LIST(CASE)
#undef CASE
  }
}

#endif  // DEBUG

bool Phi::is_loop_phi() const { return merge_state()->is_loop(); }

bool Phi::is_unmerged_loop_phi() const {
  DCHECK(is_loop_phi());
  return merge_state()->is_unmerged_loop();
}

void Phi::RecordUseReprHint(UseRepresentationSet repr_mask,
                            int current_offset) {
  if (is_loop_phi() && merge_state()->HasLoopInfo() &&
      merge_state()->loop_info()->Contains(current_offset)) {
    same_loop_uses_repr_hint_.Add(repr_mask);
  }

  if (!repr_mask.is_subset_of(uses_repr_hint_)) {
    uses_repr_hint_.Add(repr_mask);

    // Propagate in inputs, ignoring unbounded loop backedges.
    int bound_inputs = input_count();
    if (merge_state()->is_unmerged_loop()) --bound_inputs;

    for (int i = 0; i < bound_inputs; i++) {
      if (Phi* phi_input = input(i).node()->TryCast<Phi>()) {
        phi_input->RecordUseReprHint(repr_mask, current_offset);
      }
    }
  }
}

void Phi::SetUseRequires31BitValue() {
  if (uses_require_31_bit_value()) return;
  set_uses_require_31_bit_value();
  auto inputs =
      is_loop_phi() ? merge_state_->predecessors_so_far() : input_count();
  for (uint32_t i = 0; i < inputs; ++i) {
    ValueNode* input_node = input(i).node();
    DCHECK(input_node);
    if (auto phi = input_node->TryCast<Phi>()) {
      phi->SetUseRequires31BitValue();
    }
  }
}

InitialValue::InitialValue(uint64_t bitfield, interpreter::Register source)
    : Base(bitfield), source_(source) {}

namespace {

// ---
// Print
// ---

bool IsStoreToNonEscapedObject(const NodeBase* node) {
  switch (node->opcode()) {
    case Opcode::kStoreMap:
    case Opcode::kStoreTaggedFieldWithWriteBarrier:
    case Opcode::kStoreTaggedFieldNoWriteBarrier:
    case Opcode::kStoreScriptContextSlotWithWriteBarrier:
    case Opcode::kStoreFloat64:
      DCHECK_GT(node->input_count(), 0);
      if (InlinedAllocation* alloc =
              node->input(0).node()->template TryCast<InlinedAllocation>()) {
        return alloc->HasBeenAnalysed() && alloc->HasBeenElided();
      }
      return false;
    default:
      return false;
  }
}

void PrintInputs(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                 const NodeBase* node) {
  if (!node->has_inputs()) return;

  os << " [";
  for (int i = 0; i < node->input_count(); i++) {
    if (i != 0) os << ", ";
    graph_labeller->PrintInput(os, node->input(i));
  }
  if (IsStoreToNonEscapedObject(node)) {
    os << " ğŸª¦";
  }
  os << "]";
}

void PrintResult(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                 const NodeBase* node) {}

void PrintResult(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                 const ValueNode* node) {
  os << " â†’ " << node->result().operand();
  if (node->result().operand().IsAllocated() && node->is_spilled() &&
      node->spill_slot() != node->result().operand()) {
    os << " (spilled: " << node->spill_slot() << ")";
  }
  if (node->has_valid_live_range()) {
    os << ", live range: [" << node->live_range().start << "-"
       << node->live_range().end << "]";
  }
  if (!node->has_id()) {
    os << ", " << node->use_count() << " uses";
    if (const InlinedAllocation* alloc = node->TryCast<InlinedAllocation>()) {
      os << " (" << alloc->non_escaping_use_count() << " non escaping uses)";
      if (alloc->HasBeenAnalysed() && alloc->HasBeenElided()) {
        os << " ğŸª¦";
      }
    } else if (!node->is_used()) {
      if (node->opcode() != Opcode::kAllocationBlock &&
          node->properties().is_required_when_unused()) {
        os << ", but required";
      } else {
        os << " ğŸª¦";
      }
    }
  }
}

void PrintTargets(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                  const NodeBase* node) {}

void PrintTargets(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                  const UnconditionalControlNode* node) {
  os << " b" << graph_labeller->BlockId(node->target());
}

void PrintTargets(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                  const BranchControlNode* node) {
  os << " b" << graph_labeller->BlockId(node->if_true()) << " b"
     << graph_labeller->BlockId(node->if_false());
}

void PrintTargets(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                  const Switch* node) {
  for (int i = 0; i < node->size(); i++) {
    const BasicBlockRef& target = node->Cast<Switch>()->targets()[i];
    os << " b" << graph_labeller->BlockId(target.block_ptr());
  }
  if (node->Cast<Switch>()->has_fallthrough()) {
    BasicBlock* fallthrough_target = node->Cast<Switch>()->fallthrough();
    os << " b" << graph_labeller->BlockId(fallthrough_target);
  }
}

class MaybeUnparkForPrint {
 public:
  MaybeUnparkForPrint() {
    LocalHeap* local_heap = LocalHeap::Current();
    if (!local_heap) {
      local_heap = Isolate::Current()->main_thread_local_heap();
    }
    DCHECK_NOT_NULL(local_heap);
    if (local_heap->IsParked()) {
      scope_.emplace(local_heap);
    }
  }

 private:
  std::optional<UnparkedScope> scope_;
};

template <typename NodeT>
void PrintImpl(std::ostream& os, MaglevGraphLabeller* graph_labeller,
               const NodeT* node, bool skip_targets) {
  MaybeUnparkForPrint unpark;
  os << node->opcode();
  node->PrintParams(os, graph_labeller);
  PrintInputs(os, graph_labeller, node);
  PrintResult(os, graph_labeller, node);
  if (!skip_targets) {
    PrintTargets(os, graph_labeller, node);
  }
}

bool RootToBoolean(RootIndex index) {
  switch (index) {
    case RootIndex::kFalseValue:
    case RootIndex::kNullValue:
    case RootIndex::kUndefinedValue:
    case RootIndex::kNanValue:
    case RootIndex::kHoleNanValue:
    case RootIndex::kMinusZeroValue:
    case RootIndex::kempty_string:
#ifdef V8_ENABLE_WEBASSEMBLY
    case RootIndex::kWasmNull:
#endif
      return false;
    default:
      return true;
  }
}

#ifdef DEBUG
// For all RO roots, check that RootToBoolean returns the same value as
// BooleanValue on that root.
bool CheckToBooleanOnAllRoots(LocalIsolate* local_isolate) {
  ReadOnlyRoots roots(local_isolate);
  // Use the READ_ONLY_ROOT_LIST macro list rather than a for loop to get nicer
  // error messages if there is a failure.
#define DO_CHECK(type, name, CamelName)                                   \
  /* Ignore 'undefined' roots that are not the undefined value itself. */ \
  if (roots.name() != roots.undefined_value() ||                          \
      RootIndex::k##CamelName == RootIndex::kUndefinedValue) {            \
    DCHECK_EQ(Object::BooleanValue(roots.name(), local_isolate),          \
              RootToBoolean(RootIndex::k##CamelName));                    \
  }
  READ_ONLY_ROOT_LIST(DO_CHECK)
#undef DO_CHECK
  return true;
}
#endif

size_t GetInputLocationSizeForValueNode(VirtualObject::List virtual_objects,
                                        ValueNode* value) {
  // We allocate the space needed for the Virtual Object plus one location
  // used if the allocation escapes.
  DCHECK(!value->Is<VirtualObject>());
  if (const InlinedAllocation* alloc = value->TryCast<InlinedAllocation>()) {
    VirtualObject* vobject = virtual_objects.FindAllocatedWith(alloc);
    CHECK_NOT_NULL(vobject);
    return vobject->InputLocationSizeNeeded(virtual_objects) + 1;
  }
  return 1;
}

size_t GetInputLocationSizeForArray(VirtualObject::List virtual_objects,
                                    base::Vector<ValueNode*> array) {
  size_t size = 0;
  for (ValueNode* value : array) {
    size += GetInputLocationSizeForValueNode(virtual_objects, value);
  }
  return size;
}

size_t GetInputLocationSizeForCompactFrame(
    const MaglevCompilationUnit& unit, VirtualObject::List virtual_objects,
    const CompactInterpreterFrameState* frame) {
  size_t size = 0;
  frame->ForEachValue(unit, [&](ValueNode* value, interpreter::Register) {
    if (value != nullptr) {
      size += GetInputLocationSizeForValueNode(virtual_objects, value);
    }
  });
  return size;
}

size_t GetInputLocationSizeForVirtualObjectSlot(
    VirtualObject::List virtual_objects, ValueNode* node) {
  if (IsConstantNode(node->opcode()) ||
      node->opcode() == Opcode::kArgumentsElements ||
      node->opcode() == Opcode::kArgumentsLength ||
      node->opcode() == Opcode::kRestLength) {
    return 0;
  }
  return GetInputLocationSizeForValueNode(virtual_objects, node);
}

}  // namespace

size_t VirtualObject::InputLocationSizeNeeded(
    VirtualObject::List virtual_objects) const {
  if (type() != kDefault) return 0;
  size_t size = 0;
  for (uint32_t i = 0; i < slot_count(); i++) {
    size += GetInputLocationSizeForVirtualObjectSlot(virtual_objects,
                                                     slots_.data[i]);
  }
  return size;
}

void VirtualObject::List::Print(std::ostream& os, const char* prefix,
                                MaglevGraphLabeller* labeller) const {
  CHECK_NOT_NULL(labeller);
  os << prefix;
  for (const VirtualObject* vo : *this) {
    labeller->PrintNodeLabel(os, vo);
    os << "; ";
  }
  os << std::endl;
}

size_t DeoptFrame::GetInputLocationsArraySize() const {
  size_t size = 0;
  const DeoptFrame* frame = this;
  VirtualObject::List virtual_objects = GetVirtualObjects(*frame);
  do {
    switch (frame->type()) {
      case DeoptFrame::FrameType::kInterpretedFrame:
        size += GetInputLocationSizeForValueNode(
                    virtual_objects, frame->as_interpreted().closure()) +
                GetInputLocationSizeForCompactFrame(
                    frame->as_interpreted().unit(), virtual_objects,
                    frame->as_interpreted().frame_state());
        break;
      case DeoptFrame::FrameType::kInlinedArgumentsFrame:
        size += GetInputLocationSizeForValueNode(
                    virtual_objects, frame->as_inlined_arguments().closure()) +
                GetInputLocationSizeForArray(
                    virtual_objects, frame->as_inlined_arguments().arguments());
        break;
      case DeoptFrame::FrameType::kConstructInvokeStubFrame:
        size += GetInputLocationSizeForValueNode(
                    virtual_objects, frame->as_construct_stub().receiver()) +
                GetInputLocationSizeForValueNode(
                    virtual_objects, frame->as_construct_stub().context());
        break;
      case DeoptFrame::FrameType::kBuiltinContinuationFrame:
        size +=
            GetInputLocationSizeForArray(
                virtual_objects,
                frame->as_builtin_continuation().parameters()) +
            GetInputLocationSizeForValueNode(
                virtual_objects, frame->as_builtin_continuation().context());
        break;
    }
    frame = frame->parent();
  } while (frame != nullptr);
  return size;
}

bool RootConstant::ToBoolean(LocalIsolate* local_isolate) const {
#ifdef DEBUG
  // (Ab)use static locals to call CheckToBooleanOnAllRoots once, on first
  // call to this function.
  static bool check_once = CheckToBooleanOnAllRoots(local_isolate);
  DCHECK(check_once);
#endif
  // ToBoolean is only supported for RO roots.
  DCHECK(RootsTable::IsReadOnly(index_));
  return RootToBoolean(index_);
}

bool FromConstantToBool(LocalIsolate* local_isolate, ValueNode* node) {
  DCHECK(IsConstantNode(node->opcode()));
  switch (node->opcode()) {
#define CASE(Name)                                       \
  case Opcode::k##Name: {                                \
    return node->Cast<Name>()->ToBoolean(local_isolate); \
  }
    CONSTANT_VALUE_NODE_LIST(CASE)
#undef CASE
    default:
      UNREACHABLE();
  }
}

void Input::clear() {
  node_->remove_use();
  node_ = nullptr;
}

DeoptInfo::DeoptInfo(Zone* zone, const DeoptFrame top_frame,
                     compiler::FeedbackSource feedback_to_update,
                     size_t input_locations_size)
    : top_frame_(top_frame),
      feedback_to_update_(feedback_to_update),
      input_locations_(
          zone->AllocateArray<InputLocation>(input_locations_size)) {
  // Initialise InputLocations so that they correctly don't have a next use id.
  for (size_t i = 0; i < input_locations_size; ++i) {
    new (&input_locations_[i]) InputLocation();
  }
#ifdef DEBUG
  input_location_count_ = input_locations_size;
#endif  // DEBUG
}

bool LazyDeoptInfo::IsResultRegister(interpreter::Register reg) const {
  if (top_frame().type() == DeoptFrame::FrameType::kConstructInvokeStubFrame) {
    return reg == interpreter::Register::virtual_accumulator();
  }
  if (V8_LIKELY(result_size() == 1)) {
    return reg == result_location_;
  }
  if (result_size() == 0) {
    return false;
  }
  DCHECK_EQ(result_size(), 2);
  return reg == result_location_ ||
         reg == interpreter::Register(result_location_.index() + 1);
}

bool LazyDeoptInfo::InReturnValues(interpreter::Register reg,
                                   interpreter::Register result_location,
                                   int result_size) {
  if (result_size == 0 || !result_location.is_valid()) {
    return false;
  }
  return base::IsInRange(reg.index(), result_location.index(),
                         result_location.index() + result_size - 1);
}

int InterpretedDeoptFrame::ComputeReturnOffset(
    interpreter::Register result_location, int result_size) const {
  // Return offsets are counted from the end of the translation frame,
  // which is the array [parameters..., locals..., accumulator]. Since
  // it's the end, we don't need to worry about earlier frames.
  if (result_location == interpreter::Register::virtual_accumulator()) {
    return 0;
  } else if (result_location.is_parameter()) {
    // This is slightly tricky to reason about because of zero indexing
    // and fence post errors. As an example, consider a frame with 2
    // locals and 2 parameters, where we want argument index 1 -- looking
    // at the array in reverse order we have:
    //   [acc, r1, r0, a1, a0]
    //                  ^
    // and this calculation gives, correctly:
    //   2 + 2 - 1 = 3
    return unit().register_count() + unit().parameter_count() -
           result_location.ToParameterIndex();
  } else {
    return unit().register_count() - result_location.index();
  }
}

const InterpretedDeoptFrame& LazyDeoptInfo::GetFrameForExceptionHandler(
    const ExceptionHandlerInfo* handler_info) {
  const DeoptFrame* target_frame = &top_frame();
  for (int i = 0;; i++) {
    while (target_frame->type() != DeoptFrame::FrameType::kInterpretedFrame) {
      target_frame = target_frame->parent();
    }
    if (i == handler_info->depth) break;
    target_frame = target_frame->parent();
  }
  return target_frame->as_interpreted();
}

void NodeBase::Print(std::ostream& os, MaglevGraphLabeller* graph_labeller,
                     bool skip_targets) const {
  switch (opcode()) {
#define V(Name)         \
  case Opcode::k##Name: \
    return PrintImpl(os, graph_labeller, this->Cast<Name>(), skip_targets);
    NODE_BASE_LIST(V)
#undef V
  }
  UNREACHABLE();
}

void NodeBase::Print() const {
  MaglevGraphLabeller labeller;
  Print(std::cout, &labeller);
  std::cout << std::endl;
}

void ValueNode::SetHint(compiler::InstructionOperand hint) {
  if (!hint_.IsInvalid()) return;
  hint_ = hint;
  if (result_.operand().IsUnallocated()) {
    auto operand = compiler::UnallocatedOperand::cast(result_.operand());
    if (operand.HasSameAsInputPolicy()) {
      input(operand.input_index()).node()->SetHint(hint);
    }
  }
  if (this->Is<Phi>()) {
    for (Input& input : *this) {
      if (input.node()->has_id() && input.node()->id() < this->id()) {
        input.node()->SetHint(hint);
      }
    }
  }
}

void ValueNode::SetNoSpill() {
  DCHECK(!IsConstantNode(opcode()));
#ifdef DEBUG
  state_ = kSpill;
#endif  // DEBUG
  spill_ = compiler::InstructionOperand();
}

void ValueNode::SetConstantLocation() {
  DCHECK(IsConstantNode(opcode()));
#ifdef DEBUG
  state_ = kSpill;
#endif  // DEBUG
  spill_ = compiler::ConstantOperand(
      compiler::UnallocatedOperand::cast(result().operand())
          .virtual_register());
}

ExternalReference Float64Ieee754Unary::ieee_function_ref() const {
  switch (ieee_function_) {
#define CASE(MathName, ExtName, EnumName) \
  case Ieee754Function::k##EnumName:      \
    return ExternalReference::ieee754_##ExtName##_function();
    IEEE_754_UNARY_LIST(CASE)
#undef CASE
  }
}

// ---
// Check input value representation
// ---

ValueRepresentation ToValueRepresentation(MachineType type) {
  switch (type.representation()) {
    case MachineRepresentation::kTagged:
    case MachineRepresentation::kTaggedSigned:
    case MachineRepresentation::kTaggedPointer:
      return ValueRepresentation::kTagged;
    case MachineRepresentation::kFloat64:
      return ValueRepresentation::kFloat64;
    case MachineRepresentation::kWord64:
      DCHECK_EQ(kSystemPointerSize, 8);
      return ValueRepresentation::kIntPtr;
    default:
      return ValueRepresentation::kInt32;
  }
}

void CheckValueInputIs(const NodeBase* node, int i,
                       ValueRepresentation expected,
                       MaglevGraphLabeller* graph_labeller) {
  ValueNode* input = node->input(i).node();
  DCHECK(!input->Is<Identity>());
  ValueRepresentation got = input->properties().value_representation();
  // Allow Float64 values to be inputs when HoleyFloat64 is expected.
  bool valid =
      (got == expected) || (got == ValueRepresentation::kFloat64 &&
                            expected == ValueRepresentation::kHoleyFloat64);
  if (!valid) {
    std::ostringstream str;
    str << "Type representation error: node ";
    if (graph_labeller) {
      str << "#" << graph_labeller->NodeId(node) << " : ";
    }
    str << node->opcode() << " (input @" << i << " = " << input->opcode()
        << ") type " << got << " is not " << expected;
    FATAL("%s", str.str().c_str());
  }
}

void CheckValueInputIs(const NodeBase* node, int i, Opcode expected,
                       MaglevGraphLabeller* graph_labeller) {
  ValueNode* input = node->input(i).node();
  Opcode got = input->opcode();
  if (got != expected) {
    std::ostringstream str;
    str << "Opcode error: node ";
    if (graph_labeller) {
      str << "#" << graph_labeller->NodeId(node) << " : ";
    }
    str << node->opcode() << " (input @" << i << " = " << input->opcode()
        << ") opcode " << got << " is not " << expected;
    FATAL("%s", str.str().c_str());
  }
}

void GeneratorStore::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

void Phi::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  switch (value_representation()) {
#define CASE_REPR(repr)                                        \
  case ValueRepresentation::k##repr:                           \
    for (int i = 0; i < input_count(); i++) {                  \
      CheckValueInputIs(this, i, ValueRepresentation::k##repr, \
                        graph_labeller);                       \
    }                                                          \
    break;

    CASE_REPR(Tagged)
    CASE_REPR(Int32)
    CASE_REPR(Uint32)
    CASE_REPR(Float64)
    CASE_REPR(HoleyFloat64)
#undef CASE_REPR
    case ValueRepresentation::kIntPtr:
      UNREACHABLE();
  }
}

void Call::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void Call::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallForwardVarargs::VerifyInputs(
    MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallForwardVarargs::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallWithArrayLike::VerifyInputs(
    MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallWithArrayLike::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallWithSpread::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallWithSpread::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallSelf::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallSelf::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallKnownJSFunction::VerifyInputs(
    MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallKnownJSFunction::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallKnownApiFunction::VerifyInputs(
    MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallKnownApiFunction::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void Construct::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void Construct::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void ConstructWithSpread::VerifyInputs(
    MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void ConstructWithSpread::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallBuiltin::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  auto descriptor = Builtins::CallInterfaceDescriptorFor(builtin());
  int count = input_count();
  // Verify context.
  if (descriptor.HasContextParameter()) {
    CheckValueInputIs(this, count - 1, ValueRepresentation::kTagged,
                      graph_labeller);
    count--;
  }

// {all_input_count} includes the feedback slot and vector.
#ifdef DEBUG
  int all_input_count = count + (has_feedback() ? 2 : 0);
  if (descriptor.AllowVarArgs()) {
    DCHECK_GE(all_input_count, descriptor.GetParameterCount());
  } else {
    DCHECK_EQ(all_input_count, descriptor.GetParameterCount());
  }
#endif
  int i = 0;
  // Check the rest of inputs.
  for (; i < count; ++i) {
    MachineType type = i < descriptor.GetParameterCount()
                           ? descriptor.GetParameterType(i)
                           : MachineType::AnyTagged();
    CheckValueInputIs(this, i, ToValueRepresentation(type), graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallBuiltin::MarkTaggedInputsAsDecompressing() {
  auto descriptor = Builtins::CallInterfaceDescriptorFor(builtin());
  int count = input_count();
  // Set context.
  if (descriptor.HasContextParameter()) {
    input(count - 1).node()->SetTaggedResultNeedsDecompress();
    count--;
  }
  int i = 0;
  // Set the rest of the tagged inputs.
  for (; i < count; ++i) {
    MachineType type = i < descriptor.GetParameterCount()
                           ? descriptor.GetParameterType(i)
                           : MachineType::AnyTagged();
    if (type.IsTagged() && !type.IsTaggedSigned()) {
      input(i).node()->SetTaggedResultNeedsDecompress();
    }
  }
}
#endif

void CallCPPBuiltin::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallCPPBuiltin::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void CallRuntime::VerifyInputs(MaglevGraphLabeller* graph_labeller) const {
  for (int i = 0; i < input_count(); i++) {
    CheckValueInputIs(this, i, ValueRepresentation::kTagged, graph_labeller);
  }
}

#ifdef V8_COMPRESS_POINTERS
void CallRuntime::MarkTaggedInputsAsDecompressing() {
  for (int i = 0; i < input_count(); i++) {
    input(i).node()->SetTaggedResultNeedsDecompress();
  }
}
#endif

void InlinedAllocation::VerifyInputs(
    MaglevGraphLabeller* graph_labeller) const {
  Base::VerifyInputs(graph_labeller);
  CheckValueInputIs(this, 0, Opcode::kAllocationBlock, graph_labeller);
}

// ---
// Reify constants
// ---

Handle<Object> ValueNode::Reify(LocalIsolate* isolate) const {
  switch (opcode()) {
#define V(Name)         \
  case Opcode::k##Name: \
    return this->Cast<Name>()->DoReify(isolate);
    CONSTANT_VALUE_NODE_LIST(V)
#undef V
    default:
      UNREACHABLE();
  }
}

Handle<Object> ExternalConstant::DoReify(LocalIsolate* isolate) const {
  UNREACHABLE();
}

Handle<Object> SmiConstant::DoReify(LocalIsolate* isolate) const {
  return handle(value_, isolate);
}

Handle<Object> TaggedIndexConstant::DoReify(LocalIsolate* isolate) const {
  UNREACHABLE();
}

Handle<Object> Int32Constant::DoReify(LocalIsolate* isolate) const {
  return isolate->factory()->NewNumberFromInt<AllocationType::kOld>(value());
}

Handle<Object> Uint32Constant::DoReify(LocalIsolate* isolate) const {
  return isolate->factory()->NewNumberFromUint<AllocationType::kOld>(value());
}

Handle<Object> Float64Constant::DoReify(LocalIsolate* isolate) const {
  return isolate->factory()->NewNumber<AllocationType::kOld>(
      value_.get_scalar());
}

Handle<Object> Constant::DoReify(LocalIsolate* isolate) const {
  return object_.object();
}

Handle<Object> TrustedConstant::DoReify(LocalIsolate* isolate) const {
  return object_.object();
}

Handle<Object> RootConstant::DoReify(LocalIsolate* isolate) const {
  return isolate->root_handle(index());
}

#ifdef V8_ENABLE_MAGLEV

bool FromConstantToBool(MaglevAssembler* masm, ValueNode* node) {
  // TODO(leszeks): Getting the main thread local isolate is not what we
  // actually want here, but it's all we have, and it happens to work because
  // really all we're using it for is ReadOnlyRoots. We should change ToBoolean
  // to be able to pass ReadOnlyRoots in directly.
  return FromConstantToBool(masm->isolate()->AsLocalIsolate(), node);
}

// ---
// Load node to registers
// ---

namespace {
template <typename NodeT>
void LoadToRegisterHelper(NodeT* node, MaglevAssembler* masm, Register reg) {
  if constexpr (!IsDoubleRepresentation(
                    NodeT::kProperties.value_representation())) {
    return node->DoLoadToRegister(masm, reg);
  } else {
    UNREACHABLE();
  }
}
template <typename NodeT>
void LoadToRegisterHelper(NodeT* node, MaglevAssembler* masm,
                          DoubleRegister reg) {
  if constexpr (IsDoubleRepresentation(
                    NodeT::kProperties.value_representation())) {
    return node->DoLoadToRegister(masm, reg);
  } else {
    UNREACHABLE();
  }
}
}  // namespace

void ValueNode::LoadToRegister(MaglevAssembler* masm, Register reg) {
  switch (opcode()) {
#define V(Name)         \
  case Opcode::k##Name: \
    return LoadToRegisterHelper(this->Cast<Name>(), masm, reg);
    VALUE_NODE_LIST(V)
#undef V
    default:
      UNREACHABLE();
  }
}
void ValueNode::LoadToRegister(MaglevAssembler* masm, DoubleRegister reg) {
  switch (opcode()) {
#define V(Name)         \
  case Opcode::k##Name: \
    return LoadToRegisterHelper(this->Cast<Name>(), masm, reg);
    VALUE_NODE_LIST(V)
#undef V
    default:
      UNREACHABLE();
  }
}

void ValueNode::DoLoadToRegister(MaglevAssembler* masm, Register reg) {
  DCHECK(is_spilled());
  DCHECK(!use_double_register());
  __ Move(reg,
          masm->GetStackSlot(compiler::AllocatedOperand::cast(spill_slot())));
}

void ValueNode::DoLoadToRegister(MaglevAssemb
```