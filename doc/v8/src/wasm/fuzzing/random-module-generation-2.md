Response: The user wants to understand the functionality of the C++ code snippet provided. This is the third part of a four-part file. I need to summarize the code's purpose and, if applicable, illustrate its relationship with JavaScript using examples.

**Code Analysis:**

The code defines a `BodyGen` class responsible for generating the body of WebAssembly functions. It utilizes a `WasmFunctionBuilder` to emit WebAssembly instructions. Key functionalities include:

- **Generating different Wasm value types:** This includes primitive types (i32, i64, f32, f64), reference types (ref null, ref func, ref extern, ref struct, ref array, ref i31, ref any, ref eq), and potentially SIMD types.
- **Handling nullability of references:** The generator can create nullable or non-nullable references.
- **Generating various Wasm instructions:**  This includes local variable access (get/set), global variable access (get/set), control flow instructions (block, loop, if, br, br_if, return), memory operations (load, store), numeric operations (arithmetic, comparison, conversion), reference operations (ref.null, ref.is_null, ref.func, ref.cast, ref.as_non_null), and potentially SIMD operations.
- **Generating function calls:** This includes direct calls (call), indirect calls (call_indirect), and tail calls (return_call, return_call_indirect).
- **Generating Wasm GC instructions:** For Wasm GC types, it can generate struct creation (struct.new, struct.new_default), array creation (array.new, array.new_fixed, array.new_default), and related operations (struct.get, struct.set, array.get, array.set, array.len).
- **Managing recursion depth:** The generator has a mechanism to limit recursion during code generation.
- **Interacting with module-level information:** It uses information about functions, locals, globals, structs, and arrays defined in the module.
- **String interop:** It includes logic for interacting with imported "wasm:js-string" functions.

**Relationship with JavaScript:**

WebAssembly modules can be loaded and executed within a JavaScript environment. The code generated by `BodyGen` directly corresponds to the bytecode executed by the Wasm engine in a JavaScript runtime.

**JavaScript Examples:**

Let's illustrate how some of the generated Wasm features relate to JavaScript:

1. **Function Calls:**

   - **Wasm:** `call $my_function`
   - **JavaScript:**
     ```javascript
     const wasmInstance = await WebAssembly.instantiateStreaming(fetch('module.wasm'));
     wasmInstance.exports.my_function();
     ```

2. **Memory Access:**

   - **Wasm:** `i32.load offset=10 align=4`
   - **JavaScript:**
     ```javascript
     const wasmInstance = await WebAssembly.instantiateStreaming(fetch('module.wasm'));
     const memory = wasmInstance.exports.memory;
     const view = new Int32Array(memory.buffer);
     const value = view[10 / 4]; // Accessing memory at offset 10
     ```

3. **Global Variables:**

   - **Wasm:** `global.get $my_global`
   - **JavaScript:**
     ```javascript
     const wasmInstance = await WebAssembly.instantiateStreaming(fetch('module.wasm'));
     const globalValue = wasmInstance.exports.my_global.value;
     ```

4. **Wasm GC (Structs and Arrays):**

   - **Wasm (creating a struct):** `struct.new $my_struct (i32.const 1, f64.const 2.5)`
   - **JavaScript (accessing a struct, assuming an exported function returns it):**
     ```javascript
     const wasmInstance = await WebAssembly.instantiateStreaming(fetch('module.wasm'));
     const myStruct = wasmInstance.exports.get_my_struct();
     // Assuming the struct has fields named 'field1' and 'field2'
     const value1 = myStruct.field1;
     const value2 = myStruct.field2;
     ```

5. **String Interop:**

   - **Wasm (calling a string import):** `call $wasm_js_string.length`
   - **JavaScript (the corresponding import in the Wasm module):**
     ```javascript
     const importObject = {
       "wasm:js-string": {
         "length": (jsString) => jsString.length
       }
     };
     const wasmInstance = await WebAssembly.instantiateStreaming(fetch('module.wasm'), importObject);
     // ... the Wasm module can now call the imported 'length' function
     ```

**Summary of Functionality (Part 3):**

This part of the code defines the `BodyGen` class, which is responsible for generating the instructions within the body of WebAssembly functions. It provides methods to emit code for various Wasm value types, instructions (including control flow, memory access, numeric operations, and reference operations), and function calls. It also includes specific logic for generating Wasm GC instructions and interacting with JavaScript strings via imported functions. The `BodyGen` class uses a `WasmFunctionBuilder` to construct the function body piece by piece.

这是第三部分，描述了 `BodyGen` 类的实现，该类负责生成 WebAssembly 函数的指令序列（函数体）。以下是其功能的归纳：

**主要功能:**

* **生成 WebAssembly 指令:** `BodyGen` 类提供了各种方法来生成不同的 WebAssembly 指令，包括：
    * **常量:** 生成各种类型的常量值 (i32, i64, f32, f64, 引用类型等)。
    * **局部变量操作:** 获取和设置局部变量的值 (`local.get`, `local.set`).
    * **全局变量操作:** 获取和设置全局变量的值 (`global.get`, `global.set`).
    * **内存操作:** 加载和存储不同类型的值到线性内存 (`i32.load`, `f64.store` 等)。
    * **控制流:** 生成块 (`block`), 循环 (`loop`), 条件语句 (`if`, `else`), 分支 (`br`, `br_if`), `return` 等控制流指令。
    * **数值运算:** 生成各种算术、比较和类型转换指令 (例如 `i32.add`, `f64.sub`, `i32.trunc_f64_s` 等)。
    * **引用类型操作:** 生成与引用类型相关的指令，例如 `ref.null`, `ref.is_null`, `ref.func`, `ref.cast`, `ref.as_non_null` 等。
    * **函数调用:** 生成直接函数调用 (`call`) 和间接函数调用 (`call_indirect`) 指令。
    * **SIMD 指令:** 如果启用了 SIMD 支持，则可以生成 SIMD 相关的指令。
    * **Wasm GC 指令:**  如果启用了 Wasm GC (垃圾回收) 支持，则可以生成与 Wasm GC 类型 (结构体和数组) 相关的指令，例如 `struct.new`, `array.new`, `struct.get`, `array.get`, `ref.as_non_null` 等。
    * **异常处理:** 生成抛出和捕获异常的指令 (`throw`, `try`, `catch`).

* **处理不同类型的 WebAssembly 值:** `BodyGen` 可以根据给定的 `ValueType` 生成对应类型的指令，包括基本类型 (i32, i64, f32, f64)、引用类型 (`funcref`, `externref`, 用户定义的引用类型等) 和 SIMD 类型。

* **处理引用类型的空值性:** 可以生成可空 (`ref null`) 和不可空 (`ref.as_non_null`) 的引用。

* **与模块级信息交互:**  `BodyGen` 接收并使用来自 `WasmModuleBuilder` 的信息，例如函数签名、局部变量、全局变量、结构体和数组类型等。

* **限制代码生成深度:**  通过 `recursion_depth` 变量来限制代码生成的递归深度，防止无限循环。

* **与 JavaScript 功能的关系 (通过 `wasm:js-string` 模块):**
    * 如果启用了 Wasm GC 支持，`BodyGen` 会包含与导入的 "wasm:js-string" 模块交互的逻辑。
    * 它可以通过调用导入的函数来创建和操作 JavaScript 字符串，例如 `string_cast`, `string_fromcharcode`, `string_concat` 等。

**JavaScript 示例 (与 `wasm:js-string` 模块相关):**

假设 WebAssembly 模块导入了 "wasm:js-string" 模块，并定义了 `string_length` 函数，其签名为接受一个 `externref` (表示 JavaScript 字符串) 并返回一个 `i32` (字符串长度)。

**C++ (在 `random-module-generation.cc` 中):**

```c++
      case HeapType::kExtern: {
        uint8_t choice = data->get<uint8_t>();
        // ...
        // ~80% chance of string.
        if (choice < 230 && ShouldGenerateWasmGC(options)) {
          uint8_t subchoice = choice % 7;
          switch (subchoice) {
            case 0:
              return string_cast(data);
            // ... other string functions
          }
        }
        // ...
      }
```

**WebAssembly (可能生成的代码片段):**

```wasm
  ;; 假设 $my_string 是一个本地变量，类型为 externref
  local.get $my_string
  call $wasm_js_string.length  ;; 调用导入的 JavaScript 函数获取字符串长度
```

**JavaScript (加载和使用该 WebAssembly 模块):**

```javascript
const importObject = {
  "wasm:js-string": {
    "length": (jsString) => jsString.length
  }
};

WebAssembly.instantiateStreaming(fetch('module.wasm'), importObject)
  .then(result => {
    const wasmInstance = result.instance;
    const myString = "Hello";
    // 假设 WebAssembly 模块导出了一个函数，该函数接受一个字符串并返回其长度
    const stringLength = wasmInstance.exports.getStringLength(myString);
    console.log(`字符串 "${myString}" 的长度是: ${stringLength}`);
  });
```

在这个例子中，`BodyGen` 生成的 WebAssembly 代码调用了 JavaScript 环境提供的 `length` 函数 (通过 "wasm:js-string" 模块导入)。这展示了 WebAssembly 如何与 JavaScript 功能进行互操作。

**总结:**

`BodyGen` 类是 WebAssembly 代码生成的核心组件，负责根据随机数据生成各种有效的 WebAssembly 指令序列，从而构建出功能各异的 WebAssembly 函数体。它还处理了与 JavaScript 环境的互操作性，特别是当启用了 Wasm GC 功能时，可以通过导入的 "wasm:js-string" 模块来操作 JavaScript 字符串。

### 提示词
```
这是目录为v8/src/wasm/fuzzing/random-module-generation.cc的一个c++源代码文件， 请归纳一下它的功能, 如果它与javascript的功能有关系，请用javascript举例说明
这是第3部分，共4部分，请归纳一下它的功能
```

### 源代码
```
+ emit_i31ref + fallback_to_eqref);
        // Try generating one of the alternatives
        // and continue to the rest of the methods in case it fails.
        if (random >= num_types + emit_i31ref) {
          if (GenerateOneOf(alternatives_other, type, data, nullability)) {
            return;
          }
          random = data->get<uint8_t>() % (num_types + emit_i31ref);
        }
        if (random < num_types) {
          // Using `HeapType(random)` here relies on the assumption that struct
          // and array types come before signatures.
          DCHECK(builder_->builder()->IsArrayType(random) ||
                 builder_->builder()->IsStructType(random));
          GenerateRef(HeapType(ModuleTypeIndex{random}), data, nullability);
        } else {
          GenerateRef(HeapType(HeapType::kI31), data, nullability);
        }
        return;
      }
      case HeapType::kFunc: {
        uint32_t random = data->get<uint8_t>() % (functions_.size() + 1);
        /// Try generating one of the alternatives
        // and continue to the rest of the methods in case it fails.
        if (random >= functions_.size()) {
          if (GenerateOneOf(alternatives_func_any, type, data, nullability)) {
            return;
          }
          random = data->get<uint8_t>() % functions_.size();
        }
        ModuleTypeIndex signature_index = functions_[random];
        DCHECK(builder_->builder()->IsSignature(signature_index));
        GenerateRef(HeapType(signature_index), data, nullability);
        return;
      }
      case HeapType::kI31: {
        // Try generating one of the alternatives
        // and continue to the rest of the methods in case it fails.
        if (data->get<bool>() &&
            GenerateOneOf(alternatives_other, type, data, nullability)) {
          return;
        }
        Generate(kWasmI32, data);
        builder_->EmitWithPrefix(kExprRefI31);
        return;
      }
      case HeapType::kExn: {
        // TODO(manoskouk): Can we somehow come up with a nontrivial exnref?
        ref_null(type, data);
        if (nullability == kNonNullable) {
          builder_->Emit(kExprRefAsNonNull);
        }
        return;
      }
      case HeapType::kExtern: {
        uint8_t choice = data->get<uint8_t>();
        if (choice < 25) {
          // ~10% chance of extern.convert_any.
          GenerateRef(HeapType(HeapType::kAny), data);
          builder_->EmitWithPrefix(kExprExternConvertAny);
          if (nullability == kNonNullable) {
            builder_->Emit(kExprRefAsNonNull);
          }
          return;
        }
        // ~80% chance of string.
        if (choice < 230 && ShouldGenerateWasmGC(options)) {
          uint8_t subchoice = choice % 7;
          switch (subchoice) {
            case 0:
              return string_cast(data);
            case 1:
              return string_fromcharcode(data);
            case 2:
              return string_fromcodepoint(data);
            case 3:
              return string_concat(data);
            case 4:
              return string_substring(data);
            case 5:
              return string_fromcharcodearray(data);
            case 6:
              return string_fromutf8array(data);
          }
        }
        // ~10% chance of fallthrough.
        [[fallthrough]];
      }
      case HeapType::kNoExtern:
      case HeapType::kNoFunc:
      case HeapType::kNone:
      case HeapType::kNoExn:
        ref_null(type, data);
        if (nullability == kNonNullable) {
          builder_->Emit(kExprRefAsNonNull);
        }
        return;
      default:
        // Indexed type (i.e. user-defined type).
        DCHECK(type.is_index());
        if (ShouldGenerateWasmGC(options) &&
            type.ref_index() == string_imports_.array_i8 &&
            data->get<uint8_t>() < 32) {
          // 1/8th chance, fits the number of remaining alternatives (7) well.
          return string_toutf8array(data);
        }
        GenerateOneOf(alternatives_indexed_type, type, data, nullability);
        return;
    }
    UNREACHABLE();
  }

  void GenerateRef(DataRange* data) {
    constexpr HeapType::Representation top_types[] = {
        HeapType::kAny,
        HeapType::kFunc,
        HeapType::kExtern,
    };
    HeapType::Representation type =
        top_types[data->get<uint8_t>() % arraysize(top_types)];
    GenerateRef(HeapType(type), data);
  }

  std::vector<ValueType> GenerateTypes(DataRange* data) {
    return fuzzing::GenerateTypes<options>(
        data, static_cast<uint32_t>(functions_.size() + structs_.size() +
                                    arrays_.size()));
  }

  void Generate(base::Vector<const ValueType> types, DataRange* data) {
    // Maybe emit a multi-value block with the expected return type. Use a
    // non-default value to indicate block generation to avoid recursion when we
    // reach the end of the data.
    bool generate_block = data->get<uint8_t>() % 32 == 1;
    if (generate_block) {
      GeneratorRecursionScope rec_scope(this);
      if (!recursion_limit_reached()) {
        const auto param_types = GenerateTypes(data);
        Generate(base::VectorOf(param_types), data);
        any_block(base::VectorOf(param_types), types, data);
        return;
      }
    }

    if (types.size() == 0) {
      Generate(kWasmVoid, data);
      return;
    }
    if (types.size() == 1) {
      Generate(types[0], data);
      return;
    }

    // Split the types in two halves and recursively generate each half.
    // Each half is non empty to ensure termination.
    size_t split_index = data->get<uint8_t>() % (types.size() - 1) + 1;
    base::Vector<const ValueType> lower_half = types.SubVector(0, split_index);
    base::Vector<const ValueType> upper_half =
        types.SubVector(split_index, types.size());
    DataRange first_range = data->split();
    Generate(lower_half, &first_range);
    Generate(upper_half, data);
  }

  void Consume(ValueType type) {
    // Try to store the value in a local if there is a local with the same
    // type. TODO(14034): For reference types a local with a super type
    // would also be fine.
    size_t num_params = builder_->signature()->parameter_count();
    for (uint32_t local_offset = 0; local_offset < locals_.size();
         ++local_offset) {
      if (locals_[local_offset] == type) {
        uint32_t local_index = static_cast<uint32_t>(local_offset + num_params);
        builder_->EmitWithU32V(kExprLocalSet, local_index);
        return;
      }
    }
    for (uint32_t param_index = 0; param_index < num_params; ++param_index) {
      if (builder_->signature()->GetParam(param_index) == type) {
        builder_->EmitWithU32V(kExprLocalSet, param_index);
        return;
      }
    }
    // No opportunity found to use the value, so just drop it.
    builder_->Emit(kExprDrop);
  }

  // Emit code to match an arbitrary signature.
  // TODO(11954): Add the missing reference type conversion/upcasting.
  void ConsumeAndGenerate(base::Vector<const ValueType> param_types,
                          base::Vector<const ValueType> return_types,
                          DataRange* data) {
    // This numeric conversion logic consists of picking exactly one
    // index in the return values and dropping all the values that come
    // before that index. Then we convert the value from that index to the
    // wanted type. If we don't find any value we generate it.
    auto primitive = [](ValueType t) -> bool {
      switch (t.kind()) {
        case kI32:
        case kI64:
        case kF32:
        case kF64:
          return true;
        default:
          return false;
      }
    };

    if (return_types.size() == 0 || param_types.size() == 0 ||
        !primitive(return_types[0])) {
      for (auto iter = param_types.rbegin(); iter != param_types.rend();
           ++iter) {
        Consume(*iter);
      }
      Generate(return_types, data);
      return;
    }

    int bottom_primitives = 0;

    while (static_cast<int>(param_types.size()) > bottom_primitives &&
           primitive(param_types[bottom_primitives])) {
      bottom_primitives++;
    }
    int return_index =
        bottom_primitives > 0 ? (data->get<uint8_t>() % bottom_primitives) : -1;
    for (int i = static_cast<int>(param_types.size() - 1); i > return_index;
         --i) {
      Consume(param_types[i]);
    }
    for (int i = return_index; i > 0; --i) {
      Convert(param_types[i], param_types[i - 1]);
      builder_->EmitI32Const(0);
      builder_->Emit(kExprSelect);
    }
    DCHECK(!return_types.empty());
    if (return_index >= 0) {
      Convert(param_types[0], return_types[0]);
      Generate(return_types + 1, data);
    } else {
      Generate(return_types, data);
    }
  }

  bool HasSimd() { return has_simd_; }

  void InitializeNonDefaultableLocals(DataRange* data) {
    for (uint32_t i = 0; i < locals_.size(); i++) {
      if (!locals_[i].is_defaultable()) {
        GenerateRef(locals_[i].heap_type(), data, kNonNullable);
        builder_->EmitWithU32V(
            kExprLocalSet, i + static_cast<uint32_t>(
                                   builder_->signature()->parameter_count()));
      }
    }
    locals_initialized_ = true;
  }

 private:
  WasmFunctionBuilder* builder_;
  std::vector<std::vector<ValueType>> blocks_;
  const std::vector<ModuleTypeIndex>& functions_;
  std::vector<ValueType> locals_;
  std::vector<ValueType> globals_;
  std::vector<uint8_t> mutable_globals_;  // indexes into {globals_}.
  uint32_t recursion_depth = 0;
  std::vector<int> catch_blocks_;
  bool has_simd_ = false;
  const std::vector<ModuleTypeIndex>& structs_;
  const std::vector<ModuleTypeIndex>& arrays_;
  const StringImports& string_imports_;
  bool locals_initialized_ = false;

  bool recursion_limit_reached() {
    return recursion_depth >= kMaxRecursionDepth;
  }
};

WasmInitExpr GenerateInitExpr(Zone* zone, DataRange& range,
                              WasmModuleBuilder* builder, ValueType type,
                              const std::vector<ModuleTypeIndex>& structs,
                              const std::vector<ModuleTypeIndex>& arrays,
                              uint32_t recursion_depth);

template <WasmModuleGenerationOptions options>
class ModuleGen {
 public:
  explicit ModuleGen(Zone* zone, WasmModuleBuilder* fn, DataRange* module_range,
                     uint8_t num_functions, uint8_t num_structs,
                     uint8_t num_arrays, uint8_t num_signatures)
      : zone_(zone),
        builder_(fn),
        module_range_(module_range),
        num_functions_(num_functions),
        num_structs_(num_structs),
        num_arrays_(num_arrays),
        num_signatures_(num_signatures),
        num_types_(num_signatures + num_structs + num_arrays) {}

  // Generates and adds random number of memories.
  void GenerateRandomMemories() {
    int num_memories = 1 + (module_range_->get<uint8_t>() % kMaxMemories);
    for (int i = 0; i < num_memories; i++) {
      uint8_t random_byte = module_range_->get<uint8_t>();
      bool mem64 = random_byte & 1;
      bool has_maximum = random_byte & 2;
      static_assert(kV8MaxWasmMemory64Pages <= kMaxUInt32);
      uint32_t max_supported_pages =
          mem64 ? kV8MaxWasmMemory64Pages : kV8MaxWasmMemory32Pages;
      uint32_t min_pages =
          module_range_->get<uint32_t>() % (max_supported_pages + 1);
      if (has_maximum) {
        uint32_t max_pages =
            std::max(min_pages, module_range_->get<uint32_t>() %
                                    (max_supported_pages + 1));
        if (mem64) {
          builder_->AddMemory64(min_pages, max_pages);
        } else {
          builder_->AddMemory(min_pages, max_pages);
        }
      } else {
        if (mem64) {
          builder_->AddMemory64(min_pages);
        } else {
          builder_->AddMemory(min_pages);
        }
      }
    }
  }

  // Puts the types into random recursive groups.
  std::map<uint8_t, uint8_t> GenerateRandomRecursiveGroups(
      uint8_t kNumDefaultArrayTypes) {
    // (Type_index -> end of explicit rec group).
    std::map<uint8_t, uint8_t> explicit_rec_groups;
    uint8_t current_type_index = 0;

    // The default array types are each in their own recgroup.
    for (uint8_t i = 0; i < kNumDefaultArrayTypes; i++) {
      explicit_rec_groups.emplace(current_type_index, current_type_index);
      builder_->AddRecursiveTypeGroup(current_type_index++, 1);
    }

    while (current_type_index < num_types_) {
      // First, pick a random start for the next group. We allow it to be
      // beyond the end of types (i.e., we add no further recursive groups).
      uint8_t group_start = module_range_->get<uint8_t>() %
                                (num_types_ - current_type_index + 1) +
                            current_type_index;
      DCHECK_GE(group_start, current_type_index);
      current_type_index = group_start;
      if (group_start < num_types_) {
        // If we did not reach the end of the types, pick a random group size.
        uint8_t group_size =
            module_range_->get<uint8_t>() % (num_types_ - group_start) + 1;
        DCHECK_LE(group_start + group_size, num_types_);
        for (uint8_t i = group_start; i < group_start + group_size; i++) {
          explicit_rec_groups.emplace(i, group_start + group_size - 1);
        }
        builder_->AddRecursiveTypeGroup(group_start, group_size);
        current_type_index += group_size;
      }
    }
    return explicit_rec_groups;
  }

  // Generates and adds random struct types.
  void GenerateRandomStructs(
      const std::map<uint8_t, uint8_t>& explicit_rec_groups,
      std::vector<ModuleTypeIndex>& struct_types, uint8_t& current_type_index,
      uint8_t kNumDefaultArrayTypes) {
    uint8_t last_struct_type_index = current_type_index + num_structs_;
    for (; current_type_index < last_struct_type_index; current_type_index++) {
      auto rec_group = explicit_rec_groups.find(current_type_index);
      uint8_t current_rec_group_end = rec_group != explicit_rec_groups.end()
                                          ? rec_group->second
                                          : current_type_index;

      ModuleTypeIndex supertype = kNoSuperType;
      uint8_t num_fields =
          module_range_->get<uint8_t>() % (kMaxStructFields + 1);

      uint32_t existing_struct_types =
          current_type_index - kNumDefaultArrayTypes;
      if (existing_struct_types > 0 && module_range_->get<bool>()) {
        supertype = ModuleTypeIndex{module_range_->get<uint8_t>() %
                                        existing_struct_types +
                                    kNumDefaultArrayTypes};
        num_fields += builder_->GetStructType(supertype)->field_count();
      }
      StructType::Builder struct_builder(zone_, num_fields);

      // Add all fields from super type.
      uint32_t field_index = 0;
      if (supertype != kNoSuperType) {
        const StructType* parent = builder_->GetStructType(supertype);
        for (; field_index < parent->field_count(); ++field_index) {
          // TODO(14034): This could also be any sub type of the supertype's
          // element type.
          struct_builder.AddField(parent->field(field_index),
                                  parent->mutability(field_index));
        }
      }
      for (; field_index < num_fields; field_index++) {
        // Notes:
        // - We allow a type to only have non-nullable fields of types that
        //   are defined earlier. This way we avoid infinite non-nullable
        //   constructions. Also relevant for arrays and functions.
        // - On the other hand, nullable fields can be picked up to the end of
        //   the current recursive group.
        // - We exclude the non-nullable generic types arrayref, anyref,
        //   structref, eqref and externref from the fields of structs and
        //   arrays. This is so that GenerateInitExpr has a way to break a
        //   recursion between a struct/array field and those types
        //   ((ref extern) gets materialized through (ref any)).
        ValueType type = GetValueTypeHelper<options>(
            module_range_, current_rec_group_end + 1, current_type_index,
            kIncludeNumericTypes, kIncludePackedTypes, kExcludeSomeGenerics);

        bool mutability = module_range_->get<bool>();
        struct_builder.AddField(type, mutability);
      }
      StructType* struct_fuz = struct_builder.Build();
      // TODO(14034): Generate some final types too.
      ModuleTypeIndex index =
          builder_->AddStructType(struct_fuz, false, supertype);
      struct_types.push_back(index);
    }
  }

  // Creates and adds random array types.
  void GenerateRandomArrays(
      const std::map<uint8_t, uint8_t>& explicit_rec_groups,
      std::vector<ModuleTypeIndex>& array_types, uint8_t& current_type_index) {
    uint32_t last_struct_type_index = current_type_index + num_structs_;
    for (; current_type_index < num_structs_ + num_arrays_;
         current_type_index++) {
      auto rec_group = explicit_rec_groups.find(current_type_index);
      uint8_t current_rec_group_end = rec_group != explicit_rec_groups.end()
                                          ? rec_group->second
                                          : current_type_index;
      ValueType type = GetValueTypeHelper<options>(
          module_range_, current_rec_group_end + 1, current_type_index,
          kIncludeNumericTypes, kIncludePackedTypes, kExcludeSomeGenerics);
      ModuleTypeIndex supertype = kNoSuperType;
      if (current_type_index > last_struct_type_index &&
          module_range_->get<bool>()) {
        // Do not include the default array types, because they are final.
        uint8_t existing_array_types =
            current_type_index - last_struct_type_index;
        supertype = ModuleTypeIndex{
            last_struct_type_index +
            (module_range_->get<uint8_t>() % existing_array_types)};
        // TODO(14034): This could also be any sub type of the supertype's
        // element type.
        type = builder_->GetArrayType(supertype)->element_type();
      }
      ArrayType* array_fuz = zone_->New<ArrayType>(type, true);
      // TODO(14034): Generate some final types too.
      ModuleTypeIndex index =
          builder_->AddArrayType(array_fuz, false, supertype);
      array_types.push_back(index);
    }
  }

  enum SigKind { kFunctionSig, kExceptionSig };

  FunctionSig* GenerateSig(SigKind sig_kind, int num_types) {
    // Generate enough parameters to spill some to the stack.
    int num_params = int{module_range_->get<uint8_t>()} % (kMaxParameters + 1);
    int num_returns =
        sig_kind == kFunctionSig
            ? int{module_range_->get<uint8_t>()} % (kMaxReturns + 1)
            : 0;

    FunctionSig::Builder builder(zone_, num_returns, num_params);
    for (int i = 0; i < num_returns; ++i) {
      builder.AddReturn(GetValueType<options>(module_range_, num_types));
    }
    for (int i = 0; i < num_params; ++i) {
      builder.AddParam(GetValueType<options>(module_range_, num_types));
    }
    return builder.Get();
  }

  // Creates and adds random function signatures.
  void GenerateRandomFunctionSigs(
      const std::map<uint8_t, uint8_t>& explicit_rec_groups,
      std::vector<ModuleTypeIndex>& function_signatures,
      uint8_t& current_type_index, bool kIsFinal) {
    // Recursive groups consist of recursive types that came with the WasmGC
    // proposal.
    DCHECK_IMPLIES(!ShouldGenerateWasmGC(options), explicit_rec_groups.empty());

    for (; current_type_index < num_types_; current_type_index++) {
      auto rec_group = explicit_rec_groups.find(current_type_index);
      uint8_t current_rec_group_end = rec_group != explicit_rec_groups.end()
                                          ? rec_group->second
                                          : current_type_index;
      FunctionSig* sig = GenerateSig(kFunctionSig, current_rec_group_end + 1);
      ModuleTypeIndex signature_index =
          builder_->ForceAddSignature(sig, kIsFinal);
      function_signatures.push_back(signature_index);
    }
  }

  void GenerateRandomExceptions(uint8_t num_exceptions) {
    for (int i = 0; i < num_exceptions; ++i) {
      FunctionSig* sig = GenerateSig(kExceptionSig, num_types_);
      builder_->AddTag(sig);
    }
  }

  // Adds the "wasm:js-string" imports to the module.
  StringImports AddImportedStringImports() {
    static constexpr ModuleTypeIndex kArrayI8{0};
    static constexpr ModuleTypeIndex kArrayI16{1};
    StringImports strings;
    strings.array_i8 = kArrayI8;
    strings.array_i16 = kArrayI16;
    static constexpr ValueType kRefExtern = ValueType::Ref(HeapType::kExtern);
    static constexpr ValueType kExternRef = kWasmExternRef;
    static constexpr ValueType kI32 = kWasmI32;
    static constexpr ValueType kRefA8 = ValueType::Ref(kArrayI8);
    static constexpr ValueType kRefNullA8 = ValueType::RefNull(kArrayI8);
    static constexpr ValueType kRefNullA16 = ValueType::RefNull(kArrayI16);

    // Shorthands: "r" = nullable "externref",
    // "e" = non-nullable "ref extern".
    static constexpr ValueType kReps_e_i[] = {kRefExtern, kI32};
    static constexpr ValueType kReps_e_rr[] = {kRefExtern, kExternRef,
                                               kExternRef};
    static constexpr ValueType kReps_e_rii[] = {kRefExtern, kExternRef, kI32,
                                                kI32};
    static constexpr ValueType kReps_i_ri[] = {kI32, kExternRef, kI32};
    static constexpr ValueType kReps_i_rr[] = {kI32, kExternRef, kExternRef};
    static constexpr ValueType kReps_from_a16[] = {kRefExtern, kRefNullA16,
                                                   kI32, kI32};
    static constexpr ValueType kReps_from_a8[] = {kRefExtern, kRefNullA8, kI32,
                                                  kI32};
    static constexpr ValueType kReps_into_a16[] = {kI32, kExternRef,
                                                   kRefNullA16, kI32};
    static constexpr ValueType kReps_into_a8[] = {kI32, kExternRef, kRefNullA8,
                                                  kI32};
    static constexpr ValueType kReps_to_a8[] = {kRefA8, kExternRef};

    static constexpr FunctionSig kSig_e_i(1, 1, kReps_e_i);
    static constexpr FunctionSig kSig_e_r(1, 1, kReps_e_rr);
    static constexpr FunctionSig kSig_e_rr(1, 2, kReps_e_rr);
    static constexpr FunctionSig kSig_e_rii(1, 3, kReps_e_rii);

    static constexpr FunctionSig kSig_i_r(1, 1, kReps_i_ri);
    static constexpr FunctionSig kSig_i_ri(1, 2, kReps_i_ri);
    static constexpr FunctionSig kSig_i_rr(1, 2, kReps_i_rr);
    static constexpr FunctionSig kSig_from_a16(1, 3, kReps_from_a16);
    static constexpr FunctionSig kSig_from_a8(1, 3, kReps_from_a8);
    static constexpr FunctionSig kSig_into_a16(1, 3, kReps_into_a16);
    static constexpr FunctionSig kSig_into_a8(1, 3, kReps_into_a8);
    static constexpr FunctionSig kSig_to_a8(1, 1, kReps_to_a8);

    static constexpr base::Vector<const char> kJsString =
        base::StaticCharVector("wasm:js-string");
    static constexpr base::Vector<const char> kTextDecoder =
        base::StaticCharVector("wasm:text-decoder");
    static constexpr base::Vector<const char> kTextEncoder =
        base::StaticCharVector("wasm:text-encoder");

#define STRINGFUNC(name, sig, group) \
  strings.name = builder_->AddImport(base::CStrVector(#name), &sig, group)

    STRINGFUNC(cast, kSig_e_r, kJsString);
    STRINGFUNC(test, kSig_i_r, kJsString);
    STRINGFUNC(fromCharCode, kSig_e_i, kJsString);
    STRINGFUNC(fromCodePoint, kSig_e_i, kJsString);
    STRINGFUNC(charCodeAt, kSig_i_ri, kJsString);
    STRINGFUNC(codePointAt, kSig_i_ri, kJsString);
    STRINGFUNC(length, kSig_i_r, kJsString);
    STRINGFUNC(concat, kSig_e_rr, kJsString);
    STRINGFUNC(substring, kSig_e_rii, kJsString);
    STRINGFUNC(equals, kSig_i_rr, kJsString);
    STRINGFUNC(compare, kSig_i_rr, kJsString);
    STRINGFUNC(fromCharCodeArray, kSig_from_a16, kJsString);
    STRINGFUNC(intoCharCodeArray, kSig_into_a16, kJsString);
    STRINGFUNC(measureStringAsUTF8, kSig_i_r, kTextEncoder);
    STRINGFUNC(encodeStringIntoUTF8Array, kSig_into_a8, kTextEncoder);
    STRINGFUNC(encodeStringToUTF8Array, kSig_to_a8, kTextEncoder);
    STRINGFUNC(decodeStringFromUTF8Array, kSig_from_a8, kTextDecoder);

#undef STRINGFUNC

    return strings;
  }

  // Creates and adds random tables.
  void GenerateRandomTables(const std::vector<ModuleTypeIndex>& array_types,
                            const std::vector<ModuleTypeIndex>& struct_types) {
    int num_tables = module_range_->get<uint8_t>() % kMaxTables + 1;
    int are_table64 = module_range_->get<uint8_t>();
    static_assert(
        kMaxTables <= 8,
        "Too many tables. Use more random bits to choose their address type.");
    for (int i = 0; i < num_tables; i++) {
      uint32_t min_size = i == 0
                              ? num_functions_
                              : module_range_->get<uint8_t>() % kMaxTableSize;
      uint32_t max_size =
          module_range_->get<uint8_t>() % (kMaxTableSize - min_size) + min_size;
      // Table 0 is always funcref. This guarantees that
      // - call_indirect has at least one funcref table to work with,
      // - we have a place to reference all functions in the program, so they
      //   count as "declared" for ref.func.
      bool force_funcref = i == 0;
      ValueType type =
          force_funcref
              ? kWasmFuncRef
              : GetValueTypeHelper<options>(
                    module_range_, num_types_, num_types_, kExcludeNumericTypes,
                    kExcludePackedTypes, kIncludeAllGenerics);
      bool use_initializer =
          !type.is_defaultable() || module_range_->get<bool>();
      AddressType address_type =
          (are_table64 & 1) ? AddressType::kI32 : AddressType::kI64;
      are_table64 >>= 1;
      uint32_t table_index =
          use_initializer
              ? builder_->AddTable(
                    type, min_size, max_size,
                    GenerateInitExpr(zone_, *module_range_, builder_, type,
                                     struct_types, array_types, 0),
                    address_type)
              : builder_->AddTable(type, min_size, max_size, address_type);
      if (type.is_reference_to(HeapType::kFunc)) {
        // For function tables, initialize them with functions from the program.
        // Currently, the fuzzer assumes that every funcref/(ref func) table
        // contains the functions in the program in the order they are defined.
        // TODO(11954): Consider generalizing this.
        WasmInitExpr init_expr = builder_->IsTable64(table_index)
                                     ? WasmInitExpr(static_cast<int64_t>(0))
                                     : WasmInitExpr(static_cast<int32_t>(0));
        WasmModuleBuilder::WasmElemSegment segment(zone_, type, table_index,
                                                   init_expr);
        for (int entry_index = 0; entry_index < static_cast<int>(min_size);
             entry_index++) {
          segment.entries.emplace_back(
              WasmModuleBuilder::WasmElemSegment::Entry::kRefFuncEntry,
              builder_->NumImportedFunctions() +
                  (entry_index % num_functions_));
        }
        builder_->AddElementSegment(std::move(segment));
      }
    }
  }

  // Creates and adds random globals.
  std::tuple<std::vector<ValueType>, std::vector<uint8_t>>
  GenerateRandomGlobals(const std::vector<ModuleTypeIndex>& array_types,
                        const std::vector<ModuleTypeIndex>& struct_types) {
    int num_globals = module_range_->get<uint8_t>() % (kMaxGlobals + 1);
    std::vector<ValueType> globals;
    std::vector<uint8_t> mutable_globals;
    globals.reserve(num_globals);
    mutable_globals.reserve(num_globals);

    for (int i = 0; i < num_globals; ++i) {
      ValueType type = GetValueType<options>(module_range_, num_types_);
      // 1/8 of globals are immutable.
      const bool mutability = (module_range_->get<uint8_t>() % 8) != 0;
      builder_->AddGlobal(type, mutability,
                          GenerateInitExpr(zone_, *module_range_, builder_,
                                           type, struct_types, array_types, 0));
      globals.push_back(type);
      if (mutability) mutable_globals.push_back(static_cast<uint8_t>(i));
    }

    return {globals, mutable_globals};
  }

 private:
  Zone* zone_;
  WasmModuleBuilder* builder_;
  DataRange* module_range_;
  const uint8_t num_functions_;
  const uint8_t num_structs_;
  const uint8_t num_arrays_;
  const uint8_t num_signatures_;
  const uint16_t num_types_;
};

WasmInitExpr GenerateStructNewInitExpr(
    Zone* zone, DataRange& range, WasmModuleBuilder* builder,
    ModuleTypeIndex index, const std::vector<ModuleTypeIndex>& structs,
    const std::vector<ModuleTypeIndex>& arrays, uint32_t recursion_depth) {
  const StructType* struct_type = builder->GetStructType(index);
  bool use_new_default =
      std::all_of(struct_type->fields().begin(), struct_type->fields().end(),
                  [](ValueType type) { return type.is_defaultable(); }) &&
      range.get<bool>();

  if (use_new_default) {
    return WasmInitExpr::StructNewDefault(index);
  } else {
    ZoneVector<WasmInitExpr>* elements =
        zone->New<ZoneVector<WasmInitExpr>>(zone);
    int field_count = struct_type->field_count();
    for (int field_index = 0; field_index < field_count; field_index++) {
      elements->push_back(GenerateInitExpr(
          zone, range, builder, struct_type->field(field_index), structs,
          arrays, recursion_depth + 1));
    }
    return WasmInitExpr::StructNew(index, elements);
  }
}

WasmInitExpr GenerateArrayInitExpr(Zone* zone, DataRange& range,
                                   WasmModuleBuilder* builder,
                                   ModuleTypeIndex index,
                                   const std::vector<ModuleTypeIndex>& structs,
                                   const std::vector<ModuleTypeIndex>& arrays,
                                   uint32_t recursion_depth) {
  constexpr int kMaxArrayLength = 20;
  uint8_t choice = range.get<uint8_t>() % 3;
  ValueType element_type = builder->GetArrayType(index)->element_type();
  if (choice == 0) {
    size_t element_count = range.get<uint8_t>() % kMaxArrayLength;
    if (!element_type.is_defaultable()) {
      // If the element type is not defaultable, limit the size to 0 or 1
      // to prevent having to create too many such elements on the value
      // stack. (With multiple non-nullable references, this can explode
      // in size very quickly.)
      element_count %= 2;
    }
    ZoneVector<WasmInitExpr>* elements =
        zone->New<ZoneVector<WasmInitExpr>>(zone);
    for (size_t i = 0; i < element_count; i++) {
      elements->push_back(GenerateInitExpr(zone, range, builder, element_type,
                                           structs, arrays,
                                           recursion_depth + 1));
    }
    return WasmInitExpr::ArrayNewFixed(index, elements);
  } else if (choice == 1 || !element_type.is_defaultable()) {
    // TODO(14034): Add other int expressions to length (same below).
    WasmInitExpr length = WasmInitExpr(range.get<uint8_t>() % kMaxArrayLength);
    WasmInitExpr init = GenerateInitExpr(zone, range, builder, element_type,
                                         structs, arrays, recursion_depth + 1);
    return WasmInitExpr::ArrayNew(zone, index, init, length);
  } else {
    WasmInitExpr length = WasmInitExpr(range.get<uint8_t>() % kMaxArrayLength);
    return WasmInitExpr::ArrayNewDefault(zone, index, length);
  }
}

WasmInitExpr GenerateInitExpr(Zone* zone, DataRange& range,
                              WasmModuleBuilder* builder, ValueType type,
                              const std::vector<ModuleTypeIndex>& structs,
                              const std::vector<ModuleTypeIndex>& arrays,
                              uint32_t recursion_depth) {
  switch (type.kind()) {
    case kI8:
    case kI16:
    case kI32: {
      if (range.size() == 0 || recursion_depth >= kMaxRecursionDepth) {
        return WasmInitExpr(int32_t{0});
      }
      // 50% to generate a constant, 50% to generate a binary operator.
      uint8_t choice = range.get<uint8_t>() % 6;
      switch (choice) {
        case 0:
        case 1:
        case 2:
          if (choice % 2 == 0 && builder->NumGlobals()) {
            // Search for a matching global to emit a global.get.
            int num_globals = builder->NumGlobals();
            int start_index = range.get<uint8_t>() % num_globals;
            for (int i = 0; i < num_globals; ++i) {
              int index = (start_index + i) % num_globals;
              if (builder->GetGlobalType(index) == type &&
                  !builder->IsMutableGlobal(index)) {
                return WasmInitExpr::GlobalGet(index);
              }
            }
            // Fall back to constant if no matching global was found.
          }
          return WasmInitExpr(range.getPseudoRandom<int32_t>());
        default:
          WasmInitExpr::Operator op = choice == 3   ? WasmInitExpr::kI32Add
                                      : choice == 4 ? WasmInitExpr::kI32Sub
                                                    : WasmInitExpr::kI32Mul;
          return WasmInitExpr::Binop(
              zone, op,
              GenerateInitExpr(zone, range, builder, kWasmI32, structs, arrays,
                               recursion_depth + 1),
              GenerateInitExpr(zone, range, builder, kWasmI32, structs, arrays,
                               recursion_depth + 1));
      }
    }
    case kI64: {
      if (range.size() == 0 || recursion_depth >= kMaxRecursionDepth) {
        return WasmInitExpr(int64_t{0});
      }
      // 50% to generate a constant, 50% to generate a binary operator.
      uint8_t choice = range.get<uint8_t>() % 6;
      switch (choice) {
        case 0:
        case 1:
        case 2:
          return WasmInitExpr(range.get<int64_t>());
        default:
          WasmInitExpr::Operator op = choice == 3   ? WasmInitExpr::kI64Add
                                      : choice == 4 ? WasmInitExpr::kI64Sub
                                                    : WasmInitExpr::kI64Mul;
          return WasmInitExpr::Binop(
              zone, op,
              GenerateInitExpr(zone, range, builder, kWasmI64, structs, arrays,
                               recursion_depth + 1),
              GenerateInitExpr(zone, range, builder, kWasmI64, structs, arrays,
                               recursion_depth + 1));
      }
    }
    case kF16:
    case kF32:
      return WasmInitExpr(0.0f);
    case kF64:
      return WasmInitExpr(0.0);
    case kS128: {
      uint8_t s128_const[kSimd128Size] = {0};
      return WasmInitExpr(s128_const);
    }
    case kRefNull: {
      bool null_only = false;
      switch (type.heap_representation()) {
        case HeapType::kNone:
        case HeapType::kNoFunc:
        case HeapType::kNoExtern:
          null_only = true;
          break;
        default:
          break;
      }
      if (range.size() == 0 || recursion_depth >= kMaxRecursionDepth ||
          null_only || (range.get<uint8_t>() % 4 == 0)) {
        return WasmInitExpr::RefNullConst(type.heap_type().representation());
      }
      [[fallthrough]];
    }
    case kRef: {
      switch (type.heap_representation()) {
        case HeapType::kStruct: {
          ModuleTypeIndex index =
              structs[range.get<uint8_t>() % structs.size()];
          return GenerateStructNewInitExpr(zone, range, builder, index, structs,
                                           arrays, recursion_depth);
        }
        case HeapType::kAny: {
          // Do not use 0 as the determining value here, otherwise an exhausted
          // {range} will generate an infinite recursion with the {kExtern}
          // case.
          if (recursion_depth < kMaxRecursionDepth && range.size() > 0 &&
              range.get<uint8_t>() % 4 == 3) {
            return WasmInitExpr::AnyConvertExtern(
                zone,
                GenerateInitExpr(zone, range, builder,
                                 ValueType::RefMaybeNull(HeapType::kExtern,
                                                         type.nullability()),
                                 structs, arrays, recursion_depth + 1));
          }
          [[fallthrough]];
        }
        case HeapType::kEq: {
          uint8_t choice = range.get<uint8_t>() % 3;
          HeapType::Representation subtype = choice == 0   ? HeapType::kI31
                                             : choice == 1 ? HeapType::kArray
                                                           : HeapType::kStruct;

          return GenerateInitExpr(
              zone, range, builder,
              ValueType::RefMaybeNull(subtype, type.nullability()), structs,
              arrays, recursion_depth);
        }
        case HeapType::kFunc: {
          uint32_t index =
              range.get<uint32_t>() % (builder->NumDeclaredFunctions() +
                                       builder->NumImportedFunctions());
          return WasmInitExpr::RefFuncConst(index);
        }
        case HeapType::kExtern:
          return WasmInitExpr::ExternConvertAny(
              zone, GenerateInitExpr(zone, range, builder,
                                     ValueType::RefMaybeNull(
                                         HeapType::kAny, type.nullability()),
                                     structs, arrays, recursion_depth + 1));
        case HeapType::kI31:
          return WasmInitExpr::RefI31(
              zone, GenerateInitExpr(zone, range, builder, kWasmI32, structs,
                                     arrays, recursion_depth + 1));
        case HeapType::kArray: {
          ModuleTypeIndex index = arrays[range.get<uint8_t>() % arrays.size()];
          return GenerateArrayInitExpr(zone, range, builder, index, structs,
                                       arrays, recursion_depth);
        }
        case HeapType::kNone:
        case HeapType::kNoFunc:
        case HeapType::kNoExtern:
          UNREACHABLE();
        default: {
          ModuleTypeIndex index = type.ref_index();
          if (builder->IsStructType(index)) {
            return GenerateStructNewInitExpr(zone, range, builder, index,
                                             structs, arrays, recursion_depth);
          } else if (builder->IsArrayType(index)) {
            return GenerateArrayInitExpr(zone, range, builder, index, structs,
                                         arrays, recursion_depth);
          } else {
            DCHECK(builder->IsSignature(index));
            for (int i = 0; i < builder->NumDeclaredFunctions(); ++i) {
              if (builder->GetFunction(i)->sig_index() == index) {
                return WasmInitExpr::RefFuncConst(
                    builder->NumImportedFunctions() + i);
              }
            }
            // There has to be at least one function per signature, otherwise
            // the init expression is unable to generate a non-nullable
            // reference with the correct type.
            UNREACHABLE();
          }
          UNREACHABLE();
        }
      }
    }
    case kVoid:
    case kRtt:
    case kTop:
    case kBottom:
      UNREACHABLE();
  }
}

}  // namespace

template <WasmModuleGenerationOptions options>
base::Vector<uint8_t> GenerateRandomWasmModule(
    Zone* zone, base::Vector<const uint8_t> data) {
  WasmModuleBuilder builder(zone);

  // Split input data in two parts:
  // - One for the "module" (types, globals, ..)
  // - One for all the function bodies
  // This prevents using a too large portion on the module resulting in
  // uninteresting function bodies.
  DataRange module_range(data);
  DataRange functions_range = module_range.split();
  std::vector<ModuleTypeIndex> function_signatures;

  static_assert(kMaxFunctions >= 1, "need min. 1 function");
  uint8_t num_functions = 1 + (module_range.get<uint8_t>() % kMaxFunctions);

  // In case of WasmGC expressions:
  // Add struct and array types first so that we get a chance to generate
  // these types in function signatures.
  // Currently, `BodyGen` assumes this order for struct/array/signature
  // definitions.
  // Otherwise, for non-WasmGC we can't use structs/arrays.
  uint8_t num_structs = 0;
  uint8_t num_arrays = 0;
  std::vector<ModuleTypeIndex> array_types;
  std::vector<ModuleTypeIndex> struct_types;

  // In case of WasmGC expressions:
  // We always add two default array types with mutable i8 and i16 elements,
  // respectively.
  constexpr uint8_t kNumDefaultArrayTypesForWasmGC = 2;
  if constexpr (ShouldGenerateWasmGC(options)) {
    // We need at least one struct and one array in order to support
    // WasmInitExpr for abstract types.
    num_structs = 1 + module_range.get<uint8_t>() % kMaxStructs;
    num_arrays = kNumDefaultArrayTypesForWasmGC +
                 module_range.get<uint8_t>() % kMaxArrays;
  }

  uint8_t num_signatures = num_functions;
  ModuleGen<options> gen_module(zone, &builder, &module_range, num_functions,
                                num_structs, num_arrays, num_signatures);

  // Add random number of memories.
  // TODO(v8:14674): Add a mode without declaring any memory or memory
  // instructions.
  gen_module.GenerateRandomMemories();

  uint8_t current_type_index = 0;
  // In case of WasmGC expressions, we create recursive groups for the recursive
  // types.
  std::map<uint8_t, uint8_t> explicit_rec_groups;
  if constexpr (ShouldGenerateWasmGC(options)) {
    // Put the types into random recursive groups.
    explicit_rec_groups = gen_module.GenerateRandomRecursiveGroups(
        kNumDefaultArrayTypesForWasmGC);

    // Add default array types.
    static constexpr ModuleTypeIndex kArrayI8{0};
    static constexpr ModuleTypeIndex kArrayI16{1};
    {
      ArrayType* a8 = zone->New<ArrayType>(kWasmI8, 1);
      CHECK_EQ(kArrayI8, builder.AddArrayType(a8, true, kNoSuperType));
      array_types.push_back(kArrayI8);
      ArrayType* a16 = zone->New<ArrayType>(kWasmI16, 1);
      CHECK_EQ(kArrayI16, builder.AddArrayType(a16, true, kNoSuperType));
      array_types.push_back(kArrayI16);
    }
    static_assert(kNumDefaultArrayTypesForWasmGC == kArrayI16.index + 1);
    current_type_index = kNumDefaultArrayTypesForWasmGC;

    // Add randomly generated structs.
    gen_module.GenerateRandomStructs(explicit_rec_groups, struct_types,
                                     current_type_index,
                                     kNumDefaultArrayTypesForWasmGC);
    DCHECK_EQ(current_type_index, kNumDefaultArrayTypesForWasmGC + num_structs);

    // Add randomly generated arrays.
    gen_module.GenerateRandomArrays(explicit_rec_groups, array_types,
                                    current_type_index);
    DCHECK_EQ(current_type_index, num_structs + num_arrays);
  }

  // We keep the signature for the first (main) function constant.
  constexpr bool kIsFinal = true;
  auto kMainFnSig = FixedSizeSignature<ValueType>::Returns(kWasmI32).Params(
      kWasmI32, kWasmI32, kWasmI32);
  function_signatures.push_back(
      builder.ForceAddSignature(&kMainFnSig, kIsFinal));
  current_type_index++;

  // Add randomly generated signatures.
  gen_module.GenerateRandomFunctionSigs(
      explicit_rec_groups, function_signatures, current_type_index, kIsFinal);
  DCHECK_EQ(current_type_index, num_functions + num_structs + num_arrays);

  // Add exceptions.
  int num_exceptions = 1 + (module_range.get<uint8_t>() % kMaxExceptions);
  gen_module.GenerateRandomExceptions(num_exceptions);

  // In case of WasmGC expressions:
  // Add the "wasm:js-string" imports to the module. They may or may not be
  // used later, but they'll always be available.
  StringImports strings = ShouldGenerateWasmGC(options)
                              ? gen_module.AddImportedStringImports()
                              : StringImports();

  // Generate function declarations before tables. This will be needed once we
  // have typed-function tables.
  std::vector<WasmFunctionBuilder*> functions;
  for (uint8_t i = 0; i < num_functions; i++) {
    // If we are using wasm-gc, we cannot allow signature normalization
    // performed by adding a function by {FunctionSig}, because we emit
    // everything in one recursive group which blocks signature
    // canonicalization.
    // TODO(14034): Relax this when we implement proper recursive-group
    // support.
    functions.push_back(builder.AddFunction(function_signatures[i]));
  }

  // Generate tables before function bodies, so they are available for table
  // operations. Generate tables before the globals, so tables don't
  // accidentally use globals in their initializer expressions.
  // Always generate at least one table for call_indirect.
  gen_module.GenerateRandomTables(array_types, struct_types);

  // Add globals.
  auto [globals, mutable_globals] =
      gen_module.GenerateRandomGlobals(array_types, struct_types);

  // Add passive data segments.
  int num_data_segments = module_range.get<uint8_t>() % kMaxPassiveDataSegments;
  for (int i = 0; i < num_data_segments; i++) {
    GeneratePassiveDataSegment(&module_range, &builder);
  }

  // Generate function bodies.
  for (int i = 0; i < num_functions; ++i) {
    WasmFunctionBuilder* f = functions[i];
    // On the last function don't split the DataRange but just use the
    // existing DataRange.
    DataRange function_range = i != num_functions - 1
                                   ? functions_range.split()
                                   : std::move(functions_range);
    BodyGen<options> gen_body(f, function_signatures, globals, mutable_globals,
                              struct_types, array_types, strings,
                              &function_range);
    const FunctionSig* sig = f->signature();
    base::Vector<const ValueType> return_types(sig->returns().begin(),
                                               sig->return_count());
    gen_body.InitializeNonDefaultableLocals(&function_range);
    gen_body.Generate(return_types, &function_range);
    // TODO(v8:14639): Disable SIMD expressions if needed, so that a module is
    // always generated.
    if (ShouldGenerateSIMD(options) && !CheckHardwareSupportsSimd() &&
        gen_body.HasSimd()) {
      return {};
    }
    f->Emit(kExprEnd);
    if (i == 0) builder.AddExport(base::CStrVector("main"), f);
  }

  ZoneBuffer buffer{zone};
  builder.WriteTo(&buffer);
  return base::VectorOf(buffer);
}

// Used by the initializer expression fuzzer.
base::Vector<uint8_t> GenerateWasmModuleForInitExpressions(
    Zone* zone, base::Vector<const uint8_t> data, size_t* count) {
  // Don't limit expressions for the initializer expression fuzzer.
  constexpr WasmModuleGenerationOptions options =
      WasmModuleGenerationOptions::kGenerateAll;
  WasmModuleBuilder builder(zone);

  DataRange module_range(data);
  std::vector<ModuleTypeIndex> function_signatures;
  std::vector<ModuleTypeIndex> array_types;
  std::vector<ModuleTypeIndex> struct_types;

  int num_globals = 1 + module_range.get<uint8_t>() % (kMaxGlobals + 1);

  uint8_t num_functions = num_globals;
  *count = num_functions;

  // We need at least one struct and one array in order to support
  // WasmInitExpr for abstract types.
  uint8_t num_structs = 1 + module_range.get<uint8_t>() % kMaxStructs;
  uint8_t num_arrays = 1 + module_range.get<uint8_t>() % kMaxArrays;
  uint16_t num_types = num_functions + num_structs + num_arrays;

  uint8_t current_type_index = 0;

  // Add random-generated types.
  uint8_t last_struct_type = current_type_index + num_structs;
  for (; current_type_index < last_struct_type; current_type_index++) {
    ModuleTypeIndex supertype = kNoSuperType;
    uint8_t num_fields = module_range.get<uint8_t>() % (kMaxStructFields + 1);

    uint32_t existing_struct_types = current_type_index;
    if (existing_struct_types > 0 && module_range.get<bool>()) {
      supertype =
          ModuleTypeIndex{module_range.get<uint8_t>() % existing_struct_types};
      num_fields += builder.GetStructType(supertype)->field_count();
    }
    StructType::Builder struct_builder(zone, num_fields);

    // Add all fields from super type.
    uint32_t field_index = 0;
    if (supertype != kNoSuperType) {
      const StructType* parent = builder.GetStructType(supertype);
      for (; field_index < parent->field_count(); ++field_index) {
        struct_builder.AddField(parent->field(field_index),
                                parent->mutability(field_index));
      }
    }
    for (; field_index < num_fields; field_index++) {
      ValueType type = GetValueTypeHelper<options>(
          &module_range, current_type_index, current_type_index,
          kIncludeNumericTypes, kIncludePackedTypes, kExcludeSomeGenerics);

      bool mutability = module_range.get<bool>();
      struct_builder.AddField(type, mutability);
    }
    StructType* struct_fuz = struct_builder.Build();
    ModuleTypeIndex index = builder.AddStructType(struct_fuz, false, supertype);
    struct_types.push_back(index);
  }

  for (; current_type_index < num_structs + num_arrays; current_type_index++) {
    ValueType type = GetValueTypeHelper<options>(
        &module_range, current_type_index, current_type_index,
        kIncludeNumericTypes, kIncludePackedTypes, kExcludeSomeGenerics);
    ModuleTypeIndex supertype = kNoSuperType;
    if (current_type_index > last_struct_type && module_range.get<bool>()) {
      uint32_t existing_array_types = current_type_index - last_struct_type;
      supertype =
          ModuleTypeIndex{last_struct_type +
                          (module_range.get<uint8_t>() % existing_array_types)};
      type = builder.GetArrayType(supertype)->element_type();
    }
    ArrayType* array_fuz = zone->New<ArrayType>(type, true);
    ModuleTypeIndex index = builder.AddArrayType(array_fuz, false, supertype);
    array_types.push_back(index);
  }

  // Choose global types and create function signatures.
  constexpr bool kIsFinal = true;
  std::vector<ValueType> globals;
  for (; current_type_index < num_types; current_type_index++) {
    ValueType return_type = GetValueTypeHelper<options>(
        &module_range, num_types - num_globals, num_types - num_globals,
        kIncludeNumericTypes, kExcludePackedTypes, kIncludeAllGenerics,
        kExcludeS128);
    globals.push_back(return_type);
    // Create a new function signature for each global. These functions will be
    // used to compare against the initializer value of the global.
    FunctionSig::Builder sig_builder(zone, 1, 0);
    sig_builder.AddReturn(return_type);
    ModuleTypeIndex signature_index =
        builder.ForceAddSignature(sig_builder.Get(), kIsFinal);
    function_signatures.push_back(signature_index);
  }

  std::vector<WasmFunctionBuilder*> functions;
  for (uint8_t i = 0; i < num_functions; i++) {
    functions.push_back(builder.AddFunction(function_signatures[i]));
  }

  // Create globals.
  std::vector<uint8_t> mutable_globals;
  std::vector<WasmInitExpr> init_exprs;
  init_exprs.reserve(num_globals);
  mutable_globals.reserve(num_globals);
  CHECK_EQ(globals.size(), num_globals);
  uint64_t mutabilities = module_range.get<uint64_t>();
  for (int i = 0; i < num_globals; ++i) {
    ValueType type = globals[i];
    // 50% of globals are immutable.
    const bool mutability = mutabilities & 1;
    mutabilities >>= 1;
    WasmInitExpr init_expr = GenerateInitExpr(
        zone, module_range, &builder, type, struct_types, array_types, 0);
    init_exprs.push_back(init_expr);
    auto buffer = zone->AllocateVector<char>(8);
    size_t len = base::SNPrintF(buffer, "g%i", i);
    builder.AddExportedGlobal(type, mutability, init_expr,
                              {buffer.begin(), len});
    if (mutability) mutable_globals.push_back(static_cast<uint8_t>(i));
  }

  // Create functions containing the initializer of each global as its function
  // body.
  for (int i = 0; i < num_functions; ++i) {
    WasmFunctionBuilder* f = functions[i];
    f->EmitFromInitializerExpression(init_exprs[i]);
    auto buffer = zone->AllocateVector<char>(8);
    size_t len = base::SNPrintF(buffer, "f%i", i);
    builder.AddExport({buffer.begin(), len}, f);
  }

  ZoneBuffer buffer{zone};
  builder.WriteTo(&buffer);
  return base::VectorOf(buffer);
}

namespace {

bool HasSameReturns(const FunctionSig* a, const FunctionSig* b) {
  if (a->return_count() != b->return_count()) return false;
  for (size_t i = 0; i < a->return_count(); ++i) {
    if (a->GetReturn(i) != b->GetReturn(i)) return false;
  }
  return true;
}

template <WasmModuleGenerationOptions options>
void EmitDeoptAndReturnValues(BodyGen<options> gen_body, WasmFunctionBuilder* f,
                              const FunctionSig* target_sig,
                              ModuleTypeIndex target_sig_index,
                              uint32_t global_index, uint32_t table_index,
                              bool use_table64, DataRange* data) {
  base::Vector<const ValueType> return_types = f->signature()->returns();
  // Split the return types randomly and generate some values before the
  // deopting call and some afterwards. (This makes sure that we have deopts
  // where there are values on the wasm value stack which are not used by the
  // deopting call itself.)
  uint32_t returns_split = data->get<uint8_t>() % (return_types.size() + 1);
  if (returns_split) {
    gen_body.Generate(return_types.SubVector(0, returns_split), data);
  }
  gen_body.Generate(target_sig->parameters(), data);
  f->EmitWithU32V(kExprGlobalGet, global_index);
  if (use_table64) {
    f->Emit(kExprI64UConvertI32);
  }
  // Tail calls can only be emitted if the return types match.
  bool same_returns = HasSameReturns(target_sig, f->signature());
  size_t option_count = (same_returns + 1) * 2;
  switch (data->get<uint8_t>() % option_count) {
    case 0:
      // Emit call_ref.
      f->Emit(kExprTableGet);
      f->EmitU32V(table_index);
      f->EmitWithPrefix(kExprRefCast);
      f->EmitI32V(target_sig_index);
      f->EmitWithU32V(kExprCallRef, target_sig_index);
      break;
    case 1:
      // Emit call_indirect.
      f->EmitWithU32V(kExprCallIndirect, target_sig_index);
      f->EmitByte(table_index);
      break;
    case 2:
      // Emit return_call_ref.
      f->Emit(kExprTableGet);
      f->EmitU32V(table_index);
      f->EmitWithPrefix(kExprRefCast);
      f->EmitI32V(target_sig_index);
      f->EmitWithU32V(kExprReturnCallRef, target_sig_index);
      break;
    case 3:
      // Emit return_call_indirect.
      f->EmitWithU32V(kExprReturnCallIndirect, target_sig_index);
      f->EmitByte(table_index);
      break;
    default:
      UNREACHABLE();
  }
  gen_body.ConsumeAndGenerate(target_sig->returns(),
                              return_types.SubVectorFrom(returns_split), data);
}

template <WasmModuleGenerationOptions options>
void EmitCallAndReturnValues(BodyGen<options> gen_body, WasmFunctionBuilder* f,
                             WasmFunctionBuilder* callee, uint32_t table_index,
                             bool use_table64, DataRange* data) {
  const FunctionSig* callee_sig = callee->signature();
  uint32_t callee_index =
      callee->func_index() + gen_body.NumImportedFunctions();

  base::Vector<const ValueType> return_types = f->signature()->returns();
  // Split the return types randomly and generate some values before the
  // deopting call and some afterwards to create more interesting test cases.
  uint32_t returns_split = data->get<uint8_t>() % (return_types.size() + 1);
  if (returns_split) {
    gen_body.Generate(return_types.SubVector(0, returns_split), data);
  }
  gen_body.Generate(callee_sig->parameters(), data);
  // Tail calls can only be emitted if the return types match.
  bool same_returns = HasSameReturns(callee_sig, f->signature());
  size_t option_count = (same_returns + 1) * 3;
  switch (data->get<uint8_t>() % option_count) {
    case 0:
      f->EmitWithU32V(kExprCallFunction, callee_index);
      break;
    case 1:
      f->EmitWithU32V(kExprRefFunc, callee_index);
      f->EmitWithU32V(kExprCallRef, callee->sig_index());
      break;
    case 2:
      // Note that this assumes that the declared function index is the same as
      // the index of the function in the table.
      use_table64 ? f->EmitI64Const(callee->func_index())
                  : f->EmitI32Const(callee->func_index());
      f->EmitWithU32V(kExprCallIndirect, callee->sig_index());
      f->EmitByte(table_index);
      break;
    case 3:
      f->EmitWithU32V(kExprReturnCall, callee_index);
      break;
    case 4:
      f->EmitWithU32V(kExprRefFunc, callee_index);
      f->EmitWithU32V(kExprReturnCallRef, callee->sig_index());
      break;
    case 5:
      // Note that this assumes that the declared function index is the same as
      // the index of the function in the table.
      use_table64 ? f->EmitI64Const(callee->func_index())
                  : f->EmitI32Const(callee->func_index());
      f->EmitWithU32V(kExprReturnCallIndirect, callee->sig_index());
      f->EmitByte(table_index);
      break;
    default:
      UNREACHABLE();
  }
  gen_body.ConsumeAndGenerate(callee_sig->returns(),
                              return_types.SubVectorFrom(returns_split), data);
}
}  // anonymous namespace

base::Vector<uint8_t> GenerateWasmModuleForDeopt(
    Zone* zone, base::Vector<const uint8_t> data,
    std::vector<std::string>& callees, std::vector<std::string>& inlinees) {
  // Don't limit the features for the deopt fuzzer.
  constexpr WasmModuleGenerationOptions options =
      WasmModuleGenerationOptions::kGenerateAll;
  WasmModuleBuilder builder(zone);

  DataRange range(data);
  std::vector<ModuleTypeIndex> function_signatures;
  std::vector<ModuleTypeIndex> array_types;
  std::vector<ModuleTypeIndex> struct_types;

  const int kMaxCallTargets = 5;
  const int kMaxInlinees = 3;

  // We need at least 2 call targets to be able to trigger a deopt.
  const int num_call_targets = 2 + range.get<uint8_t>() % (kMaxCallTargets - 1);
  const int num_inlinees = range.get<uint8_t>() % (kMaxInlinees + 1);

  // 1 main function + x inlinees + x callees.
  uint8_t num_functions = 1 + num_inlinees + num_call_targets;
  // 1 signature for all the callees, 1 signature for the main function +
  // 1 signature per inlinee.
  uint8_t num_signatures = 2 + num_inlinees;

  uint8_t num_structs = 1 + range.get<uint8_t>() % kMaxStructs;
  // In case of WasmGC expressions:
  // We always add two default array types with mutable i8 and i16 elements,
  // respectively.
  constexpr uint8_t kNumDefaultArrayTypesForWasmGC = 2;
  uint8_t num_arrays =
      range.get<uint8_t>() % kMaxArrays + kNumDefaultArrayTypesForWasmGC;
  // Just ignoring user-defined signature types in the signatures.
  uint16_t num_types = num_structs + num_arrays;

  uint8_t current_type_index = kNumDefaultArrayTypesForWasmGC;

  // Add random-generated types.
  ModuleGen<options> gen_module(zone, &builder, &range, num_functions,
                                num_structs, num_arrays, num_signatures);

  gen_module.GenerateRandomMemories();
  std::map<uint8_t, uint8_t> explicit_rec_groups =
      gen_module.GenerateRandomRecursiveGroups(kNumDefaultArrayTypesForWasmGC);
  // Add default array types.
  static constexpr ModuleTypeIndex kArrayI8{0};
  static constexpr ModuleTypeIndex kArrayI16{1};
  {
    ArrayType* a8 = zone->New<ArrayType>(kWasmI8, true);
    CHECK_EQ(kArrayI8, builder.AddArrayType(a8, true, kNoSuperType));
    array_types.push_back(kArrayI8);
    ArrayType* a16 = zone->New<ArrayType>(kWasmI16, true);
    CHECK_EQ(kArrayI16, builder.AddArrayType(a16, true, kNoSuperType));
    array_types.push_back(kArrayI16);
  }
  static_assert(kNumDefaultArrayTypesForWasmGC == kArrayI16.index + 1);
  gen_module.GenerateRandomStructs(explicit_rec_groups, struct_types,
                                   current_type_index,
                                   kNumDefaultArrayTypesForWasmGC);
  DCHECK_EQ(current_type_index, kNumDefaultArrayTypesForWasmGC + num_structs);
  gen_module.GenerateRandomArrays(explicit_rec_groups, array_types,
                                  current_type_index);
  DCHECK_EQ(current_type_index, num_structs + num_arrays);

  // Create signature for call target.
  std::vector<ValueType> return_types =
      GenerateTypes<options>(&range, num_types);
  constexpr bool kIsFinal = true;
  const FunctionSig* target_sig = CreateSignature(
      builder.zone(), base::VectorOf(GenerateTypes<options>(&range, num_types)),
      base::VectorOf(return_types));
  ModuleTypeIndex target_sig_index =
      builder.ForceAddSignature(target_sig, kIsFinal);

  for (int i = 0; i < num_call_targets; ++i) {
    // Simplification: All call targets of a call_ref / call_indirect have the
    // same signature.
    function_signatures.push_back(target_sig_index);
  }

  // Create signatures for inlinees.
  // Use the same return types with a certain chance. This increases the chance
  // to emit return calls.
  uint8_t use_same_return = range.get<uint8_t>();
  for (int i = 0; i < num_inlinees; ++i) {
    if ((use_same_return & (1 << i)) == 0) {
      return_types = GenerateTypes<options>(&range, num_types);
    }
    const FunctionSig* inlinee_sig = CreateSignature(
        builder.zone(),
        base::VectorOf(GenerateTypes<options>(&range, num_types)),
        base::VectorOf(return_types));
    function_signatures.push_back(
        builder.ForceAddSignature(inlinee_sig, kIsFinal));
  }

  // Create signature for main function.
  const FunctionSig* main_sig = CreateSignature(
      builder.zone(), base::VectorOf({kWasmI32}), base::VectorOf({kWasmI32}));
  function_signatures.push_back(builder.ForceAddSignature(main_sig, kIsFinal));

  DCHECK_EQ(function_signatures.back().index,
            num_structs + num_arrays + num_signatures - 1);

  // This needs to be done after the signatures are added.
  int num_exceptions = 1 + range.get<uint8_t>() % kMaxExceptions;
  gen_module.GenerateRandomExceptions(num_exceptions);
  StringImports strings = gen_module.AddImportedStringImports();

  // Add functions to module.
  std::vector<WasmFunctionBuilder*> functions;
  DCHECK_EQ(num_functions, function_signatures.size());
  functions.reserve(num_functions);
  for (uint8_t i = 0; i < num_functions; i++) {
    functions.push_back(builder.AddFunction(function_signatures[i]));
  }

  uint32_t num_entries = num_call_targets + num_inlinees;
  bool use_table64 = range.get<bool>();
  AddressType address_type =
      use_table64 ? AddressType::kI64 : AddressType::kI32;
  uint32_t table_index =
      builder.AddTable(kWasmFuncRef, num_entries, num_entries, address_type);
  WasmModuleBuilder::WasmElemSegment segment(
      zone, kWasmFuncRef, table_index,
      use_table64 ? WasmInitExpr(int64_t{0}) : WasmInitExpr(0));
  for (uint32_t i = 0; i < num_entries; i++) {
    segment.entries.emplace_back(
        WasmModuleBuilder::WasmElemSegment::Entry::kRefFuncEntry,
        builder.NumImportedFunctions() + i);
  }
  builder.AddElementSegment(std::move(segment));

  gen_module.GenerateRandomTables(array_types, struct_types);

  // Create global for call target index.
  // Simplification: This global is used to specify the call target at the deopt
  // point instead of passing the call target around dynamically.
  uint32_t global_index =
      builder.AddExportedGlobal(kWasmI32, true, WasmInitExpr(0),
                                base::StaticCharVector("call_target_index"));

  // Create inlinee bodies.
  for (int i = 0; i < num_inlinees; ++i) {
    uint32_t declared_func_index = i + num_call_targets;
    WasmFunctionBuilder* f = functions[declared_func_index];
    DataRange function_range = range.split();
    BodyGen<options> gen_body(f, function_signatures, {}, {}, struct_types,
                              array_types, strings, &function_range);
    const FunctionSig* sig = f->signature();
    base::Vector<const ValueType> return_types(sig->returns().begin(),
                                               sig->return_count());
    gen_body.InitializeNonDefaultableLocals(&function_range);
    if (i == 0) {
      // For the inner-most inlinee, emit the deopt point (e.g. a call_ref).
      EmitDeoptAndReturnValues(gen_body, f, target_sig, target_sig_index,
                               global_index, table_index, use_table64,
                               &function_range);
    } else {
      // All other inlinees call the previous inlinee.
      uint32_t callee_declared_index = declared_func_index - 1;
      EmitCallAndReturnValues(gen_body, f, functions[callee_declared_index],
                              table_index, use_table64, &function_range);
    }
    // TODO(v8:14639): Disable SIMD expressions if needed, so that a module is
    // always generated.
    if (ShouldGenerateSIMD(options) && !CheckHardwareSupportsSimd() &&
        gen_body.HasSimd()) {
      return {};
    }
    f->Emit(kExprEnd);
    auto buffer = zone->AllocateVector<char>(32);
    size_t len = base::SNPrintF(buffer, "inlinee_%i", i);
    builder.AddExport({buffer.begin(), len}, f);
    inlinees.emplace_back(buffer.begin(), len);
  }

  // Create main function body.
  {
    uint32_t de
```