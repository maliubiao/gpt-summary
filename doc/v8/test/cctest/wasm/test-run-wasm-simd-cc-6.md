Response:
Let's break down the thought process for analyzing this V8 test file.

1. **Identify the Core Purpose:** The file name `test-run-wasm-simd.cc` immediately tells us this is a test file for WebAssembly (Wasm) SIMD (Single Instruction, Multiple Data) functionality within the V8 JavaScript engine. The `cctest` directory further indicates these are C++ tests.

2. **Examine the Includes and Namespaces (Implicit):** Though not explicitly shown in the provided snippet,  a full V8 test file would include headers for V8 internals, Wasm specifics, and testing frameworks. The namespace `v8::internal::wasm` and potentially others like `v8::internal::compiler` are likely in use. This provides context for the code constructs.

3. **Look for Key Test Structures:**  The presence of `TEST(...)` macros signifies the use of V8's testing framework. Each `TEST` block represents an individual test case. The names of the tests (e.g., `RunWasmTurbofan_S256Load8Splat`) provide clues about the specific SIMD operations being tested. "Turbofan" refers to V8's optimizing compiler, so these tests target optimized SIMD execution.

4. **Analyze Individual Test Cases:**  For each test:
    * **Check for CPU Feature Guards:**  Lines like `if (!CpuFeatures::IsSupported(AVX2)) return;` are crucial. They indicate that the test is only executed if the underlying hardware supports the required CPU features (in this case, AVX2). This is important for understanding the test's scope.
    * **Identify the `WasmRunner`:** The `WasmRunner` template class (e.g., `WasmRunner<int8_t> r(...)`) is a common V8 testing utility. It simplifies the process of creating and running Wasm modules within the test environment. The template argument (`int8_t` in this case) often represents the return type of the Wasm function being tested. The `TestExecutionTier::kTurbofan` argument confirms the focus on the optimizing compiler.
    * **Memory Allocation:**  `r.builder().AddMemoryElems<T>(size)` indicates the allocation of linear memory within the Wasm module. This memory is used for input data and observing output.
    * **Wasm Instructions:**  The `WASM_...` macros (e.g., `WASM_LOCAL_SET`, `WASM_SIMD_LOAD_OP`, `WASM_SIMD_STORE_MEM`) represent WebAssembly instructions. Understanding these instructions is key to deciphering the test's logic.
    * **Data Setup and Execution:** Look for code that initializes memory with specific values (e.g., `r.builder().WriteMemory(...)`) and then calls the Wasm function (`r.Call()`).
    * **Verification:** The `CHECK_EQ(...)` and `CHECK_TRAP(...)` macros are used to verify the correctness of the Wasm execution. They compare the actual results (often read from memory after the call) with expected values. `TSSimd256VerifyScope` suggests a mechanism to verify that specific SIMD instructions are generated by the compiler.
    * **Looping and Input Generation:**  `FOR_INT8_INPUTS(x)` and similar macros indicate loops that iterate through various input values to thoroughly test the Wasm code. `compiler::ValueHelper::GetVector<T>()` is another way to generate test data.

5. **Infer Functionality from Test Names and Instructions:**
    * Tests with names like `RunWasmTurbofan_S256Load8Splat` likely test the `s128.load8_splat` Wasm instruction, which loads a single byte and replicates it across a 128-bit SIMD vector. The "S256" part likely indicates testing in the context of 256-bit SIMD operations (likely through vectorization).
    * Tests with `LoadExtend` in the name (e.g., `S128Load8x8U`) test instructions that load smaller data types and extend them to larger ones within SIMD vectors.
    * Tests with `Shuffle` involve rearranging elements within SIMD vectors.
    * Tests with `Splat` create SIMD vectors where all elements have the same value.
    * Tests with `Phi` likely test the handling of Phi nodes in the compiler's intermediate representation, which are important for loop optimizations.
    * Tests with `ForcePack` are explicitly about testing the compiler's ability to pack 128-bit SIMD operations into 256-bit ones for better performance, even when the memory accesses aren't perfectly contiguous.
    * Tests with `Reduce` examine operations that combine elements of a SIMD vector into a single value.

6. **Relate to JavaScript (if applicable):**  While the test file is C++, the underlying Wasm functionality is often exposed to JavaScript. Think about how the tested Wasm SIMD operations correspond to JavaScript's `SIMD` API (e.g., `SIMD.int8x16`, `SIMD.float32x4`).

7. **Consider Potential User Errors:**  Tests that involve memory loads and stores, especially with offsets, are often designed to catch common programming errors like out-of-bounds access. The `CHECK_TRAP` macro confirms this.

8. **Synthesize a Summary:** Based on the analysis of the individual tests, identify the overarching purpose of the file and the categories of SIMD operations it covers.

**Self-Correction/Refinement During the Process:**

* **Initial Assumption Check:**  If a test name suggests a specific Wasm instruction, quickly verify if the code within the test actually uses that instruction.
* **Understanding Compiler Optimizations:** Realize that "Turbofan" tests are not just about functional correctness but also about how the optimizing compiler handles these operations. The `TSSimd256VerifyScope` is a strong hint of this.
* **Addressing Ambiguities:**  If a test's purpose isn't immediately clear from the name, carefully examine the sequence of Wasm instructions and the verification logic.
* **Connecting the Dots:**  Recognize patterns in the test code (e.g., the use of `WasmRunner`, memory allocation, `CHECK_EQ`) to streamline the analysis of subsequent tests.

By following these steps, we can systematically analyze a V8 test file like `test-run-wasm-simd.cc` and understand its functionality, even without being an expert in V8's internals.
好的，让我们来分析一下这段 V8 源代码 `v8/test/cctest/wasm/test-run-wasm-simd.cc` 的第 7 部分的功能。

**核心功能归纳：**

这段代码主要测试了 V8 的 Turbofan 优化编译器在处理 WebAssembly SIMD (Single Instruction, Multiple Data) 指令时的正确性和优化效果，特别是针对 256 位 SIMD 操作 (`S256` 前缀的测试) 以及一些特定的 SIMD 指令组合和优化场景。

**具体功能分解：**

1. **`TEST(RunWasmTurbofan_S256Load8x8U)` 和 `TEST(RunWasmTurbofan_S256Load8x8S)`:**
   - **功能:** 测试 `s128.load8x8_u` 和 `s128.load8x8_s` 指令的正确性，这两个指令将内存中的 8 个字节加载到 128 位 SIMD 寄存器中，并将结果分别进行零扩展 (unsigned) 和符号扩展 (signed) 到 16 位。同时，这些测试名称中的 "S256" 以及代码中的 `TSSimd256VerifyScope` 表明它们也在验证 Turbofan 能否将这些 128 位操作提升为 256 位 SIMD 操作进行优化。
   - **代码逻辑:**
     - 定义一个模板函数 `RunLoadExtendRevecTest`，用于测试这类加载并扩展的指令。
     - 分别测试了无符号和有符号的 8 位扩展到 16 位的情况。
     - 使用 `BUILD_LOADEXTEND` 宏构建 Wasm 代码，该宏设置了加载指令，并通过存储指令将结果写回内存进行验证。
     - 针对正常情况和越界访问情况分别进行了测试，`CHECK_TRAP` 用于验证越界访问会触发异常。
   - **假设输入与输出 (以 `S128Load8x8U` 为例):**
     - **假设输入:** 内存地址 `mem_index` 处存储了 8 个字节的数据，例如 `0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08`。
     - **预期输出:** 加载并零扩展后，128 位 SIMD 寄存器中前 8 个 16 位元素的值应为 `0x0001, 0x0002, 0x0003, 0x0004, 0x0005, 0x0006, 0x0007, 0x0008`。测试还会将这个结果存储回内存进行验证。
   - **用户常见的编程错误:** 访问内存越界。例如，尝试加载超出内存范围的字节。

2. **`TEST(RunWasmTurbofan_S256Load16x4U)` 和 `TEST(RunWasmTurbofan_S256Load16x4S)`:**
   - **功能:** 类似于上面的测试，但这次测试的是 `s128.load16x4_u` 和 `s128.load16x4_s` 指令，将内存中的 4 个 16 位值加载到 128 位 SIMD 寄存器并进行零扩展或符号扩展到 32 位。同样关注 Turbofan 的 256 位优化。

3. **`TEST(RunWasmTurbofan_S256Load32x2U)` 和 `TEST(RunWasmTurbofan_S256Load32x2S)`:**
   - **功能:** 测试 `s128.load32x2_u` 和 `s128.load32x2_s` 指令，将内存中的 2 个 32 位值加载到 128 位 SIMD 寄存器并进行零扩展或符号扩展到 64 位。

4. **`TEST(RunWasmTurbofan_I8x32Splat)`:**
   - **功能:** 测试 `i8x16.splat` 指令能否被 Turbofan 优化为 256 位的 splat 操作 (`Simd256SplatOp::Kind::kI8x32`)。 `splat` 指令将一个标量值复制到 SIMD 向量的所有通道。
   - **代码逻辑:**  使用 `TSSimd256VerifyScope` 验证特定的 256 位 splat 操作是否被生成。将一个 8 位参数 `param1` splat 到一个 128 位向量，然后存储到内存的两个不同偏移位置，模拟 256 位操作的效果。
   - **假设输入与输出:**
     - **假设输入:** `param1` 的值为任意 `int8_t` 值，例如 `5`。
     - **预期输出:** 内存的起始 16 个字节和偏移 16 字节开始的 16 个字节都将被设置为 `5`。

5. **`TEST(RunWasmTurbofan_I16x16Splat)`, `TEST(RunWasmTurbofan_I32x8Splat)`, `TEST(RunWasmTurbofan_I64x4Splat)`, `TEST(RunWasmTurbofan_F32x8Splat)`, `TEST(RunWasmTurbofan_F64x4Splat)`:**
   - **功能:** 这些测试与 `RunWasmTurbofan_I8x32Splat` 类似，测试不同数据类型的 `splat` 指令 (分别为 `i16x8.splat`, `i32x4.splat`, `i64x2.splat`, `f32x4.splat`, `f64x2.splat`) 能否被 Turbofan 优化为相应的 256 位 splat 操作 (`kI16x16`, `kI32x8`, `kI64x4`, `kF32x8`, `kF64x4`)。
   - **代码逻辑:**  与 `RunWasmTurbofan_I8x32Splat` 结构类似，只是数据类型和验证的 256 位 splat 类型不同。对于浮点数，会检查 NaN 的情况。

**与其他部分的关系 (根据上下文推断):**

由于这是第 7 部分，前面的部分很可能涵盖了：

- 基础的 Wasm SIMD 指令测试，可能没有涉及到 Turbofan 的 256 位优化。
- 简单的 SIMD 运算，如加减乘除等。
- 内存加载和存储的基本操作。

接下来的部分 (第 8 和 9 部分) 可能会涉及：

- 更复杂的 SIMD 指令，例如 lane-wise 的操作，比较操作，位运算等。
- 控制流与 SIMD 指令的结合。
- 更深入的 Turbofan 优化策略测试。

**是否为 Torque 源代码:**

根据您的描述，如果 `v8/test/cctest/wasm/test-run-wasm-simd.cc` 以 `.tq` 结尾，它才是一个 V8 Torque 源代码。 由于这里是 `.cc` 结尾，所以它是一个 C++ 源代码。

**与 JavaScript 的功能关系及示例:**

这些测试验证的 WebAssembly SIMD 功能，最终会通过 JavaScript 的 `WebAssembly.compile` 和 `WebAssembly.instantiate` 等 API 在浏览器中执行。 JavaScript 中对应的 SIMD API 位于 `SIMD` 对象下。

**JavaScript 示例 (对应 `RunWasmTurbofan_I8x32Splat` 的概念):**

```javascript
// 假设已经编译并实例化了一个 WebAssembly 模块 instance
const memory = new Int8Array(instance.exports.memory.buffer);

// 假设 WebAssembly 模块导出了一个名为 splat_i8 的函数，
// 该函数实现了与 RunWasmTurbofan_I8x32Splat 测试相似的功能

const inputValue = 5;
instance.exports.splat_i8(inputValue);

// 验证内存中的值
for (let i = 0; i < 32; i++) {
  console.assert(memory[i] === inputValue, `Memory at ${i} is incorrect`);
}
```

**总结第 7 部分的功能:**

这段代码主要集中测试了 V8 的 Turbofan 优化编译器对 WebAssembly SIMD 指令的 **256 位向量化优化** 能力，特别是针对以下场景：

- **加载并扩展指令 (load extend):**  验证 `s128.load8x8`, `s128.load16x4`, `s128.load32x2` 等指令在 Turbofan 下能否被优化为 256 位操作。
- **标量值广播 (splat):** 验证 `i8x16.splat`, `i16x8.splat`, `i32x4.splat`, `i64x2.splat`, `f32x4.splat`, `f64x2.splat` 等指令在 Turbofan 下能否被优化为相应的 256 位 splat 操作。

这些测试确保了 V8 能够有效地利用现代 CPU 的 SIMD 扩展 (如 AVX2) 来提升 WebAssembly 代码的性能。

### 提示词
```
这是目录为v8/test/cctest/wasm/test-run-wasm-simd.cc的一个v8源代码， 请列举一下它的功能, 
如果v8/test/cctest/wasm/test-run-wasm-simd.cc以.tq结尾，那它是个v8 torque源代码，
如果它与javascript的功能有关系，请用javascript举例说明,
如果有代码逻辑推理，请给出假设输入与输出，
如果涉及用户常见的编程错误，请举例说明
这是第7部分，共9部分，请归纳一下它的功能
```

### 源代码
```cpp
res::IsSupported(AVX2)) return;
  WasmRunner<int8_t> r(TestExecutionTier::kTurbofan);
  int8_t* memory = r.builder().AddMemoryElems<int8_t>(40);

  constexpr std::array<int8_t, 16> shuffle0 = {16, 1, 2,  3,  17, 5,  6,  7,
                                               18, 9, 10, 11, 19, 13, 14, 15};
  constexpr std::array<int8_t, 16> shuffle1 = {4, 17, 18, 19, 5, 21, 22, 23,
                                               6, 25, 26, 27, 7, 29, 30, 31};
  uint8_t temp1 = r.AllocateLocal(kWasmS128);
  std::array<uint8_t, kSimd128Size> all_zero = {0};

  {
    auto verify_s256load8x8u = [](const compiler::turboshaft::Graph& graph) {
      for (const compiler::turboshaft::Operation& op : graph.AllOperations()) {
        if (const compiler::turboshaft::Simd256LoadTransformOp* load_op =
                op.TryCast<compiler::turboshaft::Simd256LoadTransformOp>()) {
          if (load_op->transform_kind ==
              compiler::turboshaft::Simd256LoadTransformOp::TransformKind::
                  k8x8U) {
            return true;
          }
        }
      }
      return false;
    };

    TSSimd256VerifyScope ts_scope(r.zone(), verify_s256load8x8u);
    r.Build({WASM_LOCAL_SET(temp1,
                            WASM_SIMD_LOAD_OP(kExprS128Load64Zero, WASM_ZERO)),
             WASM_SIMD_STORE_MEM_OFFSET(
                 8, WASM_ZERO,
                 WASM_SIMD_I8x16_SHUFFLE_OP(kExprI8x16Shuffle, shuffle0,
                                            WASM_SIMD_CONSTANT(all_zero),
                                            WASM_LOCAL_GET(temp1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 24, WASM_ZERO,
                 WASM_SIMD_I8x16_SHUFFLE_OP(kExprI8x16Shuffle, shuffle1,
                                            WASM_LOCAL_GET(temp1),
                                            WASM_SIMD_CONSTANT(all_zero))),
             WASM_ONE});
  }
  std::pair<std::vector<int8_t>, std::vector<int32_t>> test_case = {
      {0, 1, 2, 3, 4, 5, 6, -1}, {0, 1, 2, 3, 4, 5, 6, 255}};
  auto input = test_case.first;
  auto expected_output = test_case.second;
  for (int i = 0; i < 8; ++i) {
    r.builder().WriteMemory(&memory[i], input[i]);
  }
  r.Call();
  int32_t* memory_int32_t = reinterpret_cast<int32_t*>(memory);
  for (int i = 0; i < 8; ++i) {
    CHECK_EQ(expected_output[i],
             r.builder().ReadMemory(&memory_int32_t[i + 2]));
  }
}

template <typename T>
void RunLoadSplatRevecTest(WasmOpcode op, WasmOpcode bin_op,
                           compiler::IrOpcode::Value revec_opcode,
                           T (*expected_op)(T, T)) {
  if (!CpuFeatures::IsSupported(AVX2)) return;

  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  constexpr int lanes = 16 / sizeof(T);
  constexpr int mem_index = 64;  // LoadSplat from mem index 64 (bytes).
  constexpr uint8_t offset = 16;

#define BUILD_LOADSPLAT(get_op, index)                                         \
  T* memory = r.builder().AddMemoryElems<T>(kWasmPageSize / sizeof(T));        \
  uint8_t temp1 = r.AllocateLocal(kWasmS128);                                  \
  uint8_t temp2 = r.AllocateLocal(kWasmS128);                                  \
  uint8_t temp3 = r.AllocateLocal(kWasmS128);                                  \
                                                                               \
  BUILD_AND_CHECK_REVEC_NODE(                                                  \
      r, revec_opcode,                                                         \
      WASM_LOCAL_SET(temp1, WASM_SIMD_LOAD_OP(op, get_op(index))),             \
      WASM_LOCAL_SET(temp2,                                                    \
                     WASM_SIMD_BINOP(bin_op, WASM_SIMD_LOAD_MEM(WASM_I32V(0)), \
                                     WASM_LOCAL_GET(temp1))),                  \
      WASM_LOCAL_SET(                                                          \
          temp3, WASM_SIMD_BINOP(                                              \
                     bin_op, WASM_SIMD_LOAD_MEM_OFFSET(offset, WASM_I32V(0)),  \
                     WASM_LOCAL_GET(temp1))),                                  \
                                                                               \
      /* Store the result to the 32-th byte, which is 2*lanes-th element (size \
         T) of memory */                                                       \
      WASM_SIMD_STORE_MEM(WASM_I32V(32), WASM_LOCAL_GET(temp2)),               \
      WASM_SIMD_STORE_MEM_OFFSET(offset, WASM_I32V(32),                        \
                                 WASM_LOCAL_GET(temp3)),                       \
      WASM_ONE);                                                               \
                                                                               \
  r.builder().WriteMemory(&memory[1], T(1));                                   \
  r.builder().WriteMemory(&memory[lanes + 1], T(1));

  {
    WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
    TSSimd256VerifyScope ts_scope(r.zone());
    BUILD_LOADSPLAT(WASM_I32V, mem_index)

    for (T x : compiler::ValueHelper::GetVector<T>()) {
      // 64-th byte in memory is 4*lanes-th element (size T) of memory.
      r.builder().WriteMemory(&memory[4 * lanes], x);
      r.Call();
      T expected = expected_op(1, x);
      CHECK_EQ(expected, memory[2 * lanes + 1]);
      CHECK_EQ(expected, memory[3 * lanes + 1]);
    }
  }

  // Test for OOB.
  {
    WasmRunner<int32_t, int32_t> r(TestExecutionTier::kTurbofan);
    TSSimd256VerifyScope ts_scope(r.zone());
    BUILD_LOADSPLAT(WASM_LOCAL_GET, 0)

    // Load splats load sizeof(T) bytes.
    for (uint32_t offset = kWasmPageSize - (sizeof(T) - 1);
         offset < kWasmPageSize; ++offset) {
      CHECK_TRAP(r.Call(offset));
    }
  }
#undef BUILD_RUN
}

TEST(RunWasmTurbofan_S256Load8Splat) {
  RunLoadSplatRevecTest<int8_t>(kExprS128Load8Splat, kExprI32x4Add,
                                compiler::IrOpcode::kI32x8Add,
                                base::AddWithWraparound);
}

TEST(RunWasmTurbofan_S256Load16Splat) {
  RunLoadSplatRevecTest<int16_t>(kExprS128Load16Splat, kExprI16x8Add,
                                 compiler::IrOpcode::kI16x16Add,
                                 base::AddWithWraparound);
}

TEST(RunWasmTurbofan_S256Load32Splat) {
  RunLoadSplatRevecTest<int32_t>(kExprS128Load32Splat, kExprI32x4Add,
                                 compiler::IrOpcode::kI32x8Add,
                                 base::AddWithWraparound);
}

TEST(RunWasmTurbofan_S256Load64Splat) {
  RunLoadSplatRevecTest<int64_t>(kExprS128Load64Splat, kExprI64x2Add,
                                 compiler::IrOpcode::kI64x4Add,
                                 base::AddWithWraparound);
}

template <typename S, typename T>
void RunLoadExtendRevecTest(WasmOpcode op) {
  if (!CpuFeatures::IsSupported(AVX2)) return;

  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  static_assert(sizeof(S) < sizeof(T),
                "load extend should go from smaller to larger type");
  constexpr int lanes_s = 16 / sizeof(S);
  constexpr int lanes_t = 16 / sizeof(T);
  constexpr uint8_t offset_s = 8;  // Load extend accesses 8 bytes value.
  constexpr uint8_t offset = 16;
  constexpr int mem_index = 0;  // Load from mem index 0 (bytes).

#define BUILD_LOADEXTEND(get_op, index)                                      \
  uint8_t temp1 = r.AllocateLocal(kWasmS128);                                \
  uint8_t temp2 = r.AllocateLocal(kWasmS128);                                \
                                                                             \
  BUILD_AND_CHECK_REVEC_NODE(                                                \
      r, compiler::IrOpcode::kStore,                                         \
      WASM_LOCAL_SET(temp1, WASM_SIMD_LOAD_OP(op, get_op(index))),           \
      WASM_LOCAL_SET(temp2,                                                  \
                     WASM_SIMD_LOAD_OP_OFFSET(op, get_op(index), offset_s)), \
                                                                             \
      /* Store the result to the 16-th byte, which is lanes-th element (size \
         S) of memory. */                                                    \
      WASM_SIMD_STORE_MEM(WASM_I32V(16), WASM_LOCAL_GET(temp1)),             \
      WASM_SIMD_STORE_MEM_OFFSET(offset, WASM_I32V(16),                      \
                                 WASM_LOCAL_GET(temp2)),                     \
      WASM_ONE);

  {
    WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
    TSSimd256VerifyScope ts_scope(r.zone());
    S* memory = r.builder().AddMemoryElems<S>(kWasmPageSize / sizeof(S));
    BUILD_LOADEXTEND(WASM_I32V, mem_index)

    for (S x : compiler::ValueHelper::GetVector<S>()) {
      for (int i = 0; i < lanes_s; i++) {
        r.builder().WriteMemory(&memory[i], x);
      }
      r.Call();
      for (int i = 0; i < 2 * lanes_t; i++) {
        CHECK_EQ(static_cast<T>(x), reinterpret_cast<T*>(&memory[lanes_s])[i]);
      }
    }
  }

  // Test for OOB.
  {
    WasmRunner<int32_t, uint32_t> r(TestExecutionTier::kTurbofan);
    TSSimd256VerifyScope ts_scope(r.zone());
    r.builder().AddMemoryElems<S>(kWasmPageSize / sizeof(S));
    BUILD_LOADEXTEND(WASM_LOCAL_GET, 0)

    // Load extends load 8 bytes, so should trap from -7.
    for (uint32_t offset = kWasmPageSize - 7; offset < kWasmPageSize;
         ++offset) {
      CHECK_TRAP(r.Call(offset));
    }
  }
}

TEST(S128Load8x8U) {
  RunLoadExtendRevecTest<uint8_t, uint16_t>(kExprS128Load8x8U);
}

TEST(S128Load8x8S) {
  RunLoadExtendRevecTest<int8_t, int16_t>(kExprS128Load8x8S);
}

TEST(S128Load16x4U) {
  RunLoadExtendRevecTest<uint16_t, uint32_t>(kExprS128Load16x4U);
}

TEST(S128Load16x4S) {
  RunLoadExtendRevecTest<int16_t, int32_t>(kExprS128Load16x4S);
}

TEST(S128Load32x2U) {
  RunLoadExtendRevecTest<uint32_t, uint64_t>(kExprS128Load32x2U);
}

TEST(S128Load32x2S) {
  RunLoadExtendRevecTest<int32_t, int64_t>(kExprS128Load32x2S);
}

TEST(RunWasmTurbofan_I8x32Splat) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX) || !CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, int8_t> r(TestExecutionTier::kTurbofan);
  int8_t* memory = r.builder().AddMemoryElems<int8_t>(32);
  int8_t param1 = 0;
  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpWithKind<
                      compiler::turboshaft::Simd256SplatOp,
                      compiler::turboshaft::Simd256SplatOp::Kind::kI8x32>);
    r.Build({WASM_SIMD_STORE_MEM(WASM_ZERO,
                                 WASM_SIMD_I8x16_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 16, WASM_ZERO, WASM_SIMD_I8x16_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_ONE});
  }
  FOR_INT8_INPUTS(x) {
    r.Call(x);
    for (int i = 0; i < 32; ++i) {
      CHECK_EQ(x, r.builder().ReadMemory(&memory[i]));
    }
  }
}

TEST(RunWasmTurbofan_I16x16Splat) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX) || !CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, int16_t> r(TestExecutionTier::kTurbofan);
  int16_t* memory = r.builder().AddMemoryElems<int16_t>(16);
  int16_t param1 = 0;
  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpWithKind<
                      compiler::turboshaft::Simd256SplatOp,
                      compiler::turboshaft::Simd256SplatOp::Kind::kI16x16>);
    r.Build({WASM_SIMD_STORE_MEM(WASM_ZERO,
                                 WASM_SIMD_I16x8_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 16, WASM_ZERO, WASM_SIMD_I16x8_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_ONE});
  }
  FOR_INT16_INPUTS(x) {
    r.Call(x);
    for (int i = 0; i < 16; ++i) {
      CHECK_EQ(x, r.builder().ReadMemory(&memory[i]));
    }
  }
}

TEST(RunWasmTurbofan_I32x8Splat) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX) || !CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, int32_t> r(TestExecutionTier::kTurbofan);
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(8);
  int32_t param1 = 0;

  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpWithKind<
                      compiler::turboshaft::Simd256SplatOp,
                      compiler::turboshaft::Simd256SplatOp::Kind::kI32x8>);
    r.Build({WASM_SIMD_STORE_MEM(WASM_ZERO,
                                 WASM_SIMD_I32x4_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 16, WASM_ZERO, WASM_SIMD_I32x4_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_ONE});
  }

  FOR_INT32_INPUTS(x) {
    r.Call(x);
    for (int i = 0; i < 8; ++i) {
      CHECK_EQ(x, r.builder().ReadMemory(&memory[i]));
    }
  }
}

TEST(RunWasmTurbofan_I64x4Splat) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX) || !CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, int64_t> r(TestExecutionTier::kTurbofan);
  int64_t* memory = r.builder().AddMemoryElems<int64_t>(4);
  int64_t param1 = 0;
  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpWithKind<
                      compiler::turboshaft::Simd256SplatOp,
                      compiler::turboshaft::Simd256SplatOp::Kind::kI64x4>);
    r.Build({WASM_SIMD_STORE_MEM(WASM_ZERO,
                                 WASM_SIMD_I64x2_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 16, WASM_ZERO, WASM_SIMD_I64x2_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_ONE});
  }

  FOR_INT64_INPUTS(x) {
    r.Call(x);
    for (int i = 0; i < 4; ++i) {
      CHECK_EQ(x, r.builder().ReadMemory(&memory[i]));
    }
  }
}

TEST(RunWasmTurbofan_F32x8Splat) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, float> r(TestExecutionTier::kTurbofan);
  float* memory = r.builder().AddMemoryElems<float>(8);
  float param1 = 0;
  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpWithKind<
                      compiler::turboshaft::Simd256SplatOp,
                      compiler::turboshaft::Simd256SplatOp::Kind::kF32x8>);
    r.Build({WASM_SIMD_STORE_MEM(WASM_ZERO,
                                 WASM_SIMD_F32x4_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 16, WASM_ZERO, WASM_SIMD_F32x4_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_ONE});
  }

  FOR_FLOAT32_INPUTS(x) {
    r.Call(x);
    for (int i = 0; i < 8; ++i) {
      if (std::isnan(x)) {
        CHECK(std::isnan(r.builder().ReadMemory(&memory[i])));
      } else {
        CHECK_EQ(x, r.builder().ReadMemory(&memory[i]));
      }
    }
  }
}

TEST(RunWasmTurbofan_F64x4Splat) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, double> r(TestExecutionTier::kTurbofan);
  double* memory = r.builder().AddMemoryElems<double>(4);
  double param1 = 0;
  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpWithKind<
                      compiler::turboshaft::Simd256SplatOp,
                      compiler::turboshaft::Simd256SplatOp::Kind::kF64x4>);
    r.Build({WASM_SIMD_STORE_MEM(WASM_ZERO,
                                 WASM_SIMD_F64x2_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_SIMD_STORE_MEM_OFFSET(
                 16, WASM_ZERO, WASM_SIMD_F64x2_SPLAT(WASM_LOCAL_GET(param1))),
             WASM_ONE});
  }

  FOR_FLOAT64_INPUTS(x) {
    r.Call(x);
    for (int i = 0; i < 4; ++i) {
      if (std::isnan(x)) {
        CHECK(std::isnan(r.builder().ReadMemory(&memory[i])));
      } else {
        CHECK_EQ(x, r.builder().ReadMemory(&memory[i]));
      }
    }
  }
}

TEST(RunWasmTurbofan_Phi) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX) || !CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t, int32_t, int32_t> r(TestExecutionTier::kTurbofan);
  constexpr int32_t iteration = 8;
  constexpr uint32_t lanes = kSimd128Size / sizeof(int32_t);
  constexpr int32_t count = 2 * iteration * lanes;
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(count);
  // Build fn perform add on 128 bit vectors a, store the result in b:
  // int32_t func(simd128* a, simd128* b) {
  //   simd128 sum1 = sum2 = 0;
  //   for (int i = 0; i < 8; i++) {
  //     sum1 += *a;
  //     sum2 += *(a+1);
  //     a += 2;
  //   }
  //   *b = sum1;
  //   *(b+1) = sum2;
  // }
  uint8_t param1 = 0;
  uint8_t param2 = 1;
  uint8_t index = r.AllocateLocal(kWasmI32);
  uint8_t sum1 = r.AllocateLocal(kWasmS128);
  uint8_t sum2 = r.AllocateLocal(kWasmS128);
  constexpr uint8_t offset = 16;
  {
    TSSimd256VerifyScope ts_scope(r.zone());
    BUILD_AND_CHECK_REVEC_NODE(
        r, compiler::IrOpcode::kPhi, WASM_LOCAL_SET(index, WASM_I32V(0)),
        WASM_LOCAL_SET(sum1, WASM_SIMD_I32x4_SPLAT(WASM_I32V(0))),
        WASM_LOCAL_SET(sum2, WASM_LOCAL_GET(sum1)),
        WASM_LOOP(
            WASM_LOCAL_SET(
                sum1,
                WASM_SIMD_BINOP(kExprI32x4Add, WASM_LOCAL_GET(sum1),
                                WASM_SIMD_LOAD_MEM(WASM_LOCAL_GET(param1)))),
            WASM_LOCAL_SET(
                sum2, WASM_SIMD_BINOP(kExprI32x4Add, WASM_LOCAL_GET(sum2),
                                      WASM_SIMD_LOAD_MEM_OFFSET(
                                          offset, WASM_LOCAL_GET(param1)))),
            WASM_IF(WASM_I32_LTS(WASM_INC_LOCAL(index), WASM_I32V(iteration)),
                    WASM_BR(1))),
        WASM_SIMD_STORE_MEM(WASM_LOCAL_GET(param2), WASM_LOCAL_GET(sum1)),
        WASM_SIMD_STORE_MEM_OFFSET(offset, WASM_LOCAL_GET(param2),
                                   WASM_LOCAL_GET(sum2)),
        WASM_ONE);
  }
  for (int32_t x : compiler::ValueHelper::GetVector<int32_t>()) {
    for (int32_t y : compiler::ValueHelper::GetVector<int32_t>()) {
      for (int32_t i = 0; i < iteration; i++) {
        for (uint32_t j = 0; j < lanes; j++) {
          r.builder().WriteMemory(&memory[i * 2 * lanes + j], x);
          r.builder().WriteMemory(&memory[i * 2 * lanes + j + lanes], y);
        }
      }
      r.Call(0, iteration * 2 * kSimd128Size);
      int32_t* output = reinterpret_cast<int32_t*>(memory + count);
      for (uint32_t i = 0; i < lanes; i++) {
        CHECK_EQ(x * iteration, output[i]);
        CHECK_EQ(y * iteration, output[i + lanes]);
      }
    }
  }
}

TEST(RunWasmTurbofan_ForcePackIdenticalLoad) {
  SKIP_TEST_IF_NO_TURBOSHAFT;
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(16);
  uint8_t temp1 = r.AllocateLocal(kWasmS128);
  uint8_t temp2 = r.AllocateLocal(kWasmS128);
  uint8_t temp3 = r.AllocateLocal(kWasmS128);

  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                      compiler::turboshaft::Opcode::kSimdPack128To256>);
    // Load from [0:15], the two loads are indentical.
    r.Build({WASM_LOCAL_SET(temp3, WASM_SIMD_LOAD_MEM(WASM_ZERO)),
             WASM_LOCAL_SET(
                 temp1, WASM_SIMD_UNOP(kExprI32x4Abs,
                                       WASM_SIMD_UNOP(kExprS128Not,
                                                      WASM_LOCAL_GET(temp3)))),
             WASM_LOCAL_SET(
                 temp2, WASM_SIMD_UNOP(kExprI32x4Abs,
                                       WASM_SIMD_UNOP(kExprS128Not,
                                                      WASM_LOCAL_GET(temp3)))),

             WASM_SIMD_STORE_MEM_OFFSET(16, WASM_ZERO, WASM_LOCAL_GET(temp1)),
             WASM_SIMD_STORE_MEM_OFFSET(32, WASM_ZERO, WASM_LOCAL_GET(temp2)),

             WASM_ONE});
  }
  FOR_INT32_INPUTS(x) {
    r.builder().WriteMemory(&memory[1], x);
    r.builder().WriteMemory(&memory[13], x);
    r.Call();
    int32_t expected = std::abs(~x);
    CHECK_EQ(expected, memory[5]);
    CHECK_EQ(expected, memory[9]);
  }
}

TEST(RunWasmTurbofan_ForcePackLoadsAtSameAddr) {
  SKIP_TEST_IF_NO_TURBOSHAFT;
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(16);
  uint8_t temp1 = r.AllocateLocal(kWasmS128);
  uint8_t temp2 = r.AllocateLocal(kWasmS128);

  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                      compiler::turboshaft::Opcode::kSimdPack128To256>);
    // Load from [0:15], the two loads are identical.
    r.Build({WASM_LOCAL_SET(
                 temp1,
                 WASM_SIMD_UNOP(kExprI32x4Abs,
                                WASM_SIMD_UNOP(kExprS128Not,
                                               WASM_SIMD_LOAD_MEM(WASM_ZERO)))),
             WASM_LOCAL_SET(
                 temp2,
                 WASM_SIMD_UNOP(kExprI32x4Abs,
                                WASM_SIMD_UNOP(kExprS128Not,
                                               WASM_SIMD_LOAD_MEM(WASM_ZERO)))),

             WASM_SIMD_STORE_MEM_OFFSET(16, WASM_ZERO, WASM_LOCAL_GET(temp1)),
             WASM_SIMD_STORE_MEM_OFFSET(32, WASM_ZERO, WASM_LOCAL_GET(temp2)),

             WASM_ONE});
  }
  FOR_INT32_INPUTS(x) {
    r.builder().WriteMemory(&memory[1], x);
    r.builder().WriteMemory(&memory[13], x);
    r.Call();
    int32_t expected = std::abs(~x);
    CHECK_EQ(expected, memory[5]);
    CHECK_EQ(expected, memory[9]);
  }
}

TEST(RunWasmTurbofan_ForcePackInContinuousLoad) {
  SKIP_TEST_IF_NO_TURBOSHAFT;
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(16);
  uint8_t temp1 = r.AllocateLocal(kWasmS128);
  uint8_t temp2 = r.AllocateLocal(kWasmS128);

  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                      compiler::turboshaft::Opcode::kSimdPack128To256>);
    // Load from [0:15] and [48:63] which are incontinuous, calculate the data
    // by Not and Abs and stores the results to [16:31] and [32:47] which are
    // continuous. By force-packing the incontinuous loads, we still revectorize
    // all the operations.
    //   simd128 *a,*b;
    //   simd128 temp1 = abs(!(*a));
    //   simd128 temp2 = abs(!(*(a + 3)));
    //   *b = temp1;
    //   *(b+1) = temp2;
    r.Build({WASM_LOCAL_SET(
                 temp1,
                 WASM_SIMD_UNOP(kExprI32x4Abs,
                                WASM_SIMD_UNOP(kExprS128Not,
                                               WASM_SIMD_LOAD_MEM(WASM_ZERO)))),
             WASM_LOCAL_SET(
                 temp2, WASM_SIMD_UNOP(kExprI32x4Abs,
                                       WASM_SIMD_UNOP(kExprS128Not,
                                                      WASM_SIMD_LOAD_MEM_OFFSET(
                                                          48, WASM_ZERO)))),

             WASM_SIMD_STORE_MEM_OFFSET(16, WASM_ZERO, WASM_LOCAL_GET(temp1)),
             WASM_SIMD_STORE_MEM_OFFSET(32, WASM_ZERO, WASM_LOCAL_GET(temp2)),

             WASM_ONE});
  }
  FOR_INT32_INPUTS(x) {
    r.builder().WriteMemory(&memory[1], x);
    r.builder().WriteMemory(&memory[13], 2 * x);
    r.Call();
    CHECK_EQ(std::abs(~x), memory[5]);
    CHECK_EQ(std::abs(~(2 * x)), memory[9]);
  }
}

TEST(RunWasmTurbofan_ForcePackIncontinuousLoadsReversed) {
  SKIP_TEST_IF_NO_TURBOSHAFT;
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(16);
  uint8_t temp1 = r.AllocateLocal(kWasmS128);
  uint8_t temp2 = r.AllocateLocal(kWasmS128);

  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                      compiler::turboshaft::Opcode::kSimdPack128To256>);
    // Loads from [48:63] and [0:15] which are incontinuous, calculate the data
    // by Not and Abs and stores the results in reversed order to [16:31] and
    // [32:47] which are continuous. By force-packing the incontinuous loads, we
    // still revectorize all the operations.
    //   simd128 *a,*b;
    //   simd128 temp1 = abs(!(*(a + 3)));
    //   simd128 temp2 = abs(!(*a));
    //   *b = temp2;
    //   *(b+1) = temp1;
    r.Build({WASM_LOCAL_SET(
                 temp1, WASM_SIMD_UNOP(kExprI32x4Abs,
                                       WASM_SIMD_UNOP(kExprS128Not,
                                                      WASM_SIMD_LOAD_MEM_OFFSET(
                                                          48, WASM_ZERO)))),
             WASM_LOCAL_SET(
                 temp2,
                 WASM_SIMD_UNOP(kExprI32x4Abs,
                                WASM_SIMD_UNOP(kExprS128Not,
                                               WASM_SIMD_LOAD_MEM(WASM_ZERO)))),
             WASM_SIMD_STORE_MEM_OFFSET(16, WASM_ZERO, WASM_LOCAL_GET(temp2)),
             WASM_SIMD_STORE_MEM_OFFSET(32, WASM_ZERO, WASM_LOCAL_GET(temp1)),
             WASM_ONE});
  }
  FOR_INT32_INPUTS(x) {
    r.builder().WriteMemory(&memory[1], x);
    r.builder().WriteMemory(&memory[14], 2 * x);
    r.Call();
    CHECK_EQ(std::abs(~x), memory[5]);
    CHECK_EQ(std::abs(~(2 * x)), memory[10]);
  }
}

TEST(RunWasmTurbofan_RevecReduce) {
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX) || !CpuFeatures::IsSupported(AVX2)) return;
  WasmRunner<int64_t, int32_t> r(TestExecutionTier::kTurbofan);
  uint32_t count = 8;
  int64_t* memory = r.builder().AddMemoryElems<int64_t>(count);
  // Build fn perform sum up 128 bit vectors a, return the result:
  // int64_t sum(simd128* a) {
  //   simd128 sum128 = a[0] + a[1] + a[2] + a[3];
  //   return LANE(sum128, 0) + LANE(sum128, 1);
  // }
  uint8_t param1 = 0;
  uint8_t sum1 = r.AllocateLocal(kWasmS128);
  uint8_t sum2 = r.AllocateLocal(kWasmS128);
  uint8_t sum = r.AllocateLocal(kWasmS128);
  constexpr uint8_t offset = 16;
  {
    TSSimd256VerifyScope ts_scope(r.zone());
    r.Build(
        {WASM_LOCAL_SET(
             sum1, WASM_SIMD_BINOP(kExprI64x2Add,
                                   WASM_SIMD_LOAD_MEM(WASM_LOCAL_GET(param1)),
                                   WASM_SIMD_LOAD_MEM_OFFSET(
                                       offset * 2, WASM_LOCAL_GET(param1)))),
         WASM_LOCAL_SET(
             sum2, WASM_SIMD_BINOP(kExprI64x2Add,
                                   WASM_SIMD_LOAD_MEM_OFFSET(
                                       offset, WASM_LOCAL_GET(param1)),
                                   WASM_SIMD_LOAD_MEM_OFFSET(
                                       offset * 3, WASM_LOCAL_GET(param1)))),
         WASM_LOCAL_SET(sum,
                        WASM_SIMD_BINOP(kExprI64x2Add, WASM_LOCAL_GET(sum1),
                                        WASM_LOCAL_GET(sum2))),
         WASM_I64_ADD(WASM_SIMD_I64x2_EXTRACT_LANE(0, WASM_LOCAL_GET(sum)),
                      WASM_SIMD_I64x2_EXTRACT_LANE(1, WASM_LOCAL_GET(sum)))});
  }
  for (int64_t x : compiler::ValueHelper::GetVector<int64_t>()) {
    for (uint32_t i = 0; i < count; i++) {
      r.builder().WriteMemory(&memory[i], x);
    }
    int64_t expected = count * x;
    CHECK_EQ(r.Call(0), expected);
  }
}

TEST(RunWasmTurbofan_ForcePackLoadSplat) {
  SKIP_TEST_IF_NO_TURBOSHAFT;
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  // Use Load32Splat for the force packing test.

  WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
  int32_t* memory = r.builder().AddMemoryElems<int32_t>(10);
  uint8_t temp1 = r.AllocateLocal(kWasmS128);
  uint8_t temp2 = r.AllocateLocal(kWasmS128);
  {
    TSSimd256VerifyScope ts_scope(
        r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                      compiler::turboshaft::Opcode::kSimdPack128To256>);
    r.Build({WASM_LOCAL_SET(
                 temp1, WASM_SIMD_UNOP(kExprI32x4Abs,
                                       WASM_SIMD_UNOP(kExprS128Not,
                                                      WASM_SIMD_LOAD_OP(
                                                          kExprS128Load32Splat,
                                                          WASM_ZERO)))),
             WASM_LOCAL_SET(
                 temp2, WASM_SIMD_UNOP(kExprI32x4Abs,
                                       WASM_SIMD_UNOP(kExprS128Not,
                                                      WASM_SIMD_LOAD_OP_OFFSET(
                                                          kExprS128Load32Splat,
                                                          WASM_ZERO, 4)))),

             WASM_SIMD_STORE_MEM_OFFSET(8, WASM_ZERO, WASM_LOCAL_GET(temp1)),
             WASM_SIMD_STORE_MEM_OFFSET(24, WASM_ZERO, WASM_LOCAL_GET(temp2)),

             WASM_ONE});
  }

  FOR_INT32_INPUTS(x) {
    FOR_INT32_INPUTS(y) {
      r.builder().WriteMemory(&memory[0], x);
      r.builder().WriteMemory(&memory[1], y);
      r.Call();
      int expected_x = std::abs(~x);
      int expected_y = std::abs(~y);
      for (int i = 0; i < 4; ++i) {
        CHECK_EQ(expected_x, memory[i + 2]);
        CHECK_EQ(expected_y, memory[i + 6]);
      }
    }
  }
}

TEST(RunWasmTurbofan_ForcePackLoadExtend) {
  SKIP_TEST_IF_NO_TURBOSHAFT;
  EXPERIMENTAL_FLAG_SCOPE(revectorize);
  if (!CpuFeatures::IsSupported(AVX2)) return;
  // Use load32x2_s for the force packing test.
  {
    // Test ForcePackType::kSplat
    WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
    int32_t* memory = r.builder().AddMemoryElems<int32_t>(10);
    uint8_t temp1 = r.AllocateLocal(kWasmS128);
    uint8_t temp2 = r.AllocateLocal(kWasmS128);
    {
      TSSimd256VerifyScope ts_scope(
          r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                        compiler::turboshaft::Opcode::kSimdPack128To256>);
      r.Build(
          {WASM_LOCAL_SET(
               temp1, WASM_SIMD_SHIFT_OP(
                          kExprI64x2Shl,
                          WASM_SIMD_UNOP(
                              kExprS128Not,
                              WASM_SIMD_LOAD_OP(kExprS128Load32x2S, WASM_ZERO)),
                          WASM_I32V(1))),
           WASM_LOCAL_SET(
               temp2, WASM_SIMD_SHIFT_OP(
                          kExprI64x2Shl,
                          WASM_SIMD_UNOP(
                              kExprS128Not,
                              WASM_SIMD_LOAD_OP(kExprS128Load32x2S, WASM_ZERO)),
                          WASM_I32V(1))),

           WASM_SIMD_STORE_MEM_OFFSET(8, WASM_ZERO, WASM_LOCAL_GET(temp1)),
           WASM_SIMD_STORE_MEM_OFFSET(24, WASM_ZERO, WASM_LOCAL_GET(temp2)),

           WASM_ONE});
    }

    FOR_INT32_INPUTS(x) {
      FOR_INT32_INPUTS(y) {
        r.builder().WriteMemory(&memory[0], x);
        r.builder().WriteMemory(&memory[1], y);
        r.Call();
        const int64_t expected_x =
            LogicalShiftLeft(~static_cast<int64_t>(x), 1);
        const int64_t expected_y =
            LogicalShiftLeft(~static_cast<int64_t>(y), 1);
        const int64_t* const output_mem =
            reinterpret_cast<const int64_t*>(&memory[2]);
        for (int i = 0; i < 2; ++i) {
          const int64_t actual_x = output_mem[i * 2];
          const int64_t actual_y = output_mem[i * 2 + 1];
          CHECK_EQ(expected_x, actual_x);
          CHECK_EQ(expected_y, actual_y);
        }
      }
    }
  }

  {
    // Test ForcePackType::kGeneral
    WasmRunner<int32_t> r(TestExecutionTier::kTurbofan);
    int32_t* memory = r.builder().AddMemoryElems<int32_t>(12);
    uint8_t temp1 = r.AllocateLocal(kWasmS128);
    uint8_t temp2 = r.AllocateLocal(kWasmS128);
    {
      // incontinuous load32x2_s
      TSSimd256VerifyScope ts_scope(
          r.zone(), TSSimd256VerifyScope::VerifyHaveOpcode<
                        compiler::turboshaft::Opcode::kSimdPack128To256>);
      r.Build(
          {WASM_LOCAL_SET(
               temp1, WASM_SIMD_SHIFT_OP(
                          kExprI64x2ShrU,
                          WASM_SIMD_UNOP(
                              kExprS128Not,
                              WASM_SIMD_LOAD_OP(kExprS128Load32x2S, WASM_ZERO)),
                          WASM_I32V(1))),
           WASM_LOCAL_SET(
               temp2, WASM_SIMD_SHIFT_OP(
                          kExprI64x2ShrU,
                          WASM_SIMD_UNOP(kExprS128Not, WASM_SIMD_LOAD_OP_OFFSET(
                                                           kExprS128Load32x2S,
                                                           WASM_ZERO, 40)),
```